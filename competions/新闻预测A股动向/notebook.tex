
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{train}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{Data1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data/TRAINSET\PYZus{}NEWS.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{Data2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data/TRAINSET\PYZus{}STOCK.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsubsection{一、数据预览}\label{ux4e00ux6570ux636eux9884ux89c8}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{Data1}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:}                 id      date  \textbackslash{}
        26299  20190326\_12  20190326   
        26300  20190326\_13  20190326   
        26301  20190326\_14  20190326   
        26302  20190327\_00  20190327   
        26303  20190327\_01  20190327   
        26304  20190327\_02  20190327   
        26305  20190327\_03  20190327   
        26306  20190327\_04  20190327   
        26307  20190327\_05  20190327   
        26308  20190327\_06  20190327   
        26309  20190327\_07  20190327   
        26310  20190327\_08  20190327   
        26311  20190327\_09  20190327   
        26312  20190327\_10  20190327   
        26313  20190327\_11  20190327   
        26314  20190327\_12  20190327   
        26315  20190327\_13  20190327   
        26316  20190327\_14  20190327   
        26317  20190327\_15  20190327   
        26318  20190327\_16  20190327   
        26319  20190327\_17  20190327   
        26320  20190327\_18  20190327   
        26321  20190328\_00  20190328   
        26322  20190328\_01  20190328   
        26323  20190328\_02  20190328   
        26324  20190328\_03  20190328   
        26325  20190328\_04  20190328   
        26326  20190328\_05  20190328   
        26327  20190328\_06  20190328   
        26328  20190328\_07  20190328   
        {\ldots}            {\ldots}       {\ldots}   
        26369  20190331\_00  20190331   
        26370  20190331\_01  20190331   
        26371  20190331\_02  20190331   
        26372  20190331\_03  20190331   
        26373  20190331\_04  20190331   
        26374  20190331\_05  20190331   
        26375  20190331\_06  20190331   
        26376  20190331\_07  20190331   
        26377  20190331\_08  20190331   
        26378  20190331\_09  20190331   
        26379  20190331\_10  20190331   
        26380  20190331\_11  20190331   
        26381  20190331\_12  20190331   
        26382  20190401\_00  20190401   
        26383  20190401\_01  20190401   
        26384  20190401\_02  20190401   
        26385  20190401\_03  20190401   
        26386  20190401\_04  20190401   
        26387  20190401\_05  20190401   
        26388  20190401\_06  20190401   
        26389  20190401\_07  20190401   
        26390  20190401\_08  20190401   
        26391  20190401\_09  20190401   
        26392  20190401\_10  20190401   
        26393  20190401\_11  20190401   
        26394  20190401\_12  20190401   
        26395  20190401\_13  20190401   
        26396  20190401\_14  20190401   
        26397  20190401\_15  20190401   
        26398  20190401\_16  20190401   
        
                                                           title  \textbackslash{}
        26299                                     李克强主持召开国务院常务会议   
        26300                                         习近平同法国总统会谈   
        26301                                   习近平出席法国总统举行的欢迎仪式   
        26302                                               联播快讯   
        26303                          国新办发表《伟大的跨越：西藏民主改革60年》白皮书   
        26304        新华社综述：谱写新时代中国梦的雪域篇章——以习近平同志为核心的党中央治边稳藏富民新实践   
        26305                            中共中央办公厅印发《公务员职务与职级并行规定》   
        26306                               韩正在国家医疗保障局调研并主持召开座谈会   
        26307                                    李克强会见圣多美和普林西比总理   
        26308                                   李克强会见博鳌亚洲论坛理事会成员   
        26309                 李克强在海南考察时强调 更大激发市场主体活力 着力破解发展和民生难题   
        26310   新华社长篇通讯：共绘美美与共的人类文明画卷——写在习近平主席在联合国教科文组织总部演讲五周年之际   
        26311                        习近平同出席中法全球治理论坛闭幕式的欧洲领导人举行会晤   
        26312                     又踏层峰望眼开——习近平主席访问意大利 摩纳哥 法国成果丰硕   
        26313                                   文明交流互鉴推动合作共赢和平发展   
        26314                                          习近平会见德国总理   
        26315                                          习近平会见法国总理   
        26316                            习近平和法国总统共同出席中法全球治理论坛闭幕式   
        26317                                         习近平会见法国参议长   
        26318                             习近平和彭丽媛出席法国总统举行的隆重欢送仪式   
        26319                  习近平结束对意大利共和国 摩纳哥公国 法兰西共和国国事访问回到北京   
        26320                                      习近平会见法国国民议会议长   
        26321                 人民日报社论：铭记伟大变革 激扬奋进力量——纪念西藏民主改革六十周年   
        26322                                   美承认以色列对戈兰高地主权遭反对   
        26323                                各界积极评价习近平主席访问欧洲三国成果   
        26324                                             国内联播快讯   
        26325                                  第七届全国道德模范评选表彰活动启动   
        26326                                 【央视短评】致敬让荒漠变绿洲的奋斗者   
        26327                                             国际联播快讯   
        26328                                   “六老汉”三代人 守得沙漠变绿洲   
        {\ldots}                                                  {\ldots}   
        26369                                  江苏南京：千里绿道 串起美景惠民生   
        26370                                             国际联播快讯   
        26371                                  古特雷斯：利比亚冲突方有望达成一致   
        26372                                             国内联播快讯   
        26373                                        高楼映春色 美景入城中   
        26374                                   吉林：聚焦实体经济 加强创新引领   
        26375                                         巴勒斯坦人大规模示威   
        26376                                   湖南湘西：聚焦精准 决战脱贫攻坚   
        26377              中办 国办印发《关于以2022年北京冬奥会为契机 大力发展冰雪运动的意见》   
        26378  【在习近平新时代中国特色社会主义思想指引下——新时代 新作为 新篇章】北京立足“四个中心”提{\ldots}   
        26379                          习近平向第30届阿拉伯国家联盟首脑理事会会议致贺电   
        26380           《求是》杂志发表习近平总书记重要文章《关于坚持和发展中国特色社会主义的几个问题》   
        26381                                    制造业采购经理指数重回扩张区间   
        26382                                     中国轮胎企业在欧洲建首家工厂   
        26383                                             国际联播快讯   
        26384                             第六批在韩中国人民志愿军烈士遗骸装殓仪式举行   
        26385                                       阿盟峰会聚焦戈兰高地问题   
        26386                                             国内联播快讯   
        26387                                      四川凉山木里县发生森林火灾   
        26388                                国新办：我国对芬太尼类物质实施整类列管   
        26389                                    我国成功发射“天链二号01星”   
        26390                                    深化增值税改革系列措施今起实施   
        26391                                         王岐山会见蒙古国外长   
        26392                                 汪洋会见澳区省级政协委员联谊会访京团   
        26393        汪洋在脱贫攻坚民主监督工作座谈会上强调 聚焦脱贫攻坚突出问题 不断提高民主监督工作实效   
        26394                                      李克强同新西兰总理举行会谈   
        26395                                   李克强举行仪式欢迎新西兰总理访华   
        26396                        习近平向2019“中国—太平洋岛国旅游年”开幕式致贺词   
        26397                                      习近平会见“元老会”代表团   
        26398                                         习近平会见新西兰总理   
        
                                                         content  
        26299  国务院总理李克强3月26日主持召开国务院常务会议，落实降低社会保险费率部署，明确具体配套措施{\ldots}  
        26300  欢迎仪式后，在威武整齐的摩托车队护卫下，习近平乘车前往爱丽舍宫，沿途100多名法兰西共和国卫{\ldots}  
        26301  在中华人民共和国和法兰西共和国建交55周年之际，中国国家主席习近平时隔五年之后再次对法国进行{\ldots}  
        26302  全国开展危险化学品安全隐患排查国务院安委办、应急管理部今天（27日）召开视频会议，要求在全国{\ldots}  
        26303  国务院新闻办公室今天（27日）发表《伟大的跨越：西藏民主改革60年》白皮书。白皮书全文约2{\ldots}  
        26304  新华社今天（27日）播发综述《谱写新时代中国梦的雪域篇章——以习近平同志为核心的党中央治边稳{\ldots}  
        26305  近日，中共中央办公厅印发了《公务员职务与职级并行规定》，并发出通知，要求各地区各部门认真遵照{\ldots}  
        26306  中共中央政治局常委、国务院副总理韩正26日到国家医疗保障局调研。韩正观看了打击欺诈骗取医保基{\ldots}  
        26307  国务院总理李克强今天（27日）在海南会见来华出席博鳌亚洲论坛2019年年会的圣多美和普林西比{\ldots}  
        26308  国务院总理李克强今天（27日）在海南博鳌会见博鳌亚洲论坛理事长潘基文和理事会部分成员。李克强{\ldots}  
        26309  27日，在出席博鳌亚洲论坛期间，中共中央政治局常委、国务院总理李克强在海南海口考察。他强调，{\ldots}  
        26310  新华社今天（27日）播发长篇通讯《共绘美美与共的人类文明画卷——写在习近平主席在联合国教科文{\ldots}  
        26311  国家主席习近平当地时间26日在巴黎同出席中法全球治理论坛闭幕式的法国总统马克龙、德国总理默克{\ldots}  
        26312  2019年3月21日至26日，国家主席习近平应邀对意大利、摩纳哥、法国进行国事访问，引领中国{\ldots}  
        26313  五年前的今天，习近平主席在联合国教科文组织进行历史性访问并发表重要演讲，全面深刻地阐述了文明{\ldots}  
        26314  国家主席习近平当地时间26日在巴黎会见专程前来出席中法全球治理论坛闭幕式的德国总理默克尔。习{\ldots}  
        26315  国家主席习近平当地时间26日在巴黎总理府会见法国总理菲利普。习近平抵达总理府时，菲利普在停车{\ldots}  
        26316  国家主席习近平当地时间26日在巴黎同法国总统马克龙一道出席中法全球治理论坛闭幕式。德国总理默{\ldots}  
        26317  国家主席习近平当地时间26日在巴黎会见法国参议长拉尔歇。习近平抵达参议院时，拉尔歇议长在停车{\ldots}  
        26318  国家主席习近平当地时间26日结束对法国的国事访问。离开巴黎之前，习近平和夫人彭丽媛出席法国总{\ldots}  
        26319  3月27日，在结束对意大利共和国、摩纳哥公国、法兰西共和国国事访问后，国家主席习近平回到北京{\ldots}  
        26320  国家主席习近平当地时间26日在巴黎会见法国国民议会议长费朗。习近平抵达国民议会时，费朗议长在{\ldots}  
        26321         今天出版的人民日报发表社论《铭记伟大变革激扬奋进力量——纪念西藏民主改革六十周年》。  
        26322  27日，联合国安理会紧急开会讨论戈兰高地问题。叙利亚常驻联合国代表贾法里谴责美国单方面承认以{\ldots}  
        26323  日前，中国国家主席习近平应邀对意大利、摩纳哥、法国进行国事访问。三国各界人士称赞习主席此次访{\ldots}  
        26324  最高法发布优化营商环境司法解释最高人民法院今天对外发布优化营商环境司法解释，要求依法保护产权{\ldots}  
        26325  中央宣传部、中央文明办、全国总工会、共青团中央、全国妇联、中央军委政治工作部今天在京召开电视{\ldots}  
        26326  三代愚公志，黄沙变绿颜。38年来，“六老汉”三代人薪火相传、久久为功，在与恶劣环境的不懈斗争{\ldots}  
        26327  英国议会下院正式确认推迟“脱欧”英国议会下院27日投票表决，正式确认推迟原定于本月29日的“{\ldots}  
        26328  甘肃古浪县地处腾格里沙漠南缘，上个世纪80年代初，饱受风沙之苦的当地六位老汉为保卫家园，毅然{\ldots}  
        {\ldots}                                                  {\ldots}  
        26369  江苏南京，通过绿道串联起自然山水和人文景观，为市民打造低碳绿色生活，为发展注入新活力。南京江{\ldots}  
        26370  巴基斯坦新瓜达尔国际机场奠基29日，中巴经济走廊框架下的重点项目巴基斯坦新瓜达尔国际机场项目{\ldots}  
        26371  联合国秘书长古特雷斯30日表示，利比亚两个主要冲突方有望就军队控制权这一关键问题达成一致。据{\ldots}  
        26372  中国民航今起执行夏秋航季航班计划中国民航今天零时起执行2019年夏秋航季航班计划。新航季持续{\ldots}  
        26373  春和景明，柳绿桃红。持续不断的生态文明建设，不仅让希望的田野百花齐放，也让高楼林立的都市充满{\ldots}  
        26374  吉林省把发展实体经济、稳定工业增长放在突出位置，出台一系列政策举措，实施创新驱动战略，加快产{\ldots}  
        26375  30日是巴勒斯坦第43个“土地日”。巴勒斯坦人当天在加沙地带边境地区举行大规模示威，并与部署{\ldots}  
        26376  湖南湘西州属于武陵山集中连片特困地区，脱贫任务重。近几年，当地大力推广十八洞村精准脱贫经验，{\ldots}  
        26377  中共中央办公厅、国务院办公厅近日印发《关于以2022年北京冬奥会为契机大力发展冰雪运动的意见{\ldots}  
        26378  党的十八大以来，习近平总书记四次到北京考察慰问，五次对北京发表重要讲话，要求北京立足“四个中{\ldots}  
        26379  国家主席习近平31日致电阿拉伯国家联盟首脑理事会会议轮值主席突尼斯总统埃塞卜西，祝贺第30届{\ldots}  
        26380  4月1日出版的第7期《求是》杂志将发表中共中央总书记、国家主席、中央军委主席习近平的重要文章{\ldots}  
        26381  中国物流与采购联合会、国家统计局今天发布：3月份中国制造业采购经理指数又重回50\%以上的扩张{\ldots}  
        26382  中国轮胎企业的首个欧洲工厂项目近日在塞尔维亚兹雷尼亚宁市启动。塞尔维亚总统武契奇出席了启动仪{\ldots}  
        26383  乌克兰总统选举将进行第二轮投票乌克兰中央选举委员会当地时间4月1日上午发布消息称，3月31日{\ldots}  
        26384  4月1日，第六批在韩中国人民志愿军烈士遗骸及遗物，在韩国仁川举行装殓仪式。根据安排，4月3日{\ldots}  
        26385  第30届阿拉伯国家联盟首脑会议3月31日在突尼斯举行。会议发表声明，坚决反对美国承认戈兰高地{\ldots}  
        26386  全国已登记器官捐献志愿者116万余人清明节前夕，中国红十字会总会等部门在多地举办缅怀器官捐献{\ldots}  
        26387  3月30日18时许，四川省凉山州木里县境内发生森林火灾，当地地形复杂、坡陡谷深，交通、通讯不{\ldots}  
        26388  今天上午，在国务院新闻办公室举行的新闻发布会上，公安部、国家卫生健康委、国家药监局联合发布公{\ldots}  
        26389  昨天23时51分，我国在西昌卫星发射中心用“长征三号乙”运载火箭，将“天链二号01星”送入太{\ldots}  
        26390  今天是第28个全国税收宣传月的首日，今年的主题是“落实减税降费，促进经济高质量发展”。同样从{\ldots}  
        26391  国家副主席王岐山今天在中南海会见蒙古国外长朝格特巴特尔。王岐山表示，蒙古国是最早同新中国建交{\ldots}  
        26392  中共中央政治局常委、全国政协主席汪洋1日在京会见了由会长马志毅率领的澳区省级政协委员联谊会访{\ldots}  
        26393  各民主党派中央脱贫攻坚民主监督工作座谈会4月1日在京召开。中共中央政治局常委、全国政协主席汪{\ldots}  
        26394  欢迎仪式后，李克强同阿德恩举行会谈。李克强再次就新西兰前不久发生严重枪击事件造成重大人员伤亡{\ldots}  
        26395  1日上午，国务院总理李克强在北京人民大会堂举行仪式，欢迎新西兰总理阿德恩对我国进行正式访问。{\ldots}  
        26396  2019“中国—太平洋岛国旅游年”4月1日在萨摩亚首都阿皮亚开幕，国家主席习近平向开幕式致贺{\ldots}  
        26397  国家主席习近平1日在人民大会堂会见“元老会”代表团。习近平指出，世界正处于百年未有之大变局。{\ldots}  
        26398  国家主席习近平1日在人民大会堂会见新西兰总理阿德恩。习近平就新西兰不久前发生严重枪击事件再次{\ldots}  
        
        [100 rows x 4 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{Data2}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}        ts\_code  trade\_date  name     open      low     high    close  change  \textbackslash{}
        0       801010    20140401  农林牧渔  1668.75  1668.54  1689.12  1689.07   22.13   
        1       801010    20140402  农林牧渔  1688.72  1684.53  1693.41  1692.24    3.17   
        2       801010    20140403  农林牧渔  1693.05  1679.85  1697.73  1685.71   -6.53   
        3       801010    20140404  农林牧渔  1681.92  1680.34  1698.44  1698.25   12.54   
        4       801010    20140408  农林牧渔  1693.24  1692.22  1706.84  1706.84    8.59   
        5       801010    20140409  农林牧渔  1708.13  1707.49  1726.01  1725.55   18.71   
        6       801010    20140410  农林牧渔  1723.57  1721.18  1730.89  1725.67    0.12   
        7       801010    20140411  农林牧渔  1721.84  1713.55  1724.08  1719.15   -6.52   
        8       801010    20140414  农林牧渔  1718.35  1717.57  1751.81  1749.88   30.73   
        9       801010    20140415  农林牧渔  1747.73  1743.36  1758.92  1748.24   -1.64   
        10      801010    20140416  农林牧渔  1743.14  1743.07  1761.87  1759.88   11.64   
        11      801010    20140417  农林牧渔  1765.11  1751.34  1768.27  1751.95   -7.93   
        12      801010    20140418  农林牧渔  1747.78  1740.37  1749.27  1748.07   -3.88   
        13      801010    20140421  农林牧渔  1738.50  1721.93  1753.82  1723.44  -24.63   
        14      801010    20140422  农林牧渔  1719.55  1689.66  1726.53  1712.55  -10.89   
        15      801010    20140423  农林牧渔  1713.95  1704.45  1723.92  1708.59   -3.96   
        16      801010    20140424  农林牧渔  1705.93  1695.73  1711.51  1696.33  -12.26   
        17      801010    20140425  农林牧渔  1697.29  1664.62  1698.52  1665.01  -31.32   
        18      801010    20140428  农林牧渔  1659.78  1606.24  1660.02  1608.36  -56.65   
        19      801010    20140429  农林牧渔  1606.90  1606.45  1630.99  1630.56   22.20   
        20      801010    20140430  农林牧渔  1627.63  1620.66  1635.84  1634.53    3.97   
        21      801010    20140505  农林牧渔  1631.20  1627.64  1669.82  1669.82   35.29   
        22      801010    20140506  农林牧渔  1666.06  1665.70  1692.11  1687.83   18.01   
        23      801010    20140507  农林牧渔  1683.20  1663.34  1685.64  1664.49  -23.34   
        24      801010    20140508  农林牧渔  1662.49  1658.42  1683.17  1662.89   -1.60   
        25      801010    20140509  农林牧渔  1660.53  1633.00  1662.81  1647.72  -15.17   
        26      801010    20140512  农林牧渔  1657.54  1651.31  1682.60  1682.57   34.85   
        27      801010    20140513  农林牧渔  1683.43  1675.81  1690.56  1679.71   -2.86   
        28      801010    20140514  农林牧渔  1680.04  1678.35  1689.54  1687.06    7.35   
        29      801010    20140515  农林牧渔  1690.36  1667.12  1702.37  1668.01  -19.05   
        {\ldots}        {\ldots}         {\ldots}   {\ldots}      {\ldots}      {\ldots}      {\ldots}      {\ldots}     {\ldots}   
        39138   802600    20190219  交银装备  3579.18  3523.59  3592.14  3571.10    7.13   
        39139   802600    20190220  交银装备  3565.80  3530.05  3576.58  3573.88    2.78   
        39140   802600    20190221  交银装备  3570.03  3558.00  3647.76  3571.58   -2.30   
        39141   802600    20190222  交银装备  3564.22  3562.49  3667.00  3667.00   95.42   
        39142   802600    20190225  交银装备  3732.26  3731.09  3866.40  3865.52  198.52   
        39143   802600    20190226  交银装备  3878.98  3823.22  3935.83  3847.28  -18.24   
        39144   802600    20190227  交银装备  3834.98  3774.68  3880.18  3817.56  -29.72   
        39145   802600    20190228  交银装备  3819.39  3802.56  3853.09  3826.23    8.67   
        39146   802600    20190301  交银装备  3846.13  3795.75  3857.13  3857.13   30.90   
        39147   802600    20190304  交银装备  3900.97  3895.05  4001.73  3930.32   73.19   
        39148   802600    20190305  交银装备  3921.66  3907.79  4044.30  4044.30  113.98   
        39149   802600    20190306  交银装备  4073.73  4018.09  4110.34  4110.04   65.73   
        39150   802600    20190307  交银装备  4103.92  4073.72  4184.69  4146.26   36.22   
        39151   802600    20190308  交银装备  4049.63  4000.45  4180.26  4000.45 -145.81   
        39152   802600    20190311  交银装备  4038.47  4022.38  4167.05  4167.05  166.60   
        39153   802600    20190312  交银装备  4206.96  4185.74  4285.56  4259.90   92.85   
        39154   802600    20190313  交银装备  4257.71  4104.35  4257.71  4131.95 -127.95   
        39155   802600    20190314  交银装备  4095.09  3978.84  4122.73  4024.24 -107.71   
        39156   802600    20190315  交银装备  4047.72  4021.14  4102.95  4062.88   38.64   
        39157   802600    20190318  交银装备  4077.09  4035.28  4152.46  4152.46   89.58   
        39158   802600    20190319  交银装备  4154.04  4146.98  4206.74  4175.87   23.41   
        39159   802600    20190320  交银装备  4174.58  4091.01  4181.05  4161.25  -14.62   
        39160   802600    20190321  交银装备  4166.62  4158.46  4241.77  4209.20   47.95   
        39161   802600    20190322  交银装备  4212.52  4139.92  4223.43  4217.71    8.51   
        39162   802600    20190325  交银装备  4146.60  4134.48  4230.93  4178.99  -38.72   
        39163   802600    20190326  交银装备  4195.85  4054.34  4208.28  4062.73 -116.26   
        39164   802600    20190327  交银装备  4090.42  4002.09  4100.63  4072.08    9.35   
        39165   802600    20190328  交银装备  4058.84  4028.51  4116.58  4029.95  -42.13   
        39166   802600    20190329  交银装备  4030.42  3995.79  4145.43  4145.43  115.48   
        39167   802600    20190401  交银装备  4182.31  4182.25  4306.69  4306.27  160.84   
        
               pct\_change        vol      amount     pe    pb  y  
        0            1.33    34914.0    291113.0  41.51  2.77  1  
        1            0.19    36300.0    289020.0  41.63  2.79  1  
        2           -0.39    31403.0    259464.0  41.38  2.78  0  
        3            0.74    28648.0    240940.0  41.76  2.80  1  
        4            0.51    35012.0    312423.0  42.00  2.79  1  
        5            1.10    43114.0    378611.0  41.68  2.81  1  
        6            0.01    42089.0    386253.0  41.68  2.81  1  
        7           -0.38    33973.0    302877.0  41.38  2.80  0  
        8            1.79    45683.0    440762.0  42.11  2.86  1  
        9           -0.09    52524.0    482483.0  41.83  2.89  0  
        10           0.67    47387.0    415858.0  41.33  2.91  1  
        11          -0.45    39258.0    364281.0  41.19  2.89  0  
        12          -0.22    27658.0    250801.0  41.05  2.87  0  
        13          -1.41    34708.0    317704.0  40.55  2.84  0  
        14          -0.63    37810.0    350380.0  40.55  2.81  0  
        15          -0.23    29933.0    281126.0  40.72  2.80  0  
        16          -0.72    28072.0    263656.0  40.65  2.78  0  
        17          -1.85    36588.0    345842.0  39.63  2.73  0  
        18          -3.40    34912.0    308748.0  38.54  2.63  0  
        19           1.38    24681.0    217555.0  40.81  2.65  1  
        20           0.24    22190.0    200379.0  41.30  2.61  1  
        21           2.16    30320.0    309628.0  43.57  2.67  1  
        22           1.08    33004.0    352131.0  44.04  2.70  1  
        23          -1.38    29082.0    296894.0  43.43  2.66  0  
        24          -0.10    23884.0    235397.0  43.39  2.66  0  
        25          -0.91    22227.0    217123.0  42.99  2.63  0  
        26           2.12    31357.0    280848.0  44.03  2.68  1  
        27          -0.17    27356.0    261752.0  43.96  2.68  0  
        28           0.44    28557.0    274429.0  44.15  2.69  1  
        29          -1.13    34382.0    345523.0  43.66  2.66  0  
        {\ldots}           {\ldots}        {\ldots}         {\ldots}    {\ldots}   {\ldots} ..  
        39138        0.20  3830034.0  33069322.0  22.52  2.07  1  
        39139        0.08  3228623.0  27097884.0  22.60  2.07  1  
        39140       -0.06  3883750.0  34698806.0  22.58  2.07  0  
        39141        2.67  3641490.0  33151818.0  23.18  2.13  1  
        39142        5.41  5568265.0  51762223.0  24.43  2.24  1  
        39143       -0.47  5892699.0  54473918.0  24.33  2.23  0  
        39144       -0.77  4787456.0  43811779.0  24.12  2.22  0  
        39145        0.23  3731296.0  32883739.0  24.17  2.22  1  
        39146        0.81  3507033.0  31617194.0  24.37  2.24  1  
        39147        1.90  5295754.0  50696989.0  24.81  2.28  1  
        39148        2.90  5071454.0  48564822.0  25.51  2.35  1  
        39149        1.63  6102440.0  58035380.0  25.90  2.39  1  
        39150        0.88  5969744.0  58999917.0  26.09  2.41  1  
        39151       -3.52  6397305.0  63981639.0  25.19  2.32  0  
        39152        4.16  5248882.0  53541545.0  26.24  2.42  1  
        39153        2.23  6373095.0  65592259.0  26.84  2.47  1  
        39154       -3.00  5788780.0  60004033.0  26.03  2.40  0  
        39155       -2.61  4363434.0  43033723.0  25.37  2.33  0  
        39156        0.96  3734033.0  37227564.0  25.63  2.36  1  
        39157        2.20  3854941.0  38517998.0  26.20  2.41  1  
        39158        0.56  3873893.0  39344316.0  26.35  2.42  1  
        39159       -0.35  3899754.0  38579665.0  26.23  2.41  0  
        39160        1.15  4519727.0  44639328.0  26.53  2.44  1  
        39161        0.20  4111832.0  41501342.0  26.60  2.44  1  
        39162       -0.92  4151879.0  42732362.0  26.34  2.42  0  
        39163       -2.78  3998022.0  40950501.0  25.61  2.35  0  
        39164        0.23  3231654.0  33449356.0  25.71  2.36  1  
        39165       -1.03  3175370.0  34319281.0  25.46  2.33  0  
        39166        2.87  3671961.0  39397777.0  26.20  2.40  1  
        39167        3.88  4620338.0  51023180.0  27.22  2.49  1  
        
        [39168 rows x 14 columns]
\end{Verbatim}
            
    \subsection{二、文本处理阶段}\label{ux4e8cux6587ux672cux5904ux7406ux9636ux6bb5}

    \subsubsection{2.1 分词}\label{ux5206ux8bcd}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{re}
        \PY{k+kn}{import} \PY{n+nn}{jieba}
        
        
        \PY{k}{def} \PY{n+nf}{get\PYZus{}stopwords}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}获取停用词\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{stop\PYZus{}words} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{file} \PY{o+ow}{in} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./stopwords}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./stopwords/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{file}\PY{p}{)}\PY{p}{,}\PY{n}{encoding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
                    \PY{n}{stop\PYZus{}words}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{f}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{splitlines}\PY{p}{(}\PY{p}{)}\PY{p}{)}
            \PY{k}{return} \PY{n+nb}{set}\PY{p}{(}\PY{n}{stop\PYZus{}words}\PY{p}{)}
        
        \PY{n}{stop\PYZus{}words} \PY{o}{=} \PY{n}{get\PYZus{}stopwords}\PY{p}{(}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{clear\PYZus{}data}\PY{p}{(}\PY{n}{data}\PY{p}{,}\PY{n}{is\PYZus{}nan}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} 注意这里有nan数据}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}数据的清洗\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{k}{if} \PY{n}{data} \PY{o+ow}{is} \PY{n}{np}\PY{o}{.}\PY{n}{nan}\PY{p}{:}
                \PY{n}{data} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{is\PYZus{}nan} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}r}\PY{l+s+s1}{Here are }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ empty titles...}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{is\PYZus{}nan}\PY{p}{)}\PY{p}{,}\PY{n}{end}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[1\PYZhy{}9]+月[0\PYZhy{}9]+日至[0\PYZhy{}9]+日}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{(当地时间)*[0\PYZhy{}9]+日}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[1\PYZhy{}9]+月[0\PYZhy{}9]+日([上|下]午)*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[0\PYZhy{}9]+日([上|下]午)*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[0\PYZhy{}9]+时[0\PYZhy{}9]+分(许)*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{([0\PYZhy{}9]+日)*([上|下]午)*[0\PYZhy{}9]+时[0\PYZhy{}9]+分(许)*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[a\PYZhy{}zA\PYZhy{}Z0\PYZhy{}9]+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[,.，。、!:}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}\PYZsq{}}\PY{l+s+s1}{：《》【】’}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{‘“”)(（·）—]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{n}{data} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{s+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}
            \PY{k}{return} \PY{n}{data}
        
        \PY{k}{def} \PY{n+nf}{split\PYZus{}data}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}结巴分词\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{data} \PY{o}{=} \PY{n}{jieba}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} todo token的时候进行停用词的去除}
            \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{word} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{data} \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{stop\PYZus{}words} \PY{p}{]}
            
        \PY{c+c1}{\PYZsh{}     data =  \PYZsq{} \PYZsq{}.join(data) + \PYZsq{}\PYZbs{}n\PYZsq{}}
            \PY{k}{return} \PY{n}{data}
        
        \PY{k}{def} \PY{n+nf}{data\PYZus{}process}\PY{p}{(}\PY{n}{head}\PY{p}{,}\PY{n}{data}\PY{p}{,}\PY{n}{save\PYZus{}path}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}数据处理第一大部分\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{cleared} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{n}{head}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{clear\PYZus{}data}\PY{p}{)}
            \PY{n}{splited} \PY{o}{=} \PY{n}{cleared}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{split\PYZus{}data}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{splited}
        
        \PY{c+c1}{\PYZsh{}     with open(\PYZsq{}./\PYZob{}\PYZcb{}\PYZsq{}.format(save\PYZus{}path),\PYZsq{}w\PYZsq{},encoding=\PYZsq{}utf8\PYZsq{}) as f:}
        \PY{c+c1}{\PYZsh{}         f.writelines(splited\PYZus{}title)}
        \PY{c+c1}{\PYZsh{}         print(\PYZsq{}\PYZbs{}nTo \PYZob{}\PYZcb{} processed.\PYZsq{}.format(save\PYZus{}path))}
        
        \PY{c+c1}{\PYZsh{} 统计空title}
        \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./my\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./my\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{创建文件夹(}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{)成功}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/my\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                
            
        \PY{c+c1}{\PYZsh{} data\PYZus{}process(\PYZsq{}title\PYZsq{},save\PYZus{}path=\PYZsq{}./my\PYZus{}data/titles\PYZus{}split.txt\PYZsq{})}
        \PY{c+c1}{\PYZsh{} data\PYZus{}process(\PYZsq{}content\PYZsq{},save\PYZus{}path=\PYZsq{}./my\PYZus{}data/contents\PYZus{}split.txt\PYZsq{})}
\end{Verbatim}


    \subsubsection{2.2 word2idx \&\& idx2word}\label{word2idx-idx2word}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} 合并所有的数据}
        \PY{k}{def} \PY{n+nf}{concat\PYZus{}splited\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}整合词表以便统计单词\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{words} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./my\PYZus{}data/titles\PYZus{}split.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{encoding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
                \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{f}\PY{o}{.}\PY{n}{readlines}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                    \PY{n}{words}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{sent}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
        
            \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./my\PYZus{}data/contents\PYZus{}split.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{encoding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
                \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{f}\PY{o}{.}\PY{n}{readlines}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                    \PY{n}{words}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{sent}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                
            \PY{k}{return} \PY{n}{words}
        
        \PY{n}{data} \PY{o}{=} \PY{n}{concat\PYZus{}splited\PYZus{}data}\PY{p}{(}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{data}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{100}\PY{p}{:}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
['在', '发展', '对华关系', '方面', '多次', '领跑', '感到', '自豪', '我', '赞同', '习', '主席', '对', '两国关系', '的', '评价', '期待', '通过', '此访', '加强', '新中', '全面', '战略伙伴', '关系', '深化', '两', '国', '经贸合作', '和', '人文', '交流', '我愿', '重申', '新西兰', '坚持', '一个', '中国', '政策', '新西兰', '奉行', '独立自主', '的', '外交政策', '坚定', '支持', '多边', '主义', '支持', '自由贸易', '很', '早就', '支持', '一带', '一路', '倡议', '参加', '亚洲', '基础设施', '投资银行', '新西兰', '将', '派', '高级别', '代表团', '来华', '出席', '即将', '举行', '的', '第二届', '一带', '一路', '国际', '合作', '高峰论坛', '深化', '共建', '一带', '一路', '合作', '新方愿', '就', '应对', '气候变化', '等', '重大', '国际', '问题', '密切', '同', '中方', '的', '协调', '配合', '杨洁篪', '王毅', '何立峰', '等', '参加', '会见']

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
5914844

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
        \PY{k+kn}{import} \PY{n+nn}{os}
        
        \PY{k}{def} \PY{n+nf}{get\PYZus{}stopwords}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{n}{stop\PYZus{}words} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{file} \PY{o+ow}{in} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./stopwords}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./stopwords/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{file}\PY{p}{)}\PY{p}{,}\PY{n}{encoding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
                    \PY{n}{stop\PYZus{}words}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{f}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{splitlines}\PY{p}{(}\PY{p}{)}\PY{p}{)}
            \PY{k}{return} \PY{n+nb}{set}\PY{p}{(}\PY{n}{stop\PYZus{}words}\PY{p}{)}
        
        \PY{n}{stop\PYZus{}words} \PY{o}{=} \PY{n}{get\PYZus{}stopwords}\PY{p}{(}\PY{p}{)}
        \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{word} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{data} \PY{k}{if} \PY{n}{word} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{stop\PYZus{}words}\PY{p}{]}
        
        \PY{n}{counter} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{data}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{counter}\PY{p}{)}\PY{p}{)}
        \PY{n}{counter}\PY{o}{.}\PY{n}{most\PYZus{}common}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{90000}\PY{p}{:}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
124628

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:} [('芙蓉', 7),
         ('一首首', 7),
         ('矿坑', 7),
         ('胶囊', 7),
         ('毛驴', 7),
         ('黄孟复', 7),
         ('净化器', 7),
         ('服装品牌', 7),
         ('喀拉', 7),
         ('长河', 7),
         ('方案设计', 7),
         ('中国经贸', 7),
         ('发源', 7),
         ('青河县', 7),
         ('结核病', 7),
         ('全球战略', 7),
         ('葫芦岛市', 7),
         ('别具特色', 7),
         ('新时尚', 7),
         ('出岛', 7),
         ('精度高', 7),
         ('蔬果', 7),
         ('红外线', 7),
         ('跟得上', 7),
         ('唐古拉山', 7),
         ('推高', 7),
         ('应用领域', 7),
         ('棕榈', 7),
         ('结构复杂', 7),
         ('军品', 7),
         ('吴桥', 7),
         ('看电视', 7),
         ('地面站', 7),
         ('西溪', 7),
         ('戴尔', 7),
         ('海藻', 7),
         ('何炳南', 7),
         ('半天', 7),
         ('廖雪玲', 7),
         ('雁翅楼', 7),
         ('原则同意', 7),
         ('小孙', 7),
         ('西欧', 7),
         ('一个点', 7),
         ('美兰', 7),
         ('西安卫星测控中心', 7),
         ('皮埃尔', 7),
         ('北京航空航天大学', 7),
         ('首单', 7),
         ('宝贵意见', 7),
         ('青贮', 7),
         ('童话', 7),
         ('均等', 7),
         ('中国海关', 7),
         ('弯路', 7),
         ('韩俊', 7),
         ('洪小勇', 7),
         ('好帮手', 7),
         ('亲密无间', 7),
         ('显示器', 7),
         ('永年', 7),
         ('徐秀娟', 7),
         ('穆虹', 7),
         ('盖房子', 7),
         ('北京市政府', 7),
         ('金融管理', 7),
         ('通过考核', 7),
         ('央广', 7),
         ('不厌其烦', 7),
         ('莫兰', 7),
         ('三文鱼', 7),
         ('靠拢', 7),
         ('眼疾', 7),
         ('陈雷', 7),
         ('互动式', 7),
         ('人口众多', 7),
         ('效能型', 7),
         ('首钢', 7),
         ('复明', 7),
         ('却成', 7),
         ('姚檀栋', 7),
         ('穿山甲', 7),
         ('山花', 7),
         ('诺市', 7),
         ('莫中', 7),
         ('几万', 7),
         ('泰兴市', 7),
         ('布托', 7),
         ('尼方愿', 7),
         ('停驶', 7),
         ('阿济', 7),
         ('肺部', 7),
         ('弱冷空气', 7),
         ('保育', 7),
         ('走后门', 7),
         ('比达', 7),
         ('前十', 7),
         ('刘振民', 7),
         ('差率', 7),
         ('光环', 7),
         ('选优', 7),
         ('萨卡', 7),
         ('墓葬', 7),
         ('竹简', 7),
         ('互联网安全', 7),
         ('京台', 7),
         ('乱放', 7),
         ('澳门半岛', 7),
         ('闯过', 7),
         ('拉什', 7),
         ('大中专', 7),
         ('监督网', 7),
         ('遵从', 7),
         ('军是', 7),
         ('一年四季', 7),
         ('冰下', 7),
         ('保持一致', 7),
         ('敏锐性', 7),
         ('选段', 7),
         ('旁遮普邦', 7),
         ('苗家', 7),
         ('妈', 7),
         ('马扎里沙里夫', 7),
         ('时度效', 7),
         ('无中生有', 7),
         ('华大基因', 7),
         ('登峰', 7),
         ('冬闲', 7),
         ('逢节', 7),
         ('乌山', 7),
         ('麻怀村', 7),
         ('猛村', 7),
         ('镇安县', 7),
         ('尹本', 7),
         ('一开', 7),
         ('乞讨', 7),
         ('石泉县', 7),
         ('问效', 7),
         ('菊', 7),
         ('开拓精神', 7),
         ('边缘化', 7),
         ('心手', 7),
         ('冰期', 7),
         ('多颗', 7),
         ('贾尼', 7),
         ('宁陕县', 7),
         ('鲁冠球', 7),
         ('兽药', 7),
         ('新貌', 7),
         ('川陕', 7),
         ('年糕', 7),
         ('马化腾', 7),
         ('汽车销量', 7),
         ('茅坪', 7),
         ('号子', 7),
         ('至点', 7),
         ('桐城', 7),
         ('感受一下', 7),
         ('吉他', 7),
         ('开关', 7),
         ('十四个', 7),
         ('异乡', 7),
         ('完年', 7),
         ('爱因斯坦', 7),
         ('赏景', 7),
         ('锣鼓声', 7),
         ('讨价还价', 7),
         ('雪橇', 7),
         ('赵一立', 7),
         ('春来早', 7),
         ('眼瞅', 7),
         ('不具', 7),
         ('迎接挑战', 7),
         ('离婚', 7),
         ('两微', 7),
         ('拆旧', 7),
         ('西卢安', 7),
         ('多方位', 7),
         ('第二类', 7),
         ('抽样', 7),
         ('秦真岭', 7),
         ('禁渔', 7),
         ('格桑卓嘎', 7),
         ('庆丰', 7),
         ('比比', 7),
         ('黄羊', 7),
         ('修文', 7),
         ('陈先生', 7),
         ('刘士余', 7),
         ('斗殴', 7),
         ('亨利', 7),
         ('上海大学', 7),
         ('马蒂', 7),
         ('比尼', 7),
         ('拉姆齐', 7),
         ('服药', 7),
         ('入盟', 7),
         ('宜游', 7),
         ('客服', 7),
         ('小看', 7),
         ('走街串巷', 7),
         ('气象日', 7),
         ('民用机场', 7),
         ('每场', 7),
         ('百只', 7),
         ('托老所', 7),
         ('摊', 7),
         ('私宅', 7),
         ('道口', 7),
         ('冯德', 7),
         ('一法', 7),
         ('库什', 7),
         ('英国国防部', 7),
         ('王平', 7),
         ('挥锹', 7),
         ('巴库', 7),
         ('陨石', 7),
         ('充气式', 7),
         ('严守纪律', 7),
         ('投食', 7),
         ('屏山县', 7),
         ('黑木耳', 7),
         ('火山地震', 7),
         ('巡逻机', 7),
         ('灵敏度', 7),
         ('贩子', 7),
         ('揭榜', 7),
         ('政教', 7),
         ('工商业者', 7),
         ('百倍', 7),
         ('脚力', 7),
         ('笔力', 7),
         ('三宝', 7),
         ('惧怕', 7),
         ('员们', 7),
         ('慕名', 7),
         ('大上', 7),
         ('超冷', 7),
         ('个人收入', 7),
         ('试金石', 7),
         ('自治县', 7),
         ('实用性', 7),
         ('油管', 7),
         ('董绪伦', 7),
         ('刘贺', 7),
         ('于伟国', 7),
         ('公差', 7),
         ('伊斯坎德尔', 7),
         ('真信', 7),
         ('海之滨', 7),
         ('矿点', 7),
         ('二哥', 7),
         ('贞丰县', 7),
         ('指手画脚', 7),
         ('计算能力', 7),
         ('体育部', 7),
         ('闽粤', 7),
         ('云盘', 7),
         ('达维', 7),
         ('旧村', 7),
         ('坚冰', 7),
         ('冲日', 7),
         ('南京航空航天大学', 7),
         ('等离子体', 7),
         ('一小', 7),
         ('节日快乐', 7),
         ('王建军', 7),
         ('地学', 7),
         ('库琴斯', 7),
         ('水势', 7),
         ('欣然', 7),
         ('尼山', 7),
         ('北非国家', 7),
         ('长白山天池', 7),
         ('赛马节', 7),
         ('势不可挡', 7),
         ('同尼', 7),
         ('熔化', 7),
         ('泄露机密', 7),
         ('只身', 7),
         ('政策方针', 7),
         ('弹道', 7),
         ('阜宁县', 7),
         ('阿塔图尔克', 7),
         ('刘波', 7),
         ('暗夜', 7),
         ('肾', 7),
         ('自行设计', 7),
         ('对空', 7),
         ('古丈县', 7),
         ('奥运健儿', 7),
         ('联合国贸易和发展会议', 7),
         ('正说', 7),
         ('个人卫生', 7),
         ('前头', 7),
         ('唐山人', 7),
         ('亚当斯', 7),
         ('下到', 7),
         ('十余', 7),
         ('中国女篮', 7),
         ('集体承包', 7),
         ('律师协会', 7),
         ('华中科技大学', 7),
         ('共枚', 7),
         ('董栋', 7),
         ('刘洋', 7),
         ('俄伊', 7),
         ('任茜', 7),
         ('作伪证', 7),
         ('加塞', 7),
         ('同质', 7),
         ('霓虹', 7),
         ('中影', 7),
         ('值勤', 7),
         ('网红', 7),
         ('佩德罗', 7),
         ('巴杰', 7),
         ('万盏', 7),
         ('织造', 7),
         ('钣', 7),
         ('索尔兹伯里', 7),
         ('重大胜利', 7),
         ('一二', 7),
         ('周炳耀', 7),
         ('中华全国归国华侨联合会', 7),
         ('写票', 7),
         ('毕世华', 7),
         ('轨道舱', 7),
         ('新建村', 7),
         ('海法', 7),
         ('穹顶', 7),
         ('车灯', 7),
         ('以船', 7),
         ('冬笋', 7),
         ('媚俗', 7),
         ('清产核资', 7),
         ('这成', 7),
         ('烟草专卖局', 7),
         ('主动脉', 7),
         ('药箱', 7),
         ('东渡', 7),
         ('劳有所得', 7),
         ('阿姆里', 7),
         ('火险', 7),
         ('腊八节', 7),
         ('校准', 7),
         ('高田', 7),
         ('韦恩', 7),
         ('波拉', 7),
         ('硬脱', 7),
         ('电煤', 7),
         ('绥化', 7),
         ('一年之计在于春', 7),
         ('选情', 7),
         ('曲玉权', 7),
         ('耶茨', 7),
         ('德沃斯', 7),
         ('王帆', 7),
         ('长富', 7),
         ('开航', 7),
         ('罗维尔', 7),
         ('孤立主义', 7),
         ('衡阳县', 7),
         ('扶梯', 7),
         ('麦克马斯特', 7),
         ('密集区', 7),
         ('孟玲芬', 7),
         ('反舰', 7),
         ('初春', 7),
         ('天鲲', 7),
         ('李林', 7),
         ('刘昆作', 7),
         ('埃特纳', 7),
         ('藕', 7),
         ('泰典', 7),
         ('金世富', 7),
         ('还贷', 7),
         ('刘赐贵', 7),
         ('中程导弹', 7),
         ('颇丰', 7),
         ('金平', 7),
         ('武雯', 7),
         ('之母', 7),
         ('彼得森', 7),
         ('卡留', 7),
         ('安哲秀', 7),
         ('车俊', 7),
         ('丝胶', 7),
         ('官厅水库', 7),
         ('残渣', 7),
         ('爱国运动', 7),
         ('企联', 7),
         ('国之志', 7),
         ('朱雨玲', 7),
         ('皇马', 7),
         ('过海', 7),
         ('委要', 7),
         ('呈递', 7),
         ('孙志刚', 7),
         ('包钢', 7),
         ('提审', 7),
         ('彩云', 7),
         ('葵花籽', 7),
         ('九寨', 7),
         ('杨道', 7),
         ('李鲁帅', 7),
         ('采沉区', 7),
         ('叶卡捷琳堡', 7),
         ('靓靓', 7),
         ('留抵', 7),
         ('斯托克', 7),
         ('第二架', 7),
         ('张彦', 7),
         ('洋山', 7),
         ('曹先建', 7),
         ('傅政华', 7),
         ('二十大', 7),
         ('阿罗约', 7),
         ('曲巴', 7),
         ('萨阿德', 7),
         ('武文赏', 7),
         ('宋迪', 7),
         ('阿根廷海军', 7),
         ('艇员', 7),
         ('图布辛', 7),
         ('中导', 7),
         ('投标法', 7),
         ('监察权', 7),
         ('不骛于', 7),
         ('虚声', 7),
         ('陈果', 7),
         ('维阿', 7),
         ('蓝花', 7),
         ('上朝', 7),
         ('辛庄村', 7),
         ('正常率', 7),
         ('自然段', 7),
         ('溶', 7),
         ('王银香', 7),
         ('选举票', 7),
         ('几比', 7),
         ('达达埃', 7),
         ('拔高', 7),
         ('马斯', 7),
         ('黄花岗', 7),
         ('同盟会', 7),
         ('刘鹤何', 7),
         ('因伊核', 7),
         ('秋分', 7),
         ('兰特', 7),
         ('扇贝', 7),
         ('共兴', 7),
         ('同萨方', 7),
         ('郭宗俊', 7),
         ('艾沙', 7),
         ('博索', 7),
         ('渔歌', 7),
         ('白格', 7),
         ('戈恩', 7),
         ('埃斯库', 7),
         ('德罗', 7),
         ('西娅', 7),
         ('鲍尔', 7),
         ('邱娥国', 7),
         ('钟竹筠', 7),
         ('邮车', 7),
         ('哨点', 7),
         ('北极熊', 7),
         ('杨忠岐', 7),
         ('狼窝', 7),
         ('贾永青', 6),
         ('新关角', 6),
         ('四百多', 6),
         ('优先股', 6),
         ('国家能源委员会', 6),
         ('祭品', 6),
         ('黑金', 6),
         ('生聚', 6),
         ('黎介寿', 6),
         ('唱主角', 6),
         ('做点', 6),
         ('田阳', 6),
         ('反贪', 6),
         ('造谣', 6),
         ('唐述', 6),
         ('滚动式', 6),
         ('京外', 6),
         ('延坪岛', 6),
         ('神农', 6),
         ('兴疆', 6),
         ('招远', 6),
         ('礼泉', 6),
         ('蒙阴', 6),
         ('冠', 6),
         ('明晨', 6),
         ('开球', 6),
         ('阿旺', 6),
         ('年度预算', 6),
         ('郝龙斌', 6),
         ('毕世祥', 6),
         ('杨瑞辉', 6),
         ('纳米材料', 6),
         ('正反', 6),
         ('玷污', 6),
         ('红柳', 6),
         ('针线包', 6),
         ('绝杀', 6),
         ('澎湖', 6),
         ('舍己救人', 6),
         ('好学', 6),
         ('澳门中华总商会', 6),
         ('蔡秀梅', 6),
         ('金凤', 6),
         ('深得人心', 6),
         ('随礼', 6),
         ('哲学家', 6),
         ('同饮', 6),
         ('医联', 6),
         ('两袖清风', 6),
         ('江红', 6),
         ('陈榕', 6),
         ('韩媒', 6),
         ('葛', 6),
         ('同享', 6),
         ('机关化', 6),
         ('始终不变', 6),
         ('尉犁县', 6),
         ('鸣警', 6),
         ('新民党', 6),
         ('获枚', 6),
         ('勤政为民', 6),
         ('误', 6),
         ('工联', 6),
         ('湾仔', 6),
         ('纠纷案件', 6),
         ('辈出', 6),
         ('无穷的', 6),
         ('汉风', 6),
         ('生化武器', 6),
         ('影视界', 6),
         ('摘要', 6),
         ('秋色', 6),
         ('俄木', 6),
         ('根本大法', 6),
         ('年本', 6),
         ('金埃', 6),
         ('槟榔', 6),
         ('柳青', 6),
         ('煤检站', 6),
         ('前前后后', 6),
         ('小官', 6),
         ('免予', 6),
         ('为强', 6),
         ('周四', 6),
         ('十五届', 6),
         ('共融', 6),
         ('朝鲜人', 6),
         ('十二月', 6),
         ('论为', 6),
         ('长青', 6),
         ('变通途', 6),
         ('犬瘟热', 6),
         ('陈锡联', 6),
         ('淡泊', 6),
         ('贡山独龙族怒族自治县', 6),
         ('正举', 6),
         ('抗埃', 6),
         ('坠河', 6),
         ('雅尔塔', 6),
         ('独臂', 6),
         ('仍有', 6),
         ('惩', 6),
         ('毕加索', 6),
         ('聂', 6),
         ('第四十二', 6),
         ('热议习', 6),
         ('如期而至', 6),
         ('禽肉', 6),
         ('盗窃案', 6),
         ('真枪', 6),
         ('电击', 6),
         ('朝霞', 6),
         ('李影超', 6),
         ('重装', 6),
         ('吕榕麟', 6),
         ('陪审员', 6),
         ('减肥', 6),
         ('美国黑人', 6),
         ('保水', 6),
         ('允展', 6),
         ('臂膀', 6),
         ('谨防', 6),
         ('鲁先平', 6),
         ('赖远明', 6),
         ('海防部队', 6),
         ('外向型', 6),
         ('崇明', 6),
         ('冷用斌', 6),
         ('肃宁县', 6),
         ('用爱', 6),
         ('红艳', 6),
         ('细毛羊', 6),
         ('增来', 6),
         ('惠建林', 6),
         ('文献片', 6),
         ('罗丹', 6),
         ('南培', 6),
         ('铁面', 6),
         ('深切关怀', 6),
         ('勇救', 6),
         ('反对声', 6),
         ('车轮下', 6),
         ('幼童', 6),
         ('终', 6),
         ('入企', 6),
         ('对令', 6),
         ('赴藏', 6),
         ('二十六', 6),
         ('薄雾', 6),
         ('盗', 6),
         ('存亡', 6),
         ('一齐', 6),
         ('获年', 6),
         ('读万卷书', 6),
         ('狭路相逢', 6),
         ('试吃', 6),
         ('扬长补短', 6),
         ('国际品牌', 6),
         ('金质', 6),
         ('永存', 6),
         ('王书平', 6),
         ('人革', 6),
         ('二营', 6),
         ('世界大赛', 6),
         ('区域系统', 6),
         ('租赁业', 6),
         ('共推', 6),
         ('联大会议', 6),
         ('匾', 6),
         ('主教', 6),
         ('美国微软公司', 6),
         ('授奖仪式', 6),
         ('江家', 6),
         ('促进会', 6),
         ('抒情', 6),
         ('致癌物', 6),
         ('十七次', 6),
         ('祖孙', 6),
         ('巨幕', 6),
         ('冲锋号', 6),
         ('土司', 6),
         ('开普敦', 6),
         ('心贴心', 6),
         ('永久中立', 6),
         ('一滴', 6),
         ('平邑', 6),
         ('吕敬', 6),
         ('权威人士', 6),
         ('开发式', 6),
         ('紧固件', 6),
         ('以营', 6),
         ('捡漏', 6),
         ('立心', 6),
         ('探险', 6),
         ('北医三院', 6),
         ('思乡', 6),
         ('创效', 6),
         ('方毅', 6),
         ('法立', 6),
         ('干货', 6),
         ('坦诚相见', 6),
         ('一团', 6),
         ('春花', 6),
         ('抗议声', 6),
         ('踏春', 6),
         ('家暴', 6),
         ('芦', 6),
         ('人人有责', 6),
         ('返回式', 6),
         ('远山', 6),
         ('杀菌剂', 6),
         ('云岭', 6),
         ('刘沙', 6),
         ('水法', 6),
         ('迪士尼', 6),
         ('王阳', 6),
         ('减上', 6),
         ('补下', 6),
         ('杨金龙', 6),
         ('改玉', 6),
         ('先声', 6),
         ('中共中央台办', 6),
         ('祝词', 6),
         ('中国芯', 6),
         ('必问', 6),
         ('目', 6),
         ('颗粒归仓', 6),
         ('美一', 6),
         ('润', 6),
         ('星星之火', 6),
         ('公司律师', 6),
         ('宜居城市', 6),
         ('访塞', 6),
         ('首获', 6),
         ('势均力敌', 6),
         ('拉纳', 6),
         ('费米子', 6),
         ('安格', 6),
         ('商运', 6),
         ('傅企平', 6),
         ('永立', 6),
         ('志在', 6),
         ('倾泻', 6),
         ('长七', 6),
         ('搅局', 6),
         ('百科全书', 6),
         ('灌顶', 6),
         ('多起', 6),
         ('百花园', 6),
         ('马兰', 6),
         ('毒气弹', 6),
         ('赛时', 6),
         ('陈人海', 6),
         ('超万人', 6),
         ('银两', 6),
         ('补钙', 6),
         ('金三银', 6),
         ('苏州高新区', 6),
         ('礼服', 6),
         ('挪穷', 6),
         ('美誉度', 6),
         ('公学', 6),
         ('世民', 6),
         ('国际标准化组织', 6),
         ('相思', 6),
         ('民族魂', 6),
         ('林阿不列', 6),
         ('诺贝尔物理学奖', 6),
         ('高峰会', 6),
         ('第七十九', 6),
         ('语', 6),
         ('冷少农', 6),
         ('认真负责', 6),
         ('第八十', 6),
         ('释法', 6),
         ('天涯若比邻', 6),
         ('寸步难行', 6),
         ('一身正气', 6),
         ('战地', 6),
         ('忘我', 6),
         ('潮州', 6),
         ('拳拳', 6),
         ('苏知斌', 6),
         ('肖文智', 6),
         ('捷报频传', 6),
         ('治税', 6),
         ('拐卖妇女', 6),
         ('新航', 6),
         ('破难', 6),
         ('奔忙', 6),
         ('纯属', 6),
         ('仪封', 6),
         ('溜', 6),
         ('骡马', 6),
         ('恭贺', 6),
         ('边防战士', 6),
         ('冰点', 6),
         ('多伤', 6),
         ('治穷', 6),
         ('电波', 6),
         ('采油厂', 6),
         ('德军', 6),
         ('容缺', 6),
         ('国安', 6),
         ('称以', 6),
         ('侨心', 6),
         ('第五十四', 6),
         ('外汇局', 6),
         ('涉腐', 6),
         ('突显', 6),
         ('带回去', 6),
         ('领保', 6),
         ('第九十', 6),
         ('三假', 6),
         ('查核', 6),
         ('安全线', 6),
         ('水清岸', 6),
         ('城市更新', 6),
         ('书海', 6),
         ('六十八', 6),
         ('这行', 6),
         ('圣多美', 6),
         ('树人德法', 6),
         ('之门', 6),
         ('六场', 6),
         ('倾情', 6),
         ('菲政府', 6),
         ('闽台', 6),
         ('冷板凳', 6),
         ('村小', 6),
         ('油溪桥', 6),
         ('立新', 6),
         ('省籍', 6),
         ('新磨村', 6),
         ('第六十九', 6),
         ('浓烈', 6),
         ('朔', 6),
         ('以向', 6),
         ('徐嘉余', 6),
         ('第六十二', 6),
         ('建绿', 6),
         ('七论', 6),
         ('颜值', 6),
         ('破坏者', 6),
         ('鸡西', 6),
         ('展示会', 6),
         ('丹心', 6),
         ('击水', 6),
         ('谦虚谨慎', 6),
         ('臭氧层', 6),
         ('先扶志', 6),
         ('之四', 6),
         ('再发', 6),
         ('项俊波', 6),
         ('受控', 6),
         ('聘任制', 6),
         ('逐梦新', 6),
         ('八十', 6),
         ('之火', 6),
         ('胡福明', 6),
         ('恰是', 6),
         ('喘', 6),
         ('玛霍索', 6),
         ('乾坤', 6),
         ('米林县', 6),
         ('苍穹', 6),
         ('少数派', 6),
         ('宇宙线', 6),
         ('叶笃初', 6),
         ('北段', 6),
         ('首绘', 6),
         ('策划者', 6),
         ('法德英', 6),
         ('以色列国', 6),
         ('新课程', 6),
         ('油船', 6),
         ('苏皖', 6),
         ('快步', 6),
         ('窦店', 6),
         ('首堆', 6),
         ('科右', 6),
         ('亏', 6),
         ('晴空', 6),
         ('通俄', 6),
         ('万紫千红', 6),
         ('阿婆', 6),
         ('撤职处分', 6),
         ('多得', 6),
         ('温敏', 6),
         ('三颗', 6),
         ('机群', 6),
         ('固防', 6),
         ('以身许国', 6),
         ('法学院', 6),
         ('小村', 6),
         ('拥枪', 6),
         ('施洋', 6),
         ('五卅运动', 6),
         ('丰田', 6),
         ('站立起来', 6),
         ('实证', 6),
         ('李培东', 6),
         ('潮涌', 6),
         ('文泰', 6),
         ('经略', 6),
         ('龙州', 6),
         ('仲夏', 6),
         ('月央企', 6),
         ('牛犇', 6),
         ('张人亚', 6),
         ('十六强', 6),
         ('奇葩', 6),
         ('遮', 6),
         ('尼雷尔', 6),
         ('单边制裁', 6),
         ('侵扰', 6),
         ('之名', 6),
         ('蓝标河', 6),
         ('部约', 6),
         ('热射病', 6),
         ('风生水', 6),
         ('美新', 6),
         ('百枚', 6),
         ('熊雄', 6),
         ('蒋先云', 6),
         ('以变', 6),
         ('雷霆', 6),
         ('锦春', 6),
         ('五分', 6),
         ('中卫市', 6),
         ('隋维钧', 6),
         ('杜梅', 6),
         ('大管家', 6),
         ('勇当', 6),
         ('乳源', 6),
         ('混', 6),
         ('柳传志', 6),
         ('海洋卫星', 6),
         ('塔里木', 6),
         ('冯平', 6),
         ('不怕死', 6),
         ('灯火', 6),
         ('探馆', 6),
         ('要敢', 6),
         ('招商银行', 6),
         ('俞昌准', 6),
         ('陇', 6),
         ('企业顾问', 6),
         ('中俄印', 6),
         ('病防治', 6),
         ('万水千山', 6),
         ('中华魂', 6),
         ('生态化', 6),
         ('辞别', 6),
         ('吴光浩', 6),
         ('神木', 6),
         ('媒', 6),
         ('卡塔尔国', 6),
         ('夜行', 6),
         ('地名', 6),
         ('陈大香', 6),
         ('九牧', 6),
         ('理论修养', 6),
         ('修炼', 6),
         ('第二十六', 6),
         ('像素', 6),
         ('鲁班', 6),
         ('打兵', 6),
         ('戈尔', 6),
         ('婚姻家庭', 6),
         ('举证', 6),
         ('中学校长', 6),
         ('追根溯源', 6),
         ('纪工委', 6),
         ('赶回来', 6),
         ('最佳时机', 6),
         ('近况', 6),
         ('近条', 6),
         ('真诚地', 6),
         ('晴好', 6),
         ('医务室', 6),
         ('出工', 6),
         ('西格', 6),
         ('期求', 6),
         ('行车时间', 6),
         ('颜料', 6),
         ('彩塑', 6),
         ('爱情故事', 6),
         ('拟制', 6),
         ('网吧', 6),
         ('小册子', 6),
         ('深学', 6),
         ('手机卡', 6),
         ('万向', 6),
         ('挎包', 6),
         ('城南', 6),
         ('终点线', 6),
         ('拒绝执行', 6),
         ('华语', 6),
         ('捏造事实', 6),
         ('后能', 6),
         ('脑部', 6),
         ('住院病人', 6),
         ('重新启动', 6),
         ('一男一女', 6),
         ('弃船', 6),
         ('乳山', 6),
         ('分管领导', 6),
         ('外省', 6),
         ('民事纠纷', 6),
         ('每期', 6),
         ('工商局', 6),
         ('接待费', 6),
         ('数为', 6),
         ('财政拨款', 6),
         ('涉密', 6),
         ('中国农业银行', 6),
         ('特长生', 6),
         ('愧疚', 6),
         ('死后', 6),
         ('风筝会', 6),
         ('广汉', 6),
         ('飞行速度', 6),
         ('放慢', 6),
         ('惦记', 6),
         ('伤疤', 6),
         ('情侣', 6),
         ('右眼', 6),
         ('出站口', 6),
         ('一亿人次', 6),
         {\ldots}]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}增加 \PYZlt{}PAD\PYZgt{} 和 \PYZlt{}UNK\PYZgt{} 标记\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{n}{words} \PY{o}{=} \PY{p}{[}\PY{n}{word}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{counter}\PY{o}{.}\PY{n}{most\PYZus{}common}\PY{p}{(}\PY{l+m+mi}{24630}\PY{p}{)}\PY{p}{]}
        \PY{n}{words}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{words}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}UNK\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k+kn}{import} \PY{n+nn}{pickle}
         
         \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}保存词表\PYZsq{}\PYZsq{}\PYZsq{}}
         \PY{n}{idx2word} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{words}\PY{p}{)}\PY{p}{)}
         \PY{n}{word2idx} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{word}\PY{p}{:}\PY{n}{idx} \PY{k}{for} \PY{n}{idx}\PY{p}{,}\PY{n}{word} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{words}\PY{p}{)}\PY{p}{\PYZcb{}}
         
         \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
             \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models/word2idx.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
             \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{word2idx}\PY{p}{,}\PY{n}{f}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} word2idx saved.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models/idx2word.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
             \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{idx2word}\PY{p}{,}\PY{n}{f}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} idx2word saved.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\# word2idx saved.
\# idx2word saved.

    \end{Verbatim}

    \subsubsection{2.3 token the words}\label{token-the-words}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} 确定seq\PYZus{}len}
         
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
         \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{norm}
         
         \PY{k}{def} \PY{n+nf}{calc\PYZus{}length}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}观察长度的分布图像确定最佳的seq\PYZus{}max\PYZsq{}\PYZsq{}\PYZsq{}}
             \PY{k}{if} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n+nb}{str}\PY{p}{)}\PY{p}{:}
                 \PY{k}{return} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{k}{return} \PY{l+m+mi}{0}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{Data1}\PY{o}{.}\PY{n}{title}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{clear\PYZus{}data}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x} \PY{p}{:} \PY{n}{jieba}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{,}\PY{n}{fit}\PY{o}{=}\PY{n}{norm}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{len(title)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{Data1}\PY{o}{.}\PY{n}{content}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{clear\PYZus{}data}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x} \PY{p}{:} \PY{n}{jieba}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{,}\PY{n}{fit}\PY{o}{=}\PY{n}{norm}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{len(content)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Here are 1 empty titles{\ldots}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Building prefix dict from the default dictionary {\ldots}
Loading model from cache C:\textbackslash{}Users\textbackslash{}liao\textbackslash{}AppData\textbackslash{}Local\textbackslash{}Temp\textbackslash{}jieba.cache
Loading model cost 0.739 seconds.
Prefix dict has been built succesfully.
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}scipy\textbackslash{}stats\textbackslash{}stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Here are 1 empty titles{\ldots}
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subparagraph{由上图可知，把contnet长度确定在800处 、title的长度在30处
比较合理的,}\label{ux7531ux4e0aux56feux53efux77e5ux628acontnetux957fux5ea6ux786eux5b9aux5728800ux5904-titleux7684ux957fux5ea6ux572830ux5904-ux6bd4ux8f83ux5408ux7406ux7684}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         
         \PY{k}{def} \PY{n+nf}{padding}\PY{p}{(}\PY{n}{titles}\PY{p}{,}\PY{n}{contents}\PY{p}{,}\PY{n}{word2idx}\PY{p}{,}\PY{n}{seq\PYZus{}len\PYZus{}content}\PY{o}{=}\PY{l+m+mi}{2000}\PY{p}{,}\PY{n}{seq\PYZus{}len\PYZus{}title}\PY{o}{=}\PY{l+m+mi}{40}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}对数据进行token及padding操作\PYZsq{}\PYZsq{}\PYZsq{}}
             \PY{n}{input\PYZus{}x\PYZus{}titles} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{input\PYZus{}x\PYZus{}contents} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             
             \PY{k}{for} \PY{n}{title} \PY{o+ow}{in} \PY{n}{titles}\PY{p}{:}
                 \PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{n}{word2idx}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{word}\PY{p}{,}\PY{n}{word2idx}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}UNK\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{title}\PY{p}{]}
                 \PY{n}{sent\PYZus{}len} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{tmp}\PY{p}{)}
                 \PY{k}{if} \PY{n}{sent\PYZus{}len} \PY{o}{\PYZgt{}} \PY{n}{seq\PYZus{}len\PYZus{}title}\PY{p}{:}
                     \PY{n}{tmp} \PY{o}{=} \PY{n}{tmp}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{40}\PY{p}{]}
                     
                 \PY{k}{else}\PY{p}{:}
                     \PY{n}{tmp}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{p}{[}\PY{n}{word2idx}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{seq\PYZus{}len\PYZus{}title} \PY{o}{\PYZhy{}} \PY{n}{sent\PYZus{}len}\PY{p}{)}\PY{p}{]}\PY{p}{)}
                 \PY{n}{input\PYZus{}x\PYZus{}titles}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tmp}\PY{p}{)}
                 
             \PY{k}{for} \PY{n}{content} \PY{o+ow}{in} \PY{n}{contents}\PY{p}{:}
                 \PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{n}{word2idx}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{word}\PY{p}{,}\PY{n}{word2idx}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}UNK\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{content}\PY{p}{]}
                 \PY{n}{sent\PYZus{}len} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{tmp}\PY{p}{)}
                 \PY{k}{if} \PY{n}{sent\PYZus{}len} \PY{o}{\PYZgt{}} \PY{n}{seq\PYZus{}len\PYZus{}content}\PY{p}{:}
                     \PY{n}{tmp} \PY{o}{=} \PY{n}{tmp}\PY{p}{[}\PY{p}{:}\PY{n}{seq\PYZus{}len\PYZus{}content}\PY{p}{]}
                     
                 \PY{k}{else}\PY{p}{:}
                     \PY{n}{tmp}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{p}{[}\PY{n}{word2idx}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{seq\PYZus{}len\PYZus{}content} \PY{o}{\PYZhy{}} \PY{n}{sent\PYZus{}len}\PY{p}{)}\PY{p}{]}\PY{p}{)}
                 \PY{n}{input\PYZus{}x\PYZus{}contents}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tmp}\PY{p}{)}
         
             \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{[}\PY{n}{input\PYZus{}x\PYZus{}titles}\PY{p}{,}\PY{n}{input\PYZus{}x\PYZus{}contents}\PY{p}{]}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{token}\PY{p}{(}\PY{n}{titles}\PY{p}{,}\PY{n}{contents}\PY{p}{,}\PY{n}{word2idx}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}数据的处理及padding\PYZsq{}\PYZsq{}\PYZsq{}}
             \PY{n}{data\PYZus{}titles} \PY{o}{=} \PY{n}{titles}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{clear\PYZus{}data}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x} \PY{p}{:} \PY{n}{jieba}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}
             \PY{n}{data\PYZus{}contents} \PY{o}{=} \PY{n}{contents}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{clear\PYZus{}data}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{jieba}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}
             \PY{n}{X} \PY{o}{=} \PY{n}{padding}\PY{p}{(}\PY{n}{data\PYZus{}titles}\PY{p}{,}\PY{n}{data\PYZus{}contents}\PY{p}{,}\PY{n}{word2idx}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{X}
         
         \PY{n}{X} \PY{o}{=} \PY{n}{token}\PY{p}{(}\PY{n}{Data1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{Data1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{content}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{word2idx}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Here are 1 empty titles{\ldots}
    \end{Verbatim}

    \subsubsection{2.4 word2vec}\label{word2vec}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{models}\PY{n+nn}{.}\PY{n+nn}{word2vec} \PY{k}{import} \PY{n}{Word2Vec}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{TfidfVectorizer}
        \PY{k+kn}{from} \PY{n+nn}{multiprocessing} \PY{k}{import} \PY{n}{cpu\PYZus{}count}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pickle}
        
        
        \PY{k}{def} \PY{n+nf}{get\PYZus{}word2vec}\PY{p}{(}\PY{n}{data}\PY{p}{,}\PY{n}{n\PYZus{}dims}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,}\PY{n}{w2v\PYZus{}path}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models/w2v\PYZus{}model.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}进行word2vec模型的获取\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{w2v\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsh{} Train the word2vec }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                \PY{n}{core\PYZus{}count} \PY{o}{=} \PY{n}{cpu\PYZus{}count}\PY{p}{(}\PY{p}{)}
                \PY{n}{w2v} \PY{o}{=} \PY{n}{Word2Vec}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{n}{n\PYZus{}dims}\PY{p}{,}\PY{n}{min\PYZus{}count}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,}\PY{n}{workers}\PY{o}{=}\PY{n}{core\PYZus{}count}\PY{p}{)}
                \PY{n}{w2v}\PY{o}{.}\PY{n}{build\PYZus{}vocab}\PY{p}{(}\PY{n}{data}\PY{p}{)}
                \PY{n}{w2v}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{data}\PY{p}{,}\PY{n}{total\PYZus{}examples}\PY{o}{=}\PY{n}{w2v}\PY{o}{.}\PY{n}{corpus\PYZus{}count}\PY{p}{,}\PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{128}\PY{p}{)}
                \PY{n}{w2v}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{w2v\PYZus{}path}\PY{p}{)}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} Finish train the word2vec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{w2v} \PY{o}{=} \PY{n}{Word2Vec}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n}{w2v\PYZus{}path}\PY{p}{)}
                
            
            \PY{k}{return} \PY{n}{w2v}
        
        \PY{k}{def} \PY{n+nf}{get\PYZus{}tf\PYZus{}idf}\PY{p}{(}\PY{n}{data}\PY{p}{,}\PY{n}{model\PYZus{}path}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models/tf\PYZus{}idf\PYZus{}model.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}进行tfidf模型的获取\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{model\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{n}{tf\PYZus{}model} \PY{o}{=} \PY{n}{TfidfVectorizer}\PY{p}{(}\PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}\PY{n}{token\PYZus{}pattern}\PY{o}{=}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{(?u)}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{w+}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                \PY{n}{tf\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data}\PY{p}{)}
                \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{tf\PYZus{}model}\PY{p}{,}\PY{n+nb}{open}\PY{p}{(}\PY{n}{model\PYZus{}path}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} Finish train the Tf\PYZhy{}idf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{tf\PYZus{}model} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{n}{model\PYZus{}path}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{tf\PYZus{}model}
        
        \PY{k}{def} \PY{n+nf}{build\PYZus{}tfidf\PYZus{}vec}\PY{p}{(}\PY{n}{sent}\PY{p}{,}\PY{n}{tfidf}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}获取tfidf向量\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{k}{return} \PY{n}{tfidf}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{p}{[}\PY{n}{sent}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        
        
        \PY{k}{def} \PY{n+nf}{build\PYZus{}word\PYZus{}vec}\PY{p}{(}\PY{n}{sent}\PY{p}{,}\PY{n}{w2v}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}获取word2vec向量\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{vec} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{sent}\PY{p}{:}
                \PY{k}{try}\PY{p}{:}
                    \PY{n}{vec}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{w2v}\PY{p}{[}\PY{n}{word}\PY{p}{]}\PY{p}{)}
                \PY{k}{except}\PY{p}{:}
                    \PY{n}{vec}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{200}\PY{p}{)}\PY{p}{)}
            \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{vec}\PY{p}{)} \PY{o}{!=} \PY{l+m+mi}{0}\PY{p}{:}
                \PY{n}{vec} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{vec}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{vec} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{l+m+mi}{200}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{vec}
        
        
        \PY{k}{def} \PY{n+nf}{convert2vec}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}    
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}把处理后的文本转换成向量\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}注意：再使用word2vec的时候split\PYZus{}data和使用tfidf的时候方法里面需要进行就该，split\PYZus{}data函数使用tfidf时加入代码\PYZdq{} \PYZdq{}.join(data) \PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{c+c1}{\PYZsh{}\PYZsh{} word2vec  }
            \PY{n}{tmp1} \PY{o}{=} \PY{n}{data\PYZus{}process}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n+nb}{list}\PY{p}{)}
            \PY{n}{tmp2} \PY{o}{=} \PY{n}{data\PYZus{}process}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{content}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n+nb}{list}\PY{p}{)}
            \PY{n}{data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{content}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
            \PY{n}{w2v} \PY{o}{=} \PY{n}{get\PYZus{}word2vec}\PY{p}{(}\PY{n}{tmp1} \PY{o}{+} \PY{n}{tmp2}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{}\PYZsh{} tf\PYZhy{}idf   }
        \PY{c+c1}{\PYZsh{}     tmp1 = data\PYZus{}process(\PYZsq{}title\PYZsq{},data)}
        \PY{c+c1}{\PYZsh{}     tmp2 = data\PYZus{}process(\PYZsq{}content\PYZsq{},data)}
        \PY{c+c1}{\PYZsh{}     tfidf = get\PYZus{}tf\PYZus{}idf(tmp1 + tmp1)}
            
            \PY{n}{tmp\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{200}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{int}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{ceil}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{tmp1} \PY{o}{+} \PY{n}{tmp2}\PY{p}{)} \PY{o}{/} \PY{n}{tmp\PYZus{}size}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                \PY{n}{tmp1}\PY{p}{[}\PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size}\PY{p}{:} \PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size} \PY{o}{+} \PY{n}{tmp\PYZus{}size}\PY{p}{]} \PY{o}{=} \PY{n}{tmp1}\PY{p}{[}\PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size}\PY{p}{:} \PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size} \PY{o}{+} \PY{n}{tmp\PYZus{}size}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{build\PYZus{}word\PYZus{}vec}\PY{p}{,}\PY{n}{args}\PY{o}{=}\PY{p}{(}\PY{n}{w2v}\PY{p}{,}\PY{p}{)}\PY{p}{)}
                \PY{n}{tmp2}\PY{p}{[}\PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size}\PY{p}{:} \PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size} \PY{o}{+} \PY{n}{tmp\PYZus{}size}\PY{p}{]} \PY{o}{=} \PY{n}{tmp2}\PY{p}{[}\PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size} \PY{p}{:}\PY{n}{i} \PY{o}{*} \PY{n}{tmp\PYZus{}size} \PY{o}{+} \PY{n}{tmp\PYZus{}size}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{build\PYZus{}word\PYZus{}vec}\PY{p}{,}\PY{n}{args}\PY{o}{=}\PY{p}{(}\PY{n}{w2v}\PY{p}{,}\PY{p}{)}\PY{p}{)}
                
        \PY{c+c1}{\PYZsh{}         tmp1[i * tmp\PYZus{}size: i * tmp\PYZus{}size + tmp\PYZus{}size] = tmp1[i * tmp\PYZus{}size: i * tmp\PYZus{}size + tmp\PYZus{}size].apply(build\PYZus{}tfidf\PYZus{}vec,args=(tfidf,))}
        \PY{c+c1}{\PYZsh{}         tmp2[i * tmp\PYZus{}size: i * tmp\PYZus{}size + tmp\PYZus{}size] = tmp2[i * tmp\PYZus{}size :i * tmp\PYZus{}size + tmp\PYZus{}size].apply(build\PYZus{}tfidf\PYZus{}vec,args=(tfidf,))}
            
        \PY{c+c1}{\PYZsh{}     data[\PYZsq{}allVec\PYZsq{}] = list(np.concatenate([list(tmp1),list(tmp2)],axis=1))  \PYZsh{} 这里转换成list再存进df}
            \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{[}\PY{n+nb}{list}\PY{p}{(}\PY{n}{tmp1}\PY{p}{)}\PY{p}{,}\PY{n+nb}{list}\PY{p}{(}\PY{n}{tmp2}\PY{p}{)}\PY{p}{]}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} 这里转换成list再存进df}
        
            \PY{n}{sum\PYZus{}vec} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{p}{)}
            \PY{n}{count\PYZus{}vec} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            
            \PY{n}{sum\PYZus{}vec}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{sum\PYZus{}vec}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{n}{count\PYZus{}vec}
            
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} Finish build word\PYZus{}vec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{sum\PYZus{}vec}
        
        \PY{n}{new\PYZus{}data} \PY{o}{=} \PY{n}{convert2vec}\PY{p}{(}\PY{n}{Data1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}gensim\textbackslash{}utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize\_serial
  warnings.warn("detected Windows; aliasing chunkize to chunkize\_serial")

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Here are 1 empty titles{\ldots}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Building prefix dict from the default dictionary {\ldots}
Loading model from cache C:\textbackslash{}Users\textbackslash{}liao\textbackslash{}AppData\textbackslash{}Local\textbackslash{}Temp\textbackslash{}jieba.cache
Loading model cost 0.765 seconds.
Prefix dict has been built succesfully.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Here are 1 empty titles{\ldots}
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:46: DeprecationWarning: Call to deprecated `\_\_getitem\_\_` (Method will be removed in 4.0.0, use self.wv.\_\_getitem\_\_() instead).

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\# Finish build word\_vec

    \end{Verbatim}

    \subsubsection{2.5
合并一天对应一段时间10天内的数据(必要去除train\_set开头与test\_set的末尾一部分数据再做组合验证数据)}\label{ux5408ux5e76ux4e00ux5929ux5bf9ux5e94ux4e00ux6bb5ux65f6ux95f410ux5929ux5185ux7684ux6570ux636eux5fc5ux8981ux53bbux9664train_setux5f00ux5934ux4e0etest_setux7684ux672bux5c3eux4e00ux90e8ux5206ux6570ux636eux518dux505aux7ec4ux5408ux9a8cux8bc1ux6570ux636e}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{new\PYZus{}data}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:}                  date                                             allVec
         date                                                                    
         2014-04-14 2014-04-14  [0.06317358290155729, 0.43262030531962714, -0{\ldots}
         2014-04-15 2014-04-15  [-0.1878579319221899, 0.06973273736657576, -0{\ldots}
         2014-04-16 2014-04-16  [-0.07485291386644045, 0.07098943205481326, -0{\ldots}
         2014-04-17 2014-04-17  [-0.18737137507414445, -0.0876698462292552, -0{\ldots}
         2014-04-18 2014-04-18  [0.052207767883724075, -0.6337272375423639, -0{\ldots}
         2014-04-19 2014-04-19  [0.3185145132361896, -0.4371863577574019, -0.6{\ldots}
         2014-04-20 2014-04-20  [-0.1160324103475272, -0.49018933321093466, -0{\ldots}
         2014-04-21 2014-04-21  [0.21492725891225478, -0.2824603892424527, -0{\ldots}
         2014-04-22 2014-04-22  [0.11055358188730993, -0.01651803932729223, -0{\ldots}
         2014-04-23 2014-04-23  [0.2789467494668705, -0.20326825696974993, -0{\ldots}
         2014-04-24 2014-04-24  [0.2319015884869977, 0.40526491674153425, -0.4{\ldots}
         2014-04-25 2014-04-25  [-0.21469083944698683, -0.22129782234385076, -{\ldots}
         2014-04-26 2014-04-26  [0.245105941840891, -0.47111576946363565, -0.0{\ldots}
         2014-04-27 2014-04-27  [0.12406243034638464, -0.25139506079722196, -0{\ldots}
         2014-04-28 2014-04-28  [0.08236550566028146, -0.3728565445900256, -0{\ldots}
         2014-04-29 2014-04-29  [-0.20064894533833535, -0.3332128195772095, -0{\ldots}
         2014-04-30 2014-04-30  [0.010440887036648664, 0.007233017547564073, -{\ldots}
         2014-05-01 2014-05-01  [-0.08968028926523403, -0.36635966882109644, 0{\ldots}
         2014-05-02 2014-05-02  [0.16242664886845484, -0.6231746909519037, -0{\ldots}
         2014-05-03 2014-05-03  [-0.10046919034077571, -0.5014296925793855, -0{\ldots}
         2014-05-04 2014-05-04  [0.46871524144496235, -0.25603435511168626, -0{\ldots}
         2014-05-05 2014-05-05  [0.03161852844793068, -0.16087545233704742, -0{\ldots}
         2014-05-06 2014-05-06  [-0.18779879225486962, 0.40200529468280294, -0{\ldots}
         2014-05-07 2014-05-07  [-0.0033269312349148094, 0.26320724195490286, {\ldots}
         2014-05-08 2014-05-08  [-0.0116067118629688, 0.07190808885488188, -0{\ldots}
         2014-05-09 2014-05-09  [0.3222431540489197, -0.18174753757193685, 0.0{\ldots}
         2014-05-10 2014-05-10  [-0.4086331130388905, 0.03841691363383742, -0{\ldots}
         2014-05-11 2014-05-11  [-0.22461932771524093, -0.017055863164421314, {\ldots}
         2014-05-12 2014-05-12  [-0.009486113353209065, -0.08427692524750124, {\ldots}
         2014-05-13 2014-05-13  [0.08071086666028171, 0.30901424428888824, -0{\ldots}
         {\ldots}               {\ldots}                                                {\ldots}
         2019-03-03 2019-03-03  [-0.2020006664097309, -0.11363947745412588, 0{\ldots}
         2019-03-04 2019-03-04  [-0.03988091216275567, -0.11202058627417213, 0{\ldots}
         2019-03-05 2019-03-05  [-0.20344245977818018, 0.7372373402828262, 0.6{\ldots}
         2019-03-06 2019-03-06  [-0.2465901678078808, -0.09947523940354586, 0{\ldots}
         2019-03-07 2019-03-07  [-0.7913894275617268, 1.004884098139074, 1.398{\ldots}
         2019-03-08 2019-03-08  [-0.47105524020598216, 0.3232247809715131, 0.8{\ldots}
         2019-03-09 2019-03-09  [0.15557727054692805, 0.42383681843057275, 1.2{\ldots}
         2019-03-10 2019-03-10  [0.13728358570693266, -0.12430853696746963, 0{\ldots}
         2019-03-11 2019-03-11  [0.34189128239328664, -0.17620940615112582, 0{\ldots}
         2019-03-12 2019-03-12  [-0.09236960698451314, 0.10829498880498466, 0{\ldots}
         2019-03-13 2019-03-13  [-0.06382871922865815, 0.05267816135773854, 0{\ldots}
         2019-03-14 2019-03-14  [-0.054967357660643756, -0.45509158493950963, {\ldots}
         2019-03-15 2019-03-15  [0.046129180578624494, 0.10269019399203506, 0{\ldots}
         2019-03-16 2019-03-16  [0.031253376327179096, 0.11078477711589248, 0{\ldots}
         2019-03-17 2019-03-17  [0.17994708114561916, -0.3953890476516691, -0{\ldots}
         2019-03-18 2019-03-18  [-0.3490238786839387, -0.529447498238262, 0.04{\ldots}
         2019-03-19 2019-03-19  [0.011133174101511637, -0.003462909658749898, {\ldots}
         2019-03-20 2019-03-20  [-0.4041741090662339, -0.29064978702979927, 0{\ldots}
         2019-03-21 2019-03-21  [0.11162909699810873, -0.09217680143537345, 0{\ldots}
         2019-03-22 2019-03-22  [0.004055563100230168, -0.10558473274988286, -{\ldots}
         2019-03-23 2019-03-23  [-0.27142128306219265, 0.35459551073255996, -0{\ldots}
         2019-03-24 2019-03-24  [-0.28013465725458586, 0.45258940297823685, -0{\ldots}
         2019-03-25 2019-03-25  [-0.5653454885400253, 0.3382759407573475, -0.1{\ldots}
         2019-03-26 2019-03-26  [0.13403566082318624, 0.10535221497217814, -0{\ldots}
         2019-03-27 2019-03-27  [-0.1512569575325439, 0.48190362571755, -0.033{\ldots}
         2019-03-28 2019-03-28  [0.1946971543236739, 0.005427229735586379, -0{\ldots}
         2019-03-29 2019-03-29  [0.06450071040954855, -0.1656143127511891, -0{\ldots}
         2019-03-30 2019-03-30  [0.24856407248548099, -0.23959227601940533, -0{\ldots}
         2019-03-31 2019-03-31  [0.13668648449656293, -0.07084936810991702, 0{\ldots}
         2019-04-01 2019-04-01  [0.27238404506645286, 0.2541276776709226, -0.1{\ldots}
         
         [1814 rows x 2 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        
        \PY{n}{Data2}\PY{o}{.}\PY{n}{y} \PY{o}{=} \PY{n}{Data2}\PY{o}{.}\PY{n}{y}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{str}\PY{p}{)}
        \PY{n}{Data2}\PY{o}{.}\PY{n}{trade\PYZus{}date} \PY{o}{=} \PY{n}{Data2}\PY{o}{.}\PY{n}{trade\PYZus{}date}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{str}\PY{p}{)}
        
        \PY{n}{Data} \PY{o}{=} \PY{n}{Data2}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{name}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trade\PYZus{}date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trade\PYZus{}date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{p}{)}
        \PY{n}{Data}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{n}{Data}\PY{o}{.}\PY{n}{trade\PYZus{}date}\PY{p}{,}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        
        \PY{n}{new\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{to\PYZus{}datetime}\PY{p}{(}\PY{n}{new\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n+nb}{format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{new\PYZus{}data}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{n}{new\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{}  把对应的过去一段时间内10天的数据合并进第一个表}
        \PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{k+kc}{None}
        
        \PY{k}{for} \PY{n}{date} \PY{o+ow}{in} \PY{n}{Data}\PY{o}{.}\PY{n}{index}\PY{p}{:}
            \PY{n}{temp\PYZus{}data} \PY{o}{=} \PY{n}{new\PYZus{}data}\PY{o}{.}\PY{n}{truncate}\PY{p}{(}\PY{n}{after}\PY{o}{=}\PY{n}{date}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{20}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{10}\PY{p}{]}
            \PY{n}{Data}\PY{o}{.}\PY{n}{set\PYZus{}value}\PY{p}{(}\PY{n}{date}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{temp\PYZus{}data}\PY{o}{.}\PY{n}{allVec}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} 去除不完整数据}
        \PY{n}{Data} \PY{o}{=} \PY{n}{Data}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:6: FutureWarning: set\_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead
  

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{new\PYZus{}data}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:}                  date                                             allVec
        date                                                                    
        2014-04-14 2014-04-14  [0.06317358290155729, 0.43262030531962714, -0{\ldots}
        2014-04-15 2014-04-15  [-0.1878579319221899, 0.06973273736657576, -0{\ldots}
        2014-04-16 2014-04-16  [-0.07485291386644045, 0.07098943205481326, -0{\ldots}
        2014-04-17 2014-04-17  [-0.18737137507414445, -0.0876698462292552, -0{\ldots}
        2014-04-18 2014-04-18  [0.052207767883724075, -0.6337272375423639, -0{\ldots}
        2014-04-19 2014-04-19  [0.3185145132361896, -0.4371863577574019, -0.6{\ldots}
        2014-04-20 2014-04-20  [-0.1160324103475272, -0.49018933321093466, -0{\ldots}
        2014-04-21 2014-04-21  [0.21492725891225478, -0.2824603892424527, -0{\ldots}
        2014-04-22 2014-04-22  [0.11055358188730993, -0.01651803932729223, -0{\ldots}
        2014-04-23 2014-04-23  [0.2789467494668705, -0.20326825696974993, -0{\ldots}
        2014-04-24 2014-04-24  [0.2319015884869977, 0.40526491674153425, -0.4{\ldots}
        2014-04-25 2014-04-25  [-0.21469083944698683, -0.22129782234385076, -{\ldots}
        2014-04-26 2014-04-26  [0.245105941840891, -0.47111576946363565, -0.0{\ldots}
        2014-04-27 2014-04-27  [0.12406243034638464, -0.25139506079722196, -0{\ldots}
        2014-04-28 2014-04-28  [0.08236550566028146, -0.3728565445900256, -0{\ldots}
        2014-04-29 2014-04-29  [-0.20064894533833535, -0.3332128195772095, -0{\ldots}
        2014-04-30 2014-04-30  [0.010440887036648664, 0.007233017547564073, -{\ldots}
        2014-05-01 2014-05-01  [-0.08968028926523403, -0.36635966882109644, 0{\ldots}
        2014-05-02 2014-05-02  [0.16242664886845484, -0.6231746909519037, -0{\ldots}
        2014-05-03 2014-05-03  [-0.10046919034077571, -0.5014296925793855, -0{\ldots}
        2014-05-04 2014-05-04  [0.46871524144496235, -0.25603435511168626, -0{\ldots}
        2014-05-05 2014-05-05  [0.03161852844793068, -0.16087545233704742, -0{\ldots}
        2014-05-06 2014-05-06  [-0.18779879225486962, 0.40200529468280294, -0{\ldots}
        2014-05-07 2014-05-07  [-0.0033269312349148094, 0.26320724195490286, {\ldots}
        2014-05-08 2014-05-08  [-0.0116067118629688, 0.07190808885488188, -0{\ldots}
        2014-05-09 2014-05-09  [0.3222431540489197, -0.18174753757193685, 0.0{\ldots}
        2014-05-10 2014-05-10  [-0.4086331130388905, 0.03841691363383742, -0{\ldots}
        2014-05-11 2014-05-11  [-0.22461932771524093, -0.017055863164421314, {\ldots}
        2014-05-12 2014-05-12  [-0.009486113353209065, -0.08427692524750124, {\ldots}
        2014-05-13 2014-05-13  [0.08071086666028171, 0.30901424428888824, -0{\ldots}
        {\ldots}               {\ldots}                                                {\ldots}
        2019-03-03 2019-03-03  [-0.2020006664097309, -0.11363947745412588, 0{\ldots}
        2019-03-04 2019-03-04  [-0.03988091216275567, -0.11202058627417213, 0{\ldots}
        2019-03-05 2019-03-05  [-0.20344245977818018, 0.7372373402828262, 0.6{\ldots}
        2019-03-06 2019-03-06  [-0.2465901678078808, -0.09947523940354586, 0{\ldots}
        2019-03-07 2019-03-07  [-0.7913894275617268, 1.004884098139074, 1.398{\ldots}
        2019-03-08 2019-03-08  [-0.47105524020598216, 0.3232247809715131, 0.8{\ldots}
        2019-03-09 2019-03-09  [0.15557727054692805, 0.42383681843057275, 1.2{\ldots}
        2019-03-10 2019-03-10  [0.13728358570693266, -0.12430853696746963, 0{\ldots}
        2019-03-11 2019-03-11  [0.34189128239328664, -0.17620940615112582, 0{\ldots}
        2019-03-12 2019-03-12  [-0.09236960698451314, 0.10829498880498466, 0{\ldots}
        2019-03-13 2019-03-13  [-0.06382871922865815, 0.05267816135773854, 0{\ldots}
        2019-03-14 2019-03-14  [-0.054967357660643756, -0.45509158493950963, {\ldots}
        2019-03-15 2019-03-15  [0.046129180578624494, 0.10269019399203506, 0{\ldots}
        2019-03-16 2019-03-16  [0.031253376327179096, 0.11078477711589248, 0{\ldots}
        2019-03-17 2019-03-17  [0.17994708114561916, -0.3953890476516691, -0{\ldots}
        2019-03-18 2019-03-18  [-0.3490238786839387, -0.529447498238262, 0.04{\ldots}
        2019-03-19 2019-03-19  [0.011133174101511637, -0.003462909658749898, {\ldots}
        2019-03-20 2019-03-20  [-0.4041741090662339, -0.29064978702979927, 0{\ldots}
        2019-03-21 2019-03-21  [0.11162909699810873, -0.09217680143537345, 0{\ldots}
        2019-03-22 2019-03-22  [0.004055563100230168, -0.10558473274988286, -{\ldots}
        2019-03-23 2019-03-23  [-0.27142128306219265, 0.35459551073255996, -0{\ldots}
        2019-03-24 2019-03-24  [-0.28013465725458586, 0.45258940297823685, -0{\ldots}
        2019-03-25 2019-03-25  [-0.5653454885400253, 0.3382759407573475, -0.1{\ldots}
        2019-03-26 2019-03-26  [0.13403566082318624, 0.10535221497217814, -0{\ldots}
        2019-03-27 2019-03-27  [-0.1512569575325439, 0.48190362571755, -0.033{\ldots}
        2019-03-28 2019-03-28  [0.1946971543236739, 0.005427229735586379, -0{\ldots}
        2019-03-29 2019-03-29  [0.06450071040954855, -0.1656143127511891, -0{\ldots}
        2019-03-30 2019-03-30  [0.24856407248548099, -0.23959227601940533, -0{\ldots}
        2019-03-31 2019-03-31  [0.13668648449656293, -0.07084936810991702, 0{\ldots}
        2019-04-01 2019-04-01  [0.27238404506645286, 0.2541276776709226, -0.1{\ldots}
        
        [1814 rows x 2 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{Data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:}            trade\_date                                   y  \textbackslash{}
        trade\_date                                                  
        20140424     20140424  0100000000000100000000000000001000   
        20140425     20140425  0000000000000000000000000000010000   
        20140428     20140428  0000000000000000000000000000000000   
        20140429     20140429  1111111111111011111111111111111111   
        20140430     20140430  1011010111111011111111111111100111   
        
                                                               allVec  
        trade\_date                                                     
        20140424    [0.06317358290155729, 0.43262030531962714, -0{\ldots}  
        20140425    [-0.06234217451031631, 0.2511765213431014, -0{\ldots}  
        20140428    [-0.0669401740154987, -0.029610921806120617, -{\ldots}  
        20140429    [-0.0026977261402173123, -0.09754016113133417,{\ldots}  
        20140430    [-0.018888395312690154, -0.1536328999998485, -{\ldots}  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{def} \PY{n+nf}{fix\PYZus{}y\PYZus{}1}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}处理y值成格式1\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{k}{def} \PY{n+nf}{map\PYZus{}f}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
                \PY{k}{if} \PY{n}{x} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                    \PY{k}{return} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
                \PY{k}{else}\PY{p}{:}
                    \PY{k}{return} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
            \PY{k}{return} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n}{map\PYZus{}f}\PY{p}{,}\PY{n}{y}\PY{p}{)}\PY{p}{)}
            
        \PY{k}{def} \PY{n+nf}{fix\PYZus{}y\PYZus{}2}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}处理y值成格式2\PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{n}{labels} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                \PY{k}{if} \PY{n}{y}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                    \PY{n}{labels}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{i}\PY{p}{)}
            \PY{k}{return} \PY{n}{labels}
        
        \PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n+nb}{int}\PY{p}{,}\PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  对数据进行适当的排版
\item
  word2vec向量化
\item
  过去5天的word2vec合并的到向量
\item
  使用到过去5天部分的stack数据
\item
  构建LSTM网络进行预测
\item
  softmax进行多分类的概率输出，使用cross\_entropy进行多分类的概率输出
\end{enumerate}

    \subsubsection{val\_data
数据集的构建}\label{val_data-ux6570ux636eux96c6ux7684ux6784ux5efa}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{pre\PYZus{}date} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{20190402}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{20190403}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{20190404}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{20190408}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{20190409}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{k}{def} \PY{n+nf}{set\PYZus{}val\PYZus{}data}\PY{p}{(}\PY{n}{date\PYZus{}list}\PY{p}{,}\PY{n}{new\PYZus{}data}\PY{p}{)}\PY{p}{:}
             \PY{n}{val\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{index}\PY{o}{=}\PY{n}{pre\PYZus{}date}\PY{p}{)}
         
             \PY{k}{for} \PY{n}{date} \PY{o+ow}{in} \PY{n}{date\PYZus{}list}\PY{p}{:}
                 \PY{n}{temp\PYZus{}data} \PY{o}{=} \PY{n}{new\PYZus{}data}\PY{o}{.}\PY{n}{truncate}\PY{p}{(}\PY{n}{before}\PY{o}{=}\PY{l+m+mi}{20190402}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{20}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{10}\PY{p}{]}
                 \PY{n}{val\PYZus{}data}\PY{o}{.}\PY{n}{set\PYZus{}value}\PY{p}{(}\PY{n}{date}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{temp\PYZus{}data}\PY{o}{.}\PY{n}{allVec}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{val\PYZus{}data}
         
         \PY{n}{val\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{]}\PY{p}{:}
             \PY{n}{val\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{new\PYZus{}data}\PY{o}{.}\PY{n}{allVec}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{20} \PY{o}{+} \PY{n}{i}\PY{p}{:} \PY{o}{\PYZhy{}}\PY{l+m+mi}{10} \PY{o}{+} \PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{val\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{val\PYZus{}data}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:}         0         1         2         3         4         5         6    \textbackslash{}
         0  0.075507 -0.320794  0.276342 -0.329421  0.424764  0.600995  0.306627   
         1  0.052452 -0.188885  0.153269 -0.363884  0.396031  0.535677  0.285108   
         2 -0.027414 -0.136584  0.085760 -0.407716  0.353459  0.536137  0.263683   
         3  0.018558  0.054269  0.015327 -0.495508  0.221508  0.586908  0.343249   
         4  0.101556  0.049912 -0.091650 -0.364659  0.118718  0.541568  0.252173   
         
                 7         8         9      {\ldots}          190       191       192  \textbackslash{}
         0 -0.165874 -0.399119  0.012200    {\ldots}     0.290867 -0.295676 -0.305748   
         1 -0.083379 -0.267617 -0.117902    {\ldots}     0.274767 -0.290852 -0.217000   
         2 -0.065369 -0.175194 -0.097996    {\ldots}     0.300956 -0.268377 -0.244627   
         3 -0.035499 -0.073718 -0.135872    {\ldots}     0.470499 -0.189278 -0.285506   
         4 -0.083627 -0.055401 -0.137156    {\ldots}     0.464896 -0.154338 -0.281979   
         
                 193       194       195       196       197       198       199  
         0  0.311399 -0.109803  0.298839  1.260910 -0.043404  0.059408 -0.907341  
         1  0.262200 -0.041643  0.397983  1.349095 -0.145328  0.148178 -0.903176  
         2  0.246943  0.052092  0.460955  1.336976 -0.127951  0.195492 -0.928511  
         3  0.289240  0.187289  0.329051  1.466203 -0.280283  0.302277 -0.988963  
         4  0.243603  0.031188  0.216902  1.467225 -0.176486  0.336783 -0.936390  
         
         [5 rows x 200 columns]
\end{Verbatim}
            
    \subsection{三、模型构建}\label{ux4e09ux6a21ux578bux6784ux5efa}

    \subsubsection{3.1
机器学习模型尝试}\label{ux673aux5668ux5b66ux4e60ux6a21ux578bux5c1dux8bd5}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{input\PYZus{}y}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:} array([0, 0, 0, {\ldots}, 0, 1, 1])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{multiclass} \PY{k}{import} \PY{n}{OneVsRestClassifier}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LogisticRegressionCV}\PY{p}{,}\PY{n}{LogisticRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
         
         
         
         \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n}{input\PYZus{}y}\PY{p}{,}\PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PY{n}{train\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{128}\PY{p}{)}
         
         \PY{n}{ss} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
         \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
         \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{Cs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{logspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{7}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Cs = np.linspace(0.0012,0.0008,10)}
         \PY{n}{Cs} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.001}\PY{p}{]}
         
         \PY{n}{model\PYZus{}lr} \PY{o}{=} \PY{n}{LogisticRegressionCV}\PY{p}{(}\PY{n}{Cs}\PY{p}{,}\PY{n}{penalty}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{roc\PYZus{}auc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{dual}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{solver}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{liblinear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{multi\PYZus{}class}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ovr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
         \PY{n}{model\PYZus{}lr}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}17}]:} LogisticRegressionCV(Cs=[0.001], class\_weight=None, cv=10, dual=True,
                    fit\_intercept=True, intercept\_scaling=1.0, max\_iter=100,
                    multi\_class='ovr', n\_jobs=None, penalty='l2', random\_state=None,
                    refit=True, scoring='roc\_auc', solver='liblinear', tol=0.0001,
                    verbose=0)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         
         \PY{n}{len\PYZus{}cs} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{Cs}\PY{p}{)}
         \PY{n}{score} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{model\PYZus{}lr}\PY{o}{.}\PY{n}{scores\PYZus{}}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best C:}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{model\PYZus{}lr}\PY{o}{.}\PY{n}{C\PYZus{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{Cs}\PY{p}{,}\PY{n}{score}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
          
         \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
         \PY{l+s+sd}{0:0.0069}
         \PY{l+s+sd}{1：0.001}
         \PY{l+s+sd}{2:0.0001}
         \PY{l+s+sd}{3:0.0008}
         \PY{l+s+sd}{4:0.001}
         \PY{l+s+sd}{5:0.0004}
         \PY{l+s+sd}{6:0.01}
         \PY{l+s+sd}{7:1e\PYZhy{}7}
         \PY{l+s+sd}{8:1e\PYZhy{}6}
         \PY{l+s+sd}{9:0.001}
         \PY{l+s+sd}{10:1e\PYZhy{}7}
         \PY{l+s+sd}{11:1e\PYZhy{}7}
         \PY{l+s+sd}{12:1e\PYZhy{}7}
         \PY{l+s+sd}{13:0.0001}
         \PY{l+s+sd}{14:0.0008}
         \PY{l+s+sd}{15:0.001}
         \PY{l+s+sd}{16:0.001}
         \PY{l+s+sd}{17:1e\PYZhy{}7}
         \PY{l+s+sd}{18:1e\PYZhy{}8}
         \PY{l+s+sd}{19:0.001}
         \PY{l+s+sd}{20:}
         \PY{l+s+sd}{21:1e\PYZhy{}4}
         \PY{l+s+sd}{22:1e\PYZhy{}8}
         \PY{l+s+sd}{23:1e\PYZhy{}8}
         \PY{l+s+sd}{24:1e\PYZhy{}8}
         \PY{l+s+sd}{25:0.001}
         \PY{l+s+sd}{26:0.001}
         \PY{l+s+sd}{27:0.001}
         \PY{l+s+sd}{28:0.001}
         \PY{l+s+sd}{29:183.298}
         \PY{l+s+sd}{30:}
         \PY{l+s+sd}{31:0.001}
         \PY{l+s+sd}{32:0.001}
         \PY{l+s+sd}{33:0.001}
         \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
\end{Verbatim}


    
    \begin{verbatim}
<Figure size 640x480 with 1 Axes>
    \end{verbatim}

    
\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} '\textbackslash{}n0:0.0069\textbackslash{}n1：0.001\textbackslash{}n2:0.0001\textbackslash{}n3:0.0008\textbackslash{}n4:0.001\textbackslash{}n5:0.0004\textbackslash{}n6:0.01\textbackslash{}n7:1e-7\textbackslash{}n8:1e-6\textbackslash{}n9:0.001\textbackslash{}n10:1e-7\textbackslash{}n11:1e-7\textbackslash{}n12:1e-7\textbackslash{}n13:0.0001\textbackslash{}n14:0.0008\textbackslash{}n15:0.001\textbackslash{}n16:0.001\textbackslash{}n17:1e-7\textbackslash{}n18:1e-8\textbackslash{}n19:0.001\textbackslash{}n20:\textbackslash{}n21:1e-4\textbackslash{}n22:1e-8\textbackslash{}n23:1e-8\textbackslash{}n24:1e-8\textbackslash{}n25:0.001\textbackslash{}n26:0.001\textbackslash{}n27:0.001\textbackslash{}n28:0.001\textbackslash{}n29:183.298\textbackslash{}n30:\textbackslash{}n31:0.001\textbackslash{}n32:0.001\textbackslash{}n33:0.001\textbackslash{}n'
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}\PY{p}{,}\PY{n}{roc\PYZus{}auc\PYZus{}score}
         
         \PY{n}{y\PYZus{}train\PYZus{}pred} \PY{o}{=} \PY{n}{model\PYZus{}lr}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
         \PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{=} \PY{n}{model\PYZus{}lr}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} print(\PYZsq{}\PYZsh{} accuracy score in train : \PYZob{}\PYZcb{}\PYZsq{}.format(accuracy\PYZus{}score(y\PYZus{}train\PYZus{}pred,y\PYZus{}train)))}
         \PY{c+c1}{\PYZsh{} print(\PYZsq{}\PYZsh{} accuracy score in test : \PYZob{}\PYZcb{}\PYZsq{}.format(accuracy\PYZus{}score(y\PYZus{}test\PYZus{}pred,y\PYZus{}test)))}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} auc score in train : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train\PYZus{}pred}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} auc score in test : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,}\PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        ValueError                                Traceback (most recent call last)

        <ipython-input-20-25bc3a1b4c7f> in <module>
          6 \# print('\# accuracy score in train : \{\}'.format(accuracy\_score(y\_train\_pred,y\_train)))
          7 \# print('\# accuracy score in test : \{\}'.format(accuracy\_score(y\_test\_pred,y\_test)))
    ----> 8 print('\# auc score in train : \{\}'.format(roc\_auc\_score(y\_train,y\_train\_pred)))
          9 print('\# auc score in test : \{\}'.format(roc\_auc\_score(y\_test,y\_test\_pred)))
    

        D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}ranking.py in roc\_auc\_score(y\_true, y\_score, average, sample\_weight, max\_fpr)
        354     return \_average\_binary\_score(
        355         \_binary\_roc\_auc\_score, y\_true, y\_score, average,
    --> 356         sample\_weight=sample\_weight)
        357 
        358 
    

        D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}base.py in \_average\_binary\_score(binary\_metric, y\_true, y\_score, average, sample\_weight)
         75 
         76     if y\_type == "binary":
    ---> 77         return binary\_metric(y\_true, y\_score, sample\_weight=sample\_weight)
         78 
         79     check\_consistent\_length(y\_true, y\_score, sample\_weight)
    

        D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}ranking.py in \_binary\_roc\_auc\_score(y\_true, y\_score, sample\_weight)
        326 
        327         fpr, tpr, \_ = roc\_curve(y\_true, y\_score,
    --> 328                                 sample\_weight=sample\_weight)
        329         if max\_fpr is None or max\_fpr == 1:
        330             return auc(fpr, tpr)
    

        D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}ranking.py in roc\_curve(y\_true, y\_score, pos\_label, sample\_weight, drop\_intermediate)
        616     """
        617     fps, tps, thresholds = \_binary\_clf\_curve(
    --> 618         y\_true, y\_score, pos\_label=pos\_label, sample\_weight=sample\_weight)
        619 
        620     \# Attempt to drop thresholds corresponding to points in between and
    

        D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}metrics\textbackslash{}ranking.py in \_binary\_clf\_curve(y\_true, y\_score, pos\_label, sample\_weight)
        399     check\_consistent\_length(y\_true, y\_score, sample\_weight)
        400     y\_true = column\_or\_1d(y\_true)
    --> 401     y\_score = column\_or\_1d(y\_score)
        402     assert\_all\_finite(y\_true)
        403     assert\_all\_finite(y\_score)
    

        D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}utils\textbackslash{}validation.py in column\_or\_1d(y, warn)
        795         return np.ravel(y)
        796 
    --> 797     raise ValueError("bad input shape \{0\}".format(shape))
        798 
        799 
    

        ValueError: bad input shape (908, 2)

    \end{Verbatim}

    \paragraph{发现使用词向量的训练得到的结果很不好}\label{ux53d1ux73b0ux4f7fux7528ux8bcdux5411ux91cfux7684ux8badux7ec3ux5f97ux5230ux7684ux7ed3ux679cux5f88ux4e0dux597d}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{i} \PY{p}{,}\PY{n}{ts} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{Data2}\PY{o}{.}\PY{n}{ts\PYZus{}code}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{i}\PY{p}{]}
             \PY{n}{ss} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
             \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
             \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
         
             \PY{n}{model} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{l+m+mf}{0.006}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n}{input\PYZus{}y}\PY{p}{)}
             \PY{n}{pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}
         
             \PY{k}{for} \PY{n}{\PYZus{}date}\PY{p}{,}\PY{n}{\PYZus{}pred} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{pre\PYZus{}date}\PY{p}{,}\PY{n}{pred}\PY{p}{)}\PY{p}{:}
                 \PY{n}{result}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{ts}\PY{p}{,}\PY{n}{\PYZus{}date}\PY{p}{,}\PY{n}{\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{n}{result} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{result}\PY{p}{,}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ts\PYZus{}code}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trade\PYZus{}date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{result}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result2.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{index}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
D:\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow-t\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}sklearn\textbackslash{}linear\_model\textbackslash{}logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{param} \PY{o+ow}{in} \PY{n}{Data2}\PY{o}{.}\PY{n}{ts\PYZus{}code}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n}{model} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZus{}1.pkl}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{param}\PY{p}{)}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{pre} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}
             
             \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{pre\PYZus{}date}\PY{p}{,}\PY{n}{pre}\PY{p}{)}\PY{p}{:}
                 \PY{n}{result}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{param}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{\PYZus{}}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{n}{result} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{result}\PY{p}{,}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ts\PYZus{}code}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trade\PYZus{}date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{result}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result2.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{index}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeClassifier}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
         
         \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{i} \PY{p}{,}\PY{n}{ts} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{Data2}\PY{o}{.}\PY{n}{ts\PYZus{}code}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{i}\PY{p}{]}
             \PY{n}{ss} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
             \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
             \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
         
             \PY{n}{model} \PY{o}{=} \PY{n}{model\PYZus{}dtc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{80}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n}{input\PYZus{}y}\PY{p}{)}
             \PY{n}{pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}
         
             \PY{k}{for} \PY{n}{\PYZus{}date}\PY{p}{,}\PY{n}{\PYZus{}pred} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{pre\PYZus{}date}\PY{p}{,}\PY{n}{pred}\PY{p}{)}\PY{p}{:}
                 \PY{n}{result}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{ts}\PY{p}{,}\PY{n}{\PYZus{}date}\PY{p}{,}\PY{n}{\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{n}{result} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{result}\PY{p}{,}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ts\PYZus{}code}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trade\PYZus{}date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{result}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result3.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{index}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}\PY{p}{,}\PY{n}{roc\PYZus{}auc\PYZus{}score}
         \PY{k+kn}{from} \PY{n+nn}{xgboost}\PY{n+nn}{.}\PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{XGBClassifier}
         
         \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{i} \PY{p}{,}\PY{n}{ts} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{Data2}\PY{o}{.}\PY{n}{ts\PYZus{}code}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{i}\PY{p}{]}
             \PY{n}{ss} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
             \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
             \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
         
             \PY{n}{model} \PY{o}{=} \PY{n}{model\PYZus{}dtc} \PY{o}{=} \PY{n}{XGBClassifier}\PY{p}{(}\PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{500}\PY{p}{,}\PY{n}{seed}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} fit...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n}{input\PYZus{}y}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auc:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{input\PYZus{}y}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}     for \PYZus{}date,\PYZus{}pred in zip(pre\PYZus{}date,pred):}
         \PY{c+c1}{\PYZsh{}         result.append([ts,\PYZus{}date,\PYZus{}pred[1]])}
         \PY{c+c1}{\PYZsh{} result = pd.DataFrame(result,columns=[\PYZsq{}ts\PYZus{}code\PYZsq{},\PYZsq{}trade\PYZus{}date\PYZsq{},\PYZsq{}p\PYZsq{}])}
         \PY{c+c1}{\PYZsh{} result.to\PYZus{}csv(\PYZsq{}result2.csv\PYZsq{},index=None)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{k+kn}{from} \PY{n+nn}{lightgbm} \PY{k}{import} \PY{n}{LGBMClassifier}
         
         \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{i} \PY{p}{,}\PY{n}{ts} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{Data2}\PY{o}{.}\PY{n}{ts\PYZus{}code}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{i}\PY{p}{]}
             \PY{n}{ss} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
             \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
             \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
         
             \PY{n}{model} \PY{o}{=} \PY{n}{model\PYZus{}dtc} \PY{o}{=} \PY{n}{LGBMClassifier}\PY{p}{(}\PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{300}\PY{p}{,}\PY{n}{seed}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} fit...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n}{input\PYZus{}y}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auc:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{input\PYZus{}y}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}     for \PYZus{}date,\PYZus{}pred in zip(pre\PYZus{}date,pred):}
         \PY{c+c1}{\PYZsh{}         result.append([ts,\PYZus{}date,\PYZus{}pred[1]])}
         \PY{c+c1}{\PYZsh{} result = pd.DataFrame(result,columns=[\PYZsq{}ts\PYZus{}code\PYZsq{},\PYZsq{}trade\PYZus{}date\PYZsq{},\PYZsq{}p\PYZsq{}])}
         \PY{c+c1}{\PYZsh{} result.to\PYZus{}csv(\PYZsq{}result\PYZus{}lgb.csv\PYZsq{},index=None)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0
\# fit{\ldots}
auc: 1.0

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{k+kn}{import} \PY{n+nn}{lightgbm} \PY{k}{as} \PY{n+nn}{lgb}
         \PY{k+kn}{from} \PY{n+nn}{lightgbm} \PY{k}{import} \PY{n}{LGBMClassifier}
         
         \PY{n}{params} \PY{o}{=}\PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{boosting\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gbdt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{c+c1}{\PYZsh{}     \PYZsq{}objective\PYZsq{}:\PYZsq{}regression\PYZsq{},}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mf}{0.1}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{seed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{64}\PY{p}{,}
         \PY{c+c1}{\PYZsh{}     \PYZsq{}num\PYZus{}leaves\PYZsq{}:50,}
         \PY{c+c1}{\PYZsh{}     \PYZsq{}sample\PYZsq{}:0.8,}
         \PY{c+c1}{\PYZsh{}     \PYZsq{}colsample\PYZus{}bytree\PYZsq{}:0.8,}
         \PY{p}{\PYZcb{}}
         
         \PY{k}{def} \PY{n+nf}{model\PYZus{}fit}\PY{p}{(}\PY{n}{params}\PY{p}{,}\PY{n}{model}\PY{p}{,}\PY{n}{x\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{n}{early\PYZus{}stopping\PYZus{}rounds}\PY{o}{=}\PY{l+m+mi}{80}\PY{p}{)}\PY{p}{:}
             \PY{n}{lgb\PYZus{}train} \PY{o}{=} \PY{n}{lgb}\PY{o}{.}\PY{n}{Dataset}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{)}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cving ...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{cv\PYZus{}result} \PY{o}{=} \PY{n}{lgb}\PY{o}{.}\PY{n}{cv}\PY{p}{(}\PY{n}{params}\PY{p}{,}\PY{n}{lgb\PYZus{}train}\PY{p}{,}\PY{n}{num\PYZus{}boost\PYZus{}round}\PY{o}{=}\PY{l+m+mi}{5000}\PY{p}{,}\PY{n}{nfold}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}\PY{n}{stratified}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
                                \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{metrics}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{early\PYZus{}stopping\PYZus{}rounds}\PY{o}{=}\PY{n}{early\PYZus{}stopping\PYZus{}rounds}\PY{p}{,}\PY{n}{seed}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cv finished }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{k+kn}{import} \PY{n+nn}{json}
             \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cv\PYZus{}result.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{k}{as} \PY{n}{file} \PY{p}{:}
                 \PY{n}{json}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{cv\PYZus{}result}\PY{p}{,}\PY{n}{file}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{n}{cv\PYZus{}result}\PY{p}{)}
             \PY{n}{n\PYZus{}estimators} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cv\PYZus{}result}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auc\PYZhy{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{set\PYZus{}params}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{n}{n\PYZus{}estimators}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{refitting ...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{over!}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{result} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{i} \PY{p}{,}\PY{n}{ts} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{Data2}\PY{o}{.}\PY{n}{ts\PYZus{}code}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{i}\PY{p}{]}
             \PY{n}{ss} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
             \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
             \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{ss}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
         
             \PY{n}{model} \PY{o}{=} \PY{n}{model\PYZus{}dtc} \PY{o}{=} \PY{n}{LGBMClassifier}\PY{p}{(}\PY{n}{learn\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}     model\PYZus{}fit(params,model,input\PYZus{}x,input\PYZus{}y)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} fit }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{i}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n}{input\PYZus{}y}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auc:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{input\PYZus{}y}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{input\PYZus{}x}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{val\PYZus{}data}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}     for \PYZus{}date,\PYZus{}pred in zip(pre\PYZus{}date,pred):}
         \PY{c+c1}{\PYZsh{}         result.append([ts,\PYZus{}date,\PYZus{}pred[1]])}
         \PY{c+c1}{\PYZsh{} result = pd.DataFrame(result,columns=[\PYZsq{}ts\PYZus{}code\PYZsq{},\PYZsq{}trade\PYZus{}date\PYZsq{},\PYZsq{}p\PYZsq{}])}
         \PY{c+c1}{\PYZsh{} result.to\PYZus{}csv(\PYZsq{}result\PYZus{}lgb2.csv\PYZsq{},index=None)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\# fit 0{\ldots}
auc: 1.0
\# fit 1{\ldots}
auc: 1.0
\# fit 2{\ldots}
auc: 1.0
\# fit 3{\ldots}
auc: 1.0
\# fit 4{\ldots}
auc: 1.0
\# fit 5{\ldots}
auc: 1.0
\# fit 6{\ldots}
auc: 1.0
\# fit 7{\ldots}
auc: 1.0
\# fit 8{\ldots}
auc: 1.0
\# fit 9{\ldots}
auc: 1.0
\# fit 10{\ldots}
auc: 1.0
\# fit 11{\ldots}
auc: 1.0
\# fit 12{\ldots}
auc: 1.0
\# fit 13{\ldots}
auc: 1.0
\# fit 14{\ldots}
auc: 1.0
\# fit 15{\ldots}
auc: 1.0
\# fit 16{\ldots}
auc: 1.0
\# fit 17{\ldots}
auc: 1.0
\# fit 18{\ldots}
auc: 1.0
\# fit 19{\ldots}
auc: 1.0
\# fit 20{\ldots}
auc: 1.0
\# fit 21{\ldots}
auc: 1.0
\# fit 22{\ldots}
auc: 1.0
\# fit 23{\ldots}
auc: 1.0
\# fit 24{\ldots}
auc: 1.0
\# fit 25{\ldots}
auc: 1.0
\# fit 26{\ldots}
auc: 1.0
\# fit 27{\ldots}
auc: 1.0
\# fit 28{\ldots}
auc: 1.0
\# fit 29{\ldots}
auc: 1.0
\# fit 30{\ldots}
auc: 1.0
\# fit 31{\ldots}
auc: 1.0
\# fit 32{\ldots}
auc: 1.0
\# fit 33{\ldots}
auc: 1.0

    \end{Verbatim}

    \subsubsection{混合结果}\label{ux6df7ux5408ux7ed3ux679c}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}71}]:} \PY{n}{result1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result\PYZus{}lgb.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{result2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result\PYZus{}lgb2.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{result3} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{result2.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{result1}\PY{o}{.}\PY{n}{p} \PY{o}{=} \PY{n}{result1}\PY{o}{.}\PY{n}{p} \PY{o}{*} \PY{l+m+mi}{3}\PY{o}{/}\PY{l+m+mi}{8} \PY{o}{+} \PY{n}{result2}\PY{o}{.}\PY{n}{p} \PY{o}{*} \PY{l+m+mi}{1}\PY{o}{/}\PY{l+m+mi}{8} \PY{o}{+} \PY{n}{result3}\PY{o}{.}\PY{n}{p} \PY{o}{*} \PY{l+m+mi}{1}\PY{o}{/}\PY{l+m+mi}{2}
         \PY{n}{result1}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}result\PYZus{}1.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsubsection{3.2
深度模型搭建}\label{ux6df1ux5ea6ux6a21ux578bux642dux5efa}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
         \PY{n}{tf}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}20}]:} '1.6.0'
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{k}{class} \PY{n+nc}{DeepModel}\PY{p}{:}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,}\PY{n}{learning\PYZus{}rate}\PY{p}{,}\PY{n}{classes\PYZus{}num}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{lr} \PY{o}{=} \PY{n}{learning\PYZus{}rate}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classes\PYZus{}num} \PY{o}{=} \PY{n}{classes\PYZus{}num}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{global\PYZus{}step} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{get\PYZus{}or\PYZus{}create\PYZus{}global\PYZus{}step}\PY{p}{(}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Placeholder }
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{k+kc}{None}\PY{p}{,}\PY{l+m+mi}{200}\PY{p}{]}\PY{p}{,}\PY{n}{dtype}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input\PYZus{}x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{k+kc}{None}\PY{p}{]}\PY{p}{,}\PY{n}{dtype}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{input\PYZus{}y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{keep\PYZus{}dropout\PYZus{}rate} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{dtype}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dropout\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 
                 
                 \PY{n}{W\PYZus{}shape} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{256}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{2}\PY{p}{\PYZcb{}}
                 \PY{n}{b\PYZus{}shape} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{256}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{2}\PY{p}{\PYZcb{}}
                 
                 
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{W1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{200}\PY{p}{,}\PY{n}{W\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{stddev}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{W2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{W\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{W\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{stddev}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{W3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n}{W\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{W\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{stddev}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{)}
                 
                 
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{b1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{constant}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{n}{b\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{b2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{constant}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{n}{b\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{b3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{constant}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{n}{b\PYZus{}shape}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{inference}\PY{p}{(}\PY{p}{)}
         
                 
             \PY{k}{def} \PY{n+nf}{inference}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input\PYZus{}x}\PY{p}{,}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{W1}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{b1}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{output}\PY{p}{)}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{keep\PYZus{}dropout\PYZus{}rate}\PY{p}{)}
                 
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{output}\PY{p}{,}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{W2}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{b2}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{output}\PY{p}{)}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{keep\PYZus{}dropout\PYZus{}rate}\PY{p}{)}
                 
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{output}\PY{p}{,}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{W3}\PY{p}{)} \PY{o}{+} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{b3}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{output}\PY{p}{)}
                 \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n}{output}\PY{p}{,}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{keep\PYZus{}dropout\PYZus{}rate}\PY{p}{)}
                 
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{logits} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{dense}\PY{p}{(}\PY{n}{output}\PY{p}{,}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{classes\PYZus{}num}\PY{p}{,}\PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{tanh}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{logits}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 
                 
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss} \PY{o}{=} \PY{n}{cross\PYZus{}entropy} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{sparse\PYZus{}softmax\PYZus{}cross\PYZus{}entropy\PYZus{}with\PYZus{}logits}\PY{p}{(}\PY{n}{labels}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input\PYZus{}y}\PY{p}{,}\PY{n}{logits}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{logits}\PY{p}{)}\PY{p}{)}
                 
                 \PY{n}{op} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{lr}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{train\PYZus{}op} \PY{o}{=} \PY{n}{op}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n}{cross\PYZus{}entropy}\PY{p}{,}\PY{n}{global\PYZus{}step}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{global\PYZus{}step}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{ckpt\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./models/ckpt\PYZus{}model/ckpt}\PY{l+s+s1}{\PYZsq{}}
         \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{64}
         \PY{n}{epoches} \PY{o}{=} \PY{l+m+mi}{5000}
         
         \PY{n}{tf}\PY{o}{.}\PY{n}{reset\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{generate\PYZus{}data}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{batch\PYZus{}size}\PY{p}{,}\PY{n}{epoches}\PY{p}{,}\PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{data\PYZus{}len} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}
             \PY{n}{batch\PYZus{}num} \PY{o}{=} \PY{n}{data\PYZus{}len} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size} \PY{o}{+} \PY{l+m+mi}{1}
             \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{epoches}\PY{p}{)}\PY{p}{:}
                 \PY{k}{if} \PY{n}{shuffle}\PY{p}{:}
                     \PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{permutation}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n}{data\PYZus{}len}\PY{p}{)}\PY{p}{)}
                     \PY{n}{x} \PY{o}{=} \PY{n}{x}\PY{p}{[}\PY{n}{indices}\PY{p}{]}
                     \PY{n}{y} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{indices}\PY{p}{]}
                 \PY{k}{for} \PY{n}{batch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}num}\PY{p}{)}\PY{p}{:}
                     \PY{n}{start\PYZus{}index} \PY{o}{=} \PY{n}{batch} \PY{o}{*} \PY{n}{batch\PYZus{}size}
                     \PY{n}{end\PYZus{}index} \PY{o}{=} \PY{n+nb}{min}\PY{p}{(}\PY{n}{data\PYZus{}len}\PY{p}{,} \PY{p}{(}\PY{n}{batch} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{*} \PY{n}{batch\PYZus{}size}\PY{p}{)}
                     \PY{k}{yield} \PY{n}{x}\PY{p}{[}\PY{n}{start\PYZus{}index}\PY{p}{:}\PY{n}{end\PYZus{}index}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{[}\PY{n}{start\PYZus{}index}\PY{p}{:}\PY{n}{end\PYZus{}index}\PY{p}{]}
             
         
         \PY{n}{config} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{ConfigProto}\PY{p}{(}\PY{p}{)}
         \PY{n}{config}\PY{o}{.}\PY{n}{gpu\PYZus{}options}\PY{o}{.}\PY{n}{allow\PYZus{}growth} \PY{o}{=} \PY{k+kc}{True}
         
         
         \PY{n}{input\PYZus{}x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{allVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n}{input\PYZus{}y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{Data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{]}
         
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{config}\PY{o}{=}\PY{n}{config}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{n}{model} \PY{o}{=} \PY{n}{DeepModel}\PY{p}{(}\PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}
             
             \PY{n}{saver} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{Saver}\PY{p}{(}\PY{n}{max\PYZus{}to\PYZus{}keep}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
             \PY{n}{ckpt\PYZus{}path} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{latest\PYZus{}checkpoint}\PY{p}{(}\PY{n}{ckpt\PYZus{}dir}\PY{p}{)}
             
             \PY{k}{if} \PY{n}{ckpt\PYZus{}path} \PY{o+ow}{is} \PY{k+kc}{None}\PY{p}{:}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} Initilize model ...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{global\PYZus{}variables\PYZus{}initializer}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{saver}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,}\PY{n}{ckpt\PYZus{}path}\PY{p}{)}
             \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{global\PYZus{}step}\PY{p}{)}
             \PY{k}{for} \PY{n}{x}\PY{p}{,}\PY{n}{y} \PY{o+ow}{in} \PY{n}{generate\PYZus{}data}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{n}{batch\PYZus{}size}\PY{p}{,}\PY{n}{epoches}\PY{p}{,}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:}
                 \PY{n}{feed\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}
                     \PY{n}{model}\PY{o}{.}\PY{n}{input\PYZus{}x} \PY{p}{:} \PY{n}{x}\PY{p}{,}
                     \PY{n}{model}\PY{o}{.}\PY{n}{input\PYZus{}y} \PY{p}{:} \PY{n}{y}\PY{p}{,}
                     \PY{n}{model}\PY{o}{.}\PY{n}{keep\PYZus{}dropout\PYZus{}rate} \PY{p}{:} \PY{l+m+mf}{0.8}
                 \PY{p}{\PYZcb{}}
                 \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{loss}\PY{p}{,} \PY{n}{gs} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{model}\PY{o}{.}\PY{n}{train\PYZus{}op}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{loss}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{global\PYZus{}step}\PY{p}{]}\PY{p}{,}\PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{n}{feed\PYZus{}dict}\PY{p}{)}
                 
                 \PY{k}{if} \PY{n}{gs} \PY{o}{\PYZpc{}} \PY{l+m+mi}{50} \PY{o}{==}\PY{l+m+mi}{0}\PY{p}{:}
                     \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Step:}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ , train loss : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{gs}\PY{p}{,}\PY{n}{loss}\PY{p}{)}\PY{p}{)}
                     \PY{n}{loss} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{loss}\PY{p}{,}\PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{model}\PY{o}{.}\PY{n}{input\PYZus{}x}\PY{p}{:}\PY{n}{x\PYZus{}test}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{input\PYZus{}y}\PY{p}{:}\PY{n}{y\PYZus{}test}\PY{p}{,}\PY{n}{model}\PY{o}{.}\PY{n}{keep\PYZus{}dropout\PYZus{}rate}\PY{p}{:}\PY{l+m+mf}{1.0}\PY{p}{\PYZcb{}}\PY{p}{)}
                     \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Step:}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ , test loss : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{gs}\PY{p}{,}\PY{n}{loss}\PY{p}{)}\PY{p}{)}
                     \PY{n}{saver}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{sess}\PY{p}{,}\PY{n}{ckpt\PYZus{}dir}\PY{p}{)}
                     \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{} Save into }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{ckpt\PYZus{}dir}\PY{p}{)}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{} Finish }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\# Initilize model {\ldots}
Step:50 , train loss : 0.676338791847229
Step:50 , test loss : 0.69144606590271
\# Save into ./models/ckpt\_model/ckpt
Step:100 , train loss : 0.6756932139396667
Step:100 , test loss : 0.6910459995269775
\# Save into ./models/ckpt\_model/ckpt
Step:150 , train loss : 0.6350569725036621
Step:150 , test loss : 0.6917679309844971
\# Save into ./models/ckpt\_model/ckpt
Step:200 , train loss : 0.6737147569656372
Step:200 , test loss : 0.6910071969032288
\# Save into ./models/ckpt\_model/ckpt
Step:250 , train loss : 0.6906408071517944
Step:250 , test loss : 0.691902220249176
\# Save into ./models/ckpt\_model/ckpt
Step:300 , train loss : 0.7359210848808289
Step:300 , test loss : 0.6926208734512329
\# Save into ./models/ckpt\_model/ckpt
Step:350 , train loss : 0.6859169602394104
Step:350 , test loss : 0.6906859278678894
\# Save into ./models/ckpt\_model/ckpt
Step:400 , train loss : 0.6772888898849487
Step:400 , test loss : 0.6906862258911133
\# Save into ./models/ckpt\_model/ckpt
Step:450 , train loss : 0.6854478716850281
Step:450 , test loss : 0.6919234991073608
\# Save into ./models/ckpt\_model/ckpt
Step:500 , train loss : 0.6822121143341064
Step:500 , test loss : 0.6909579634666443
\# Save into ./models/ckpt\_model/ckpt
Step:550 , train loss : 0.7053073644638062
Step:550 , test loss : 0.6925880908966064
\# Save into ./models/ckpt\_model/ckpt
Step:600 , train loss : 0.6848403811454773
Step:600 , test loss : 0.6911725997924805
\# Save into ./models/ckpt\_model/ckpt
Step:650 , train loss : 0.6879628896713257
Step:650 , test loss : 0.6906828880310059
\# Save into ./models/ckpt\_model/ckpt
Step:700 , train loss : 0.6726382970809937
Step:700 , test loss : 0.6931998133659363
\# Save into ./models/ckpt\_model/ckpt
Step:750 , train loss : 0.6853373646736145
Step:750 , test loss : 0.6908837556838989
\# Save into ./models/ckpt\_model/ckpt
Step:800 , train loss : 0.6760226488113403
Step:800 , test loss : 0.6942917108535767
\# Save into ./models/ckpt\_model/ckpt
Step:850 , train loss : 0.6809124946594238
Step:850 , test loss : 0.6935944557189941
\# Save into ./models/ckpt\_model/ckpt
Step:900 , train loss : 0.6798713803291321
Step:900 , test loss : 0.6907933950424194
\# Save into ./models/ckpt\_model/ckpt
Step:950 , train loss : 0.6968993544578552
Step:950 , test loss : 0.6909682154655457
\# Save into ./models/ckpt\_model/ckpt
Step:1000 , train loss : 0.692650318145752
Step:1000 , test loss : 0.6930269598960876
\# Save into ./models/ckpt\_model/ckpt
Step:1050 , train loss : 0.6964576244354248
Step:1050 , test loss : 0.6929771304130554
\# Save into ./models/ckpt\_model/ckpt
Step:1100 , train loss : 0.6921371221542358
Step:1100 , test loss : 0.6927679181098938
\# Save into ./models/ckpt\_model/ckpt
Step:1150 , train loss : 0.6428225040435791
Step:1150 , test loss : 0.7061946988105774
\# Save into ./models/ckpt\_model/ckpt
Step:1200 , train loss : 0.7041234970092773
Step:1200 , test loss : 0.6906829476356506
\# Save into ./models/ckpt\_model/ckpt
Step:1250 , train loss : 0.6990073919296265
Step:1250 , test loss : 0.6934377551078796
\# Save into ./models/ckpt\_model/ckpt
Step:1300 , train loss : 0.6867327690124512
Step:1300 , test loss : 0.6923187375068665
\# Save into ./models/ckpt\_model/ckpt
Step:1350 , train loss : 0.6693372130393982
Step:1350 , test loss : 0.6908615231513977
\# Save into ./models/ckpt\_model/ckpt
Step:1400 , train loss : 0.6802379488945007
Step:1400 , test loss : 0.6907824873924255
\# Save into ./models/ckpt\_model/ckpt
Step:1450 , train loss : 0.6978748440742493
Step:1450 , test loss : 0.6920351982116699
\# Save into ./models/ckpt\_model/ckpt
Step:1500 , train loss : 0.6594796776771545
Step:1500 , test loss : 0.694096028804779
\# Save into ./models/ckpt\_model/ckpt
Step:1550 , train loss : 0.6954479813575745
Step:1550 , test loss : 0.6918281316757202
\# Save into ./models/ckpt\_model/ckpt
Step:1600 , train loss : 0.6891561150550842
Step:1600 , test loss : 0.6908405423164368
\# Save into ./models/ckpt\_model/ckpt
Step:1650 , train loss : 0.669990062713623
Step:1650 , test loss : 0.6910591125488281
\# Save into ./models/ckpt\_model/ckpt
Step:1700 , train loss : 0.694454550743103
Step:1700 , test loss : 0.6908925175666809
\# Save into ./models/ckpt\_model/ckpt
Step:1750 , train loss : 0.6794537305831909
Step:1750 , test loss : 0.6917877197265625
\# Save into ./models/ckpt\_model/ckpt
Step:1800 , train loss : 0.6769965291023254
Step:1800 , test loss : 0.6963326930999756
\# Save into ./models/ckpt\_model/ckpt
Step:1850 , train loss : 0.6839022636413574
Step:1850 , test loss : 0.6906931400299072
\# Save into ./models/ckpt\_model/ckpt
Step:1900 , train loss : 0.702846348285675
Step:1900 , test loss : 0.6926860213279724
\# Save into ./models/ckpt\_model/ckpt
Step:1950 , train loss : 0.69343501329422
Step:1950 , test loss : 0.6918331384658813
\# Save into ./models/ckpt\_model/ckpt
Step:2000 , train loss : 0.6937054395675659
Step:2000 , test loss : 0.6914055943489075
\# Save into ./models/ckpt\_model/ckpt
Step:2050 , train loss : 0.6859451532363892
Step:2050 , test loss : 0.6961031556129456
\# Save into ./models/ckpt\_model/ckpt
Step:2100 , train loss : 0.6855754256248474
Step:2100 , test loss : 0.6907760500907898
\# Save into ./models/ckpt\_model/ckpt
Step:2150 , train loss : 0.6941350698471069
Step:2150 , test loss : 0.6923538446426392
\# Save into ./models/ckpt\_model/ckpt
Step:2200 , train loss : 0.7001645565032959
Step:2200 , test loss : 0.6913303732872009
\# Save into ./models/ckpt\_model/ckpt
Step:2250 , train loss : 0.6878383755683899
Step:2250 , test loss : 0.6915448904037476
\# Save into ./models/ckpt\_model/ckpt
Step:2300 , train loss : 0.6855103969573975
Step:2300 , test loss : 0.6918747425079346
\# Save into ./models/ckpt\_model/ckpt
Step:2350 , train loss : 0.6852666139602661
Step:2350 , test loss : 0.690683126449585
\# Save into ./models/ckpt\_model/ckpt
Step:2400 , train loss : 0.6966924667358398
Step:2400 , test loss : 0.6909926533699036
\# Save into ./models/ckpt\_model/ckpt
Step:2450 , train loss : 0.6959284543991089
Step:2450 , test loss : 0.697736918926239
\# Save into ./models/ckpt\_model/ckpt
Step:2500 , train loss : 0.68569016456604
Step:2500 , test loss : 0.691118061542511
\# Save into ./models/ckpt\_model/ckpt
Step:2550 , train loss : 0.6551703214645386
Step:2550 , test loss : 0.6907915472984314
\# Save into ./models/ckpt\_model/ckpt
Step:2600 , train loss : 0.6947803497314453
Step:2600 , test loss : 0.6907712817192078
\# Save into ./models/ckpt\_model/ckpt
Step:2650 , train loss : 0.6706581115722656
Step:2650 , test loss : 0.6922723650932312
\# Save into ./models/ckpt\_model/ckpt
Step:2700 , train loss : 0.7081763744354248
Step:2700 , test loss : 0.6908324956893921
\# Save into ./models/ckpt\_model/ckpt
Step:2750 , train loss : 0.6866846084594727
Step:2750 , test loss : 0.6906836032867432
\# Save into ./models/ckpt\_model/ckpt
Step:2800 , train loss : 0.7270084619522095
Step:2800 , test loss : 0.6975277066230774
\# Save into ./models/ckpt\_model/ckpt
Step:2850 , train loss : 0.6834947466850281
Step:2850 , test loss : 0.6928772330284119
\# Save into ./models/ckpt\_model/ckpt
Step:2900 , train loss : 0.661730170249939
Step:2900 , test loss : 0.6916422247886658
\# Save into ./models/ckpt\_model/ckpt
Step:2950 , train loss : 0.6945599317550659
Step:2950 , test loss : 0.6915130019187927
\# Save into ./models/ckpt\_model/ckpt
Step:3000 , train loss : 0.6674357056617737
Step:3000 , test loss : 0.6907625794410706
\# Save into ./models/ckpt\_model/ckpt
Step:3050 , train loss : 0.6783734560012817
Step:3050 , test loss : 0.6914119124412537
\# Save into ./models/ckpt\_model/ckpt
Step:3100 , train loss : 0.7046988010406494
Step:3100 , test loss : 0.6926862001419067
\# Save into ./models/ckpt\_model/ckpt
Step:3150 , train loss : 0.7288084030151367
Step:3150 , test loss : 0.6909713745117188
\# Save into ./models/ckpt\_model/ckpt
Step:3200 , train loss : 0.6696184277534485
Step:3200 , test loss : 0.6910697817802429
\# Save into ./models/ckpt\_model/ckpt
Step:3250 , train loss : 0.6916791200637817
Step:3250 , test loss : 0.6912108063697815
\# Save into ./models/ckpt\_model/ckpt
Step:3300 , train loss : 0.6239154934883118
Step:3300 , test loss : 0.692366898059845
\# Save into ./models/ckpt\_model/ckpt
Step:3350 , train loss : 0.6808557510375977
Step:3350 , test loss : 0.6907204985618591
\# Save into ./models/ckpt\_model/ckpt
Step:3400 , train loss : 0.7038297057151794
Step:3400 , test loss : 0.6907010078430176
\# Save into ./models/ckpt\_model/ckpt
Step:3450 , train loss : 0.6787452697753906
Step:3450 , test loss : 0.6939454078674316
\# Save into ./models/ckpt\_model/ckpt
Step:3500 , train loss : 0.6926159858703613
Step:3500 , test loss : 0.6910457015037537
\# Save into ./models/ckpt\_model/ckpt
Step:3550 , train loss : 0.6925698518753052
Step:3550 , test loss : 0.6930540204048157
\# Save into ./models/ckpt\_model/ckpt
Step:3600 , train loss : 0.6945324540138245
Step:3600 , test loss : 0.693027913570404
\# Save into ./models/ckpt\_model/ckpt
Step:3650 , train loss : 0.6917473077774048
Step:3650 , test loss : 0.6929485201835632
\# Save into ./models/ckpt\_model/ckpt
Step:3700 , train loss : 0.6949437260627747
Step:3700 , test loss : 0.6923767328262329
\# Save into ./models/ckpt\_model/ckpt
Step:3750 , train loss : 0.6808552145957947
Step:3750 , test loss : 0.6930407285690308
\# Save into ./models/ckpt\_model/ckpt
Step:3800 , train loss : 0.6843287348747253
Step:3800 , test loss : 0.6911719441413879
\# Save into ./models/ckpt\_model/ckpt
Step:3850 , train loss : 0.6889990568161011
Step:3850 , test loss : 0.6909626126289368
\# Save into ./models/ckpt\_model/ckpt
Step:3900 , train loss : 0.6435261368751526
Step:3900 , test loss : 0.6913857460021973
\# Save into ./models/ckpt\_model/ckpt
Step:3950 , train loss : 0.7015701532363892
Step:3950 , test loss : 0.6990095973014832
\# Save into ./models/ckpt\_model/ckpt
Step:4000 , train loss : 0.6886709332466125
Step:4000 , test loss : 0.6912970542907715
\# Save into ./models/ckpt\_model/ckpt
Step:4050 , train loss : 0.669581413269043
Step:4050 , test loss : 0.6917554140090942
\# Save into ./models/ckpt\_model/ckpt
Step:4100 , train loss : 0.6920599937438965
Step:4100 , test loss : 0.6920057535171509
\# Save into ./models/ckpt\_model/ckpt
Step:4150 , train loss : 0.6956775188446045
Step:4150 , test loss : 0.6920180320739746
\# Save into ./models/ckpt\_model/ckpt
Step:4200 , train loss : 0.6538389921188354
Step:4200 , test loss : 0.6911734938621521
\# Save into ./models/ckpt\_model/ckpt
Step:4250 , train loss : 0.6784613132476807
Step:4250 , test loss : 0.6921232342720032
\# Save into ./models/ckpt\_model/ckpt
Step:4300 , train loss : 0.7177901864051819
Step:4300 , test loss : 0.6928378343582153
\# Save into ./models/ckpt\_model/ckpt
Step:4350 , train loss : 0.662777841091156
Step:4350 , test loss : 0.6908428072929382
\# Save into ./models/ckpt\_model/ckpt
Step:4400 , train loss : 0.6877325773239136
Step:4400 , test loss : 0.6908462643623352
\# Save into ./models/ckpt\_model/ckpt
Step:4450 , train loss : 0.676133394241333
Step:4450 , test loss : 0.6908238530158997
\# Save into ./models/ckpt\_model/ckpt
Step:4500 , train loss : 0.6926145553588867
Step:4500 , test loss : 0.6926860213279724
\# Save into ./models/ckpt\_model/ckpt
Step:4550 , train loss : 0.6797777414321899
Step:4550 , test loss : 0.6918485760688782
\# Save into ./models/ckpt\_model/ckpt
Step:4600 , train loss : 0.6903960704803467
Step:4600 , test loss : 0.6916797757148743
\# Save into ./models/ckpt\_model/ckpt
Step:4650 , train loss : 0.6795781254768372
Step:4650 , test loss : 0.6910812854766846
\# Save into ./models/ckpt\_model/ckpt
Step:4700 , train loss : 0.6996409893035889
Step:4700 , test loss : 0.6914891600608826
\# Save into ./models/ckpt\_model/ckpt
Step:4750 , train loss : 0.6586025357246399
Step:4750 , test loss : 0.7010790109634399
\# Save into ./models/ckpt\_model/ckpt
Step:4800 , train loss : 0.6805784106254578
Step:4800 , test loss : 0.6913658380508423
\# Save into ./models/ckpt\_model/ckpt
Step:4850 , train loss : 0.6911706328392029
Step:4850 , test loss : 0.691710352897644
\# Save into ./models/ckpt\_model/ckpt
Step:4900 , train loss : 0.6761386394500732
Step:4900 , test loss : 0.690875232219696
\# Save into ./models/ckpt\_model/ckpt
Step:4950 , train loss : 0.7402270436286926
Step:4950 , test loss : 0.6917002201080322
\# Save into ./models/ckpt\_model/ckpt
Step:5000 , train loss : 0.6993035078048706
Step:5000 , test loss : 0.692221999168396
\# Save into ./models/ckpt\_model/ckpt
Step:5050 , train loss : 0.6835184097290039
Step:5050 , test loss : 0.690902829170227
\# Save into ./models/ckpt\_model/ckpt
Step:5100 , train loss : 0.6649388670921326
Step:5100 , test loss : 0.6924101710319519
\# Save into ./models/ckpt\_model/ckpt
Step:5150 , train loss : 0.692024290561676
Step:5150 , test loss : 0.6923640966415405
\# Save into ./models/ckpt\_model/ckpt
Step:5200 , train loss : 0.674018144607544
Step:5200 , test loss : 0.6906863451004028
\# Save into ./models/ckpt\_model/ckpt
Step:5250 , train loss : 0.6808550953865051
Step:5250 , test loss : 0.6907618045806885
\# Save into ./models/ckpt\_model/ckpt
Step:5300 , train loss : 0.6953933238983154
Step:5300 , test loss : 0.691856861114502
\# Save into ./models/ckpt\_model/ckpt
Step:5350 , train loss : 0.6924788951873779
Step:5350 , test loss : 0.6923178434371948
\# Save into ./models/ckpt\_model/ckpt
Step:5400 , train loss : 0.6476040482521057
Step:5400 , test loss : 0.6907660961151123
\# Save into ./models/ckpt\_model/ckpt
Step:5450 , train loss : 0.6931015253067017
Step:5450 , test loss : 0.6907330751419067
\# Save into ./models/ckpt\_model/ckpt
Step:5500 , train loss : 0.6927027702331543
Step:5500 , test loss : 0.6906890869140625
\# Save into ./models/ckpt\_model/ckpt
Step:5550 , train loss : 0.6587598323822021
Step:5550 , test loss : 0.6906840205192566
\# Save into ./models/ckpt\_model/ckpt
Step:5600 , train loss : 0.679336667060852
Step:5600 , test loss : 0.6908295154571533
\# Save into ./models/ckpt\_model/ckpt
Step:5650 , train loss : 0.6892512440681458
Step:5650 , test loss : 0.6915168166160583
\# Save into ./models/ckpt\_model/ckpt
Step:5700 , train loss : 0.6722370982170105
Step:5700 , test loss : 0.6961319446563721
\# Save into ./models/ckpt\_model/ckpt
Step:5750 , train loss : 0.6899451613426208
Step:5750 , test loss : 0.6921966671943665
\# Save into ./models/ckpt\_model/ckpt
Step:5800 , train loss : 0.695388913154602
Step:5800 , test loss : 0.6921074390411377
\# Save into ./models/ckpt\_model/ckpt
Step:5850 , train loss : 0.6984047889709473
Step:5850 , test loss : 0.6907387971878052
\# Save into ./models/ckpt\_model/ckpt
Step:5900 , train loss : 0.6775839924812317
Step:5900 , test loss : 0.6917251348495483
\# Save into ./models/ckpt\_model/ckpt
Step:5950 , train loss : 0.6908556222915649
Step:5950 , test loss : 0.691982090473175
\# Save into ./models/ckpt\_model/ckpt
Step:6000 , train loss : 0.7089917063713074
Step:6000 , test loss : 0.6915637850761414
\# Save into ./models/ckpt\_model/ckpt
Step:6050 , train loss : 0.694977343082428
Step:6050 , test loss : 0.6910008192062378
\# Save into ./models/ckpt\_model/ckpt
Step:6100 , train loss : 0.6962233781814575
Step:6100 , test loss : 0.692595362663269
\# Save into ./models/ckpt\_model/ckpt
Step:6150 , train loss : 0.7014167904853821
Step:6150 , test loss : 0.6907418966293335
\# Save into ./models/ckpt\_model/ckpt
Step:6200 , train loss : 0.6792556643486023
Step:6200 , test loss : 0.6917893290519714
\# Save into ./models/ckpt\_model/ckpt
Step:6250 , train loss : 0.6861286163330078
Step:6250 , test loss : 0.6909219026565552
\# Save into ./models/ckpt\_model/ckpt
Step:6300 , train loss : 0.6391404271125793
Step:6300 , test loss : 0.6962196230888367
\# Save into ./models/ckpt\_model/ckpt
Step:6350 , train loss : 0.6930011510848999
Step:6350 , test loss : 0.6930521130561829
\# Save into ./models/ckpt\_model/ckpt
Step:6400 , train loss : 0.6928384304046631
Step:6400 , test loss : 0.6930718421936035
\# Save into ./models/ckpt\_model/ckpt
Step:6450 , train loss : 0.6923438906669617
Step:6450 , test loss : 0.693036675453186
\# Save into ./models/ckpt\_model/ckpt
Step:6500 , train loss : 0.6925437450408936
Step:6500 , test loss : 0.6929049491882324
\# Save into ./models/ckpt\_model/ckpt
Step:6550 , train loss : 0.6867130994796753
Step:6550 , test loss : 0.6919655799865723
\# Save into ./models/ckpt\_model/ckpt
Step:6600 , train loss : 0.7164792418479919
Step:6600 , test loss : 0.6907910704612732
\# Save into ./models/ckpt\_model/ckpt
Step:6650 , train loss : 0.6918796300888062
Step:6650 , test loss : 0.6910966038703918
\# Save into ./models/ckpt\_model/ckpt
Step:6700 , train loss : 0.6905085444450378
Step:6700 , test loss : 0.6922352910041809
\# Save into ./models/ckpt\_model/ckpt
Step:6750 , train loss : 0.6131601929664612
Step:6750 , test loss : 0.6982862949371338
\# Save into ./models/ckpt\_model/ckpt
Step:6800 , train loss : 0.6943566203117371
Step:6800 , test loss : 0.6910417079925537
\# Save into ./models/ckpt\_model/ckpt
Step:6850 , train loss : 0.6925768852233887
Step:6850 , test loss : 0.691469669342041
\# Save into ./models/ckpt\_model/ckpt
Step:6900 , train loss : 0.7036487460136414
Step:6900 , test loss : 0.6911924481391907
\# Save into ./models/ckpt\_model/ckpt
Step:6950 , train loss : 0.6932921409606934
Step:6950 , test loss : 0.6919804215431213
\# Save into ./models/ckpt\_model/ckpt
Step:7000 , train loss : 0.6790062785148621
Step:7000 , test loss : 0.6944378018379211
\# Save into ./models/ckpt\_model/ckpt
Step:7050 , train loss : 0.653293251991272
Step:7050 , test loss : 0.6907222270965576
\# Save into ./models/ckpt\_model/ckpt
Step:7100 , train loss : 0.6907134652137756
Step:7100 , test loss : 0.6925564408302307
\# Save into ./models/ckpt\_model/ckpt
Step:7150 , train loss : 0.6781677007675171
Step:7150 , test loss : 0.6924974918365479
\# Save into ./models/ckpt\_model/ckpt
Step:7200 , train loss : 0.6914095878601074
Step:7200 , test loss : 0.6927827596664429
\# Save into ./models/ckpt\_model/ckpt
Step:7250 , train loss : 0.6899489164352417
Step:7250 , test loss : 0.6911464333534241
\# Save into ./models/ckpt\_model/ckpt
Step:7300 , train loss : 0.6708318591117859
Step:7300 , test loss : 0.6910938024520874
\# Save into ./models/ckpt\_model/ckpt
Step:7350 , train loss : 0.6630813479423523
Step:7350 , test loss : 0.6910176873207092
\# Save into ./models/ckpt\_model/ckpt
Step:7400 , train loss : 0.684640645980835
Step:7400 , test loss : 0.6913805603981018
\# Save into ./models/ckpt\_model/ckpt
Step:7450 , train loss : 0.6917883157730103
Step:7450 , test loss : 0.6941946148872375
\# Save into ./models/ckpt\_model/ckpt
Step:7500 , train loss : 0.7533369064331055
Step:7500 , test loss : 0.6913497447967529
\# Save into ./models/ckpt\_model/ckpt
Step:7550 , train loss : 0.687732458114624
Step:7550 , test loss : 0.6919206976890564
\# Save into ./models/ckpt\_model/ckpt
Step:7600 , train loss : 0.6927556991577148
Step:7600 , test loss : 0.6921350955963135
\# Save into ./models/ckpt\_model/ckpt
Step:7650 , train loss : 0.7367569804191589
Step:7650 , test loss : 0.6907473802566528
\# Save into ./models/ckpt\_model/ckpt
Step:7700 , train loss : 0.6897438764572144
Step:7700 , test loss : 0.6926425695419312
\# Save into ./models/ckpt\_model/ckpt
Step:7750 , train loss : 0.6929600238800049
Step:7750 , test loss : 0.69301438331604
\# Save into ./models/ckpt\_model/ckpt
Step:7800 , train loss : 0.6922598481178284
Step:7800 , test loss : 0.6928774118423462
\# Save into ./models/ckpt\_model/ckpt
Step:7850 , train loss : 0.6934894919395447
Step:7850 , test loss : 0.6919931769371033
\# Save into ./models/ckpt\_model/ckpt
Step:7900 , train loss : 0.6917916536331177
Step:7900 , test loss : 0.6924771666526794
\# Save into ./models/ckpt\_model/ckpt
Step:7950 , train loss : 0.6961390376091003
Step:7950 , test loss : 0.6927270293235779
\# Save into ./models/ckpt\_model/ckpt
Step:8000 , train loss : 0.68797767162323
Step:8000 , test loss : 0.6912980079650879
\# Save into ./models/ckpt\_model/ckpt
Step:8050 , train loss : 0.6834933757781982
Step:8050 , test loss : 0.6926711201667786
\# Save into ./models/ckpt\_model/ckpt
Step:8100 , train loss : 0.7235538959503174
Step:8100 , test loss : 0.6918782591819763
\# Save into ./models/ckpt\_model/ckpt
Step:8150 , train loss : 0.6919906735420227
Step:8150 , test loss : 0.6929064393043518
\# Save into ./models/ckpt\_model/ckpt
Step:8200 , train loss : 0.6930703520774841
Step:8200 , test loss : 0.6922609210014343
\# Save into ./models/ckpt\_model/ckpt
Step:8250 , train loss : 0.6557815670967102
Step:8250 , test loss : 0.6937991976737976
\# Save into ./models/ckpt\_model/ckpt
Step:8300 , train loss : 0.6934505701065063
Step:8300 , test loss : 0.6916513442993164
\# Save into ./models/ckpt\_model/ckpt
Step:8350 , train loss : 0.6903917789459229
Step:8350 , test loss : 0.6958485245704651
\# Save into ./models/ckpt\_model/ckpt
Step:8400 , train loss : 0.7258804440498352
Step:8400 , test loss : 0.691799521446228
\# Save into ./models/ckpt\_model/ckpt
Step:8450 , train loss : 0.6970279216766357
Step:8450 , test loss : 0.6982532739639282
\# Save into ./models/ckpt\_model/ckpt
Step:8500 , train loss : 0.6862074136734009
Step:8500 , test loss : 0.6912006139755249
\# Save into ./models/ckpt\_model/ckpt
Step:8550 , train loss : 0.6414368152618408
Step:8550 , test loss : 0.6929671168327332
\# Save into ./models/ckpt\_model/ckpt
Step:8600 , train loss : 0.6744641065597534
Step:8600 , test loss : 0.6910774111747742
\# Save into ./models/ckpt\_model/ckpt
Step:8650 , train loss : 0.6893057823181152
Step:8650 , test loss : 0.6908189058303833
\# Save into ./models/ckpt\_model/ckpt
Step:8700 , train loss : 0.6452034711837769
Step:8700 , test loss : 0.6918890476226807
\# Save into ./models/ckpt\_model/ckpt
Step:8750 , train loss : 0.6669332385063171
Step:8750 , test loss : 0.6947616338729858
\# Save into ./models/ckpt\_model/ckpt
Step:8800 , train loss : 0.6876324415206909
Step:8800 , test loss : 0.6912424564361572
\# Save into ./models/ckpt\_model/ckpt
Step:8850 , train loss : 0.6987574100494385
Step:8850 , test loss : 0.6906885504722595
\# Save into ./models/ckpt\_model/ckpt
Step:8900 , train loss : 0.6862993240356445
Step:8900 , test loss : 0.6909019947052002
\# Save into ./models/ckpt\_model/ckpt
Step:8950 , train loss : 0.6953481435775757
Step:8950 , test loss : 0.6906888484954834
\# Save into ./models/ckpt\_model/ckpt
Step:9000 , train loss : 0.6955822110176086
Step:9000 , test loss : 0.6922083497047424
\# Save into ./models/ckpt\_model/ckpt
Step:9050 , train loss : 0.6949329376220703
Step:9050 , test loss : 0.6907083988189697
\# Save into ./models/ckpt\_model/ckpt
Step:9100 , train loss : 0.6762337684631348
Step:9100 , test loss : 0.6910377740859985
\# Save into ./models/ckpt\_model/ckpt
Step:9150 , train loss : 0.6557688117027283
Step:9150 , test loss : 0.6928741931915283
\# Save into ./models/ckpt\_model/ckpt
Step:9200 , train loss : 0.6821441054344177
Step:9200 , test loss : 0.6931236386299133
\# Save into ./models/ckpt\_model/ckpt
Step:9250 , train loss : 0.6854841113090515
Step:9250 , test loss : 0.6907125115394592
\# Save into ./models/ckpt\_model/ckpt
Step:9300 , train loss : 0.6895210146903992
Step:9300 , test loss : 0.6923916339874268
\# Save into ./models/ckpt\_model/ckpt
Step:9350 , train loss : 0.6719653606414795
Step:9350 , test loss : 0.6909177303314209
\# Save into ./models/ckpt\_model/ckpt
Step:9400 , train loss : 0.6883974075317383
Step:9400 , test loss : 0.6926499605178833
\# Save into ./models/ckpt\_model/ckpt
Step:9450 , train loss : 0.6514540910720825
Step:9450 , test loss : 0.6924182772636414
\# Save into ./models/ckpt\_model/ckpt
Step:9500 , train loss : 0.6947975158691406
Step:9500 , test loss : 0.691180944442749
\# Save into ./models/ckpt\_model/ckpt
Step:9550 , train loss : 0.6871568560600281
Step:9550 , test loss : 0.6906845569610596
\# Save into ./models/ckpt\_model/ckpt
Step:9600 , train loss : 0.7110657691955566
Step:9600 , test loss : 0.6909351944923401
\# Save into ./models/ckpt\_model/ckpt
Step:9650 , train loss : 0.7037471532821655
Step:9650 , test loss : 0.7017322778701782
\# Save into ./models/ckpt\_model/ckpt
Step:9700 , train loss : 0.704181432723999
Step:9700 , test loss : 0.6907219886779785
\# Save into ./models/ckpt\_model/ckpt
Step:9750 , train loss : 0.6767668128013611
Step:9750 , test loss : 0.6907615065574646
\# Save into ./models/ckpt\_model/ckpt
Step:9800 , train loss : 0.6673751473426819
Step:9800 , test loss : 0.6973419189453125
\# Save into ./models/ckpt\_model/ckpt
Step:9850 , train loss : 0.6956949234008789
Step:9850 , test loss : 0.6934298276901245
\# Save into ./models/ckpt\_model/ckpt
Step:9900 , train loss : 0.6699938178062439
Step:9900 , test loss : 0.6907453536987305
\# Save into ./models/ckpt\_model/ckpt
Step:9950 , train loss : 0.6775156855583191
Step:9950 , test loss : 0.6906862258911133
\# Save into ./models/ckpt\_model/ckpt
Step:10000 , train loss : 0.6938086748123169
Step:10000 , test loss : 0.692399263381958
\# Save into ./models/ckpt\_model/ckpt
Step:10050 , train loss : 0.6751168370246887
Step:10050 , test loss : 0.6909513473510742
\# Save into ./models/ckpt\_model/ckpt
Step:10100 , train loss : 0.6897281408309937
Step:10100 , test loss : 0.6934580206871033
\# Save into ./models/ckpt\_model/ckpt
Step:10150 , train loss : 0.6903494000434875
Step:10150 , test loss : 0.690709114074707
\# Save into ./models/ckpt\_model/ckpt
Step:10200 , train loss : 0.6834085583686829
Step:10200 , test loss : 0.6909493803977966
\# Save into ./models/ckpt\_model/ckpt
Step:10250 , train loss : 0.6840870380401611
Step:10250 , test loss : 0.6910734176635742
\# Save into ./models/ckpt\_model/ckpt
Step:10300 , train loss : 0.6768419742584229
Step:10300 , test loss : 0.6938860416412354
\# Save into ./models/ckpt\_model/ckpt
Step:10350 , train loss : 0.7005818486213684
Step:10350 , test loss : 0.692528486251831
\# Save into ./models/ckpt\_model/ckpt
Step:10400 , train loss : 0.7112891674041748
Step:10400 , test loss : 0.7025473117828369
\# Save into ./models/ckpt\_model/ckpt
Step:10450 , train loss : 0.6889643669128418
Step:10450 , test loss : 0.6936240792274475
\# Save into ./models/ckpt\_model/ckpt
Step:10500 , train loss : 0.6833450198173523
Step:10500 , test loss : 0.6924363374710083
\# Save into ./models/ckpt\_model/ckpt
Step:10550 , train loss : 0.6819779276847839
Step:10550 , test loss : 0.6906828880310059
\# Save into ./models/ckpt\_model/ckpt
Step:10600 , train loss : 0.6906933784484863
Step:10600 , test loss : 0.6908320784568787
\# Save into ./models/ckpt\_model/ckpt
Step:10650 , train loss : 0.6513029932975769
Step:10650 , test loss : 0.691433846950531
\# Save into ./models/ckpt\_model/ckpt
Step:10700 , train loss : 0.6798738241195679
Step:10700 , test loss : 0.6914447546005249
\# Save into ./models/ckpt\_model/ckpt
Step:10750 , train loss : 0.6822684407234192
Step:10750 , test loss : 0.6908642053604126
\# Save into ./models/ckpt\_model/ckpt
Step:10800 , train loss : 0.6909664273262024
Step:10800 , test loss : 0.6929140686988831
\# Save into ./models/ckpt\_model/ckpt
Step:10850 , train loss : 0.6946500539779663
Step:10850 , test loss : 0.6924656629562378
\# Save into ./models/ckpt\_model/ckpt
Step:10900 , train loss : 0.6732144951820374
Step:10900 , test loss : 0.6940456628799438
\# Save into ./models/ckpt\_model/ckpt
Step:10950 , train loss : 0.7255082726478577
Step:10950 , test loss : 0.6907251477241516
\# Save into ./models/ckpt\_model/ckpt
Step:11000 , train loss : 0.6810867190361023
Step:11000 , test loss : 0.6907368302345276
\# Save into ./models/ckpt\_model/ckpt
Step:11050 , train loss : 0.6925932168960571
Step:11050 , test loss : 0.6909826397895813
\# Save into ./models/ckpt\_model/ckpt
Step:11100 , train loss : 0.7647807002067566
Step:11100 , test loss : 0.6952356696128845
\# Save into ./models/ckpt\_model/ckpt
Step:11150 , train loss : 0.6595175862312317
Step:11150 , test loss : 0.6923174262046814
\# Save into ./models/ckpt\_model/ckpt
Step:11200 , train loss : 0.6609306931495667
Step:11200 , test loss : 0.6953272223472595
\# Save into ./models/ckpt\_model/ckpt
Step:11250 , train loss : 0.6930935382843018
Step:11250 , test loss : 0.6930981874465942
\# Save into ./models/ckpt\_model/ckpt
Step:11300 , train loss : 0.6921029090881348
Step:11300 , test loss : 0.6930856108665466
\# Save into ./models/ckpt\_model/ckpt
Step:11350 , train loss : 0.6924984455108643
Step:11350 , test loss : 0.6930524706840515
\# Save into ./models/ckpt\_model/ckpt
Step:11400 , train loss : 0.692945659160614
Step:11400 , test loss : 0.6929877400398254
\# Save into ./models/ckpt\_model/ckpt
Step:11450 , train loss : 0.6908402442932129
Step:11450 , test loss : 0.6927404999732971
\# Save into ./models/ckpt\_model/ckpt
Step:11500 , train loss : 0.6640655994415283
Step:11500 , test loss : 0.6921038627624512
\# Save into ./models/ckpt\_model/ckpt
Step:11550 , train loss : 0.7019814848899841
Step:11550 , test loss : 0.6920979022979736
\# Save into ./models/ckpt\_model/ckpt
Step:11600 , train loss : 0.6704654097557068
Step:11600 , test loss : 0.6909151673316956
\# Save into ./models/ckpt\_model/ckpt
Step:11650 , train loss : 0.7307525873184204
Step:11650 , test loss : 0.694056510925293
\# Save into ./models/ckpt\_model/ckpt
Step:11700 , train loss : 0.685595691204071
Step:11700 , test loss : 0.6906971335411072
\# Save into ./models/ckpt\_model/ckpt
Step:11750 , train loss : 0.6842139959335327
Step:11750 , test loss : 0.6906837821006775
\# Save into ./models/ckpt\_model/ckpt
Step:11800 , train loss : 0.6981582045555115
Step:11800 , test loss : 0.6914581656455994
\# Save into ./models/ckpt\_model/ckpt
Step:11850 , train loss : 0.6320610642433167
Step:11850 , test loss : 0.6947838068008423
\# Save into ./models/ckpt\_model/ckpt
Step:11900 , train loss : 0.6916512250900269
Step:11900 , test loss : 0.6907438039779663
\# Save into ./models/ckpt\_model/ckpt
Step:11950 , train loss : 0.6905798316001892
Step:11950 , test loss : 0.6923835277557373
\# Save into ./models/ckpt\_model/ckpt
Step:12000 , train loss : 0.6849510073661804
Step:12000 , test loss : 0.6907052993774414
\# Save into ./models/ckpt\_model/ckpt
Step:12050 , train loss : 0.6920235753059387
Step:12050 , test loss : 0.6918107271194458
\# Save into ./models/ckpt\_model/ckpt
Step:12100 , train loss : 0.6913177371025085
Step:12100 , test loss : 0.6921627521514893
\# Save into ./models/ckpt\_model/ckpt
Step:12150 , train loss : 0.6954542994499207
Step:12150 , test loss : 0.6909606456756592
\# Save into ./models/ckpt\_model/ckpt
Step:12200 , train loss : 0.6835699677467346
Step:12200 , test loss : 0.6968798637390137
\# Save into ./models/ckpt\_model/ckpt
Step:12250 , train loss : 0.6880921721458435
Step:12250 , test loss : 0.6912594437599182
\# Save into ./models/ckpt\_model/ckpt
Step:12300 , train loss : 0.7000875473022461
Step:12300 , test loss : 0.6925908327102661
\# Save into ./models/ckpt\_model/ckpt
Step:12350 , train loss : 0.6943539381027222
Step:12350 , test loss : 0.6910892724990845
\# Save into ./models/ckpt\_model/ckpt
Step:12400 , train loss : 0.6754997968673706
Step:12400 , test loss : 0.6933857202529907
\# Save into ./models/ckpt\_model/ckpt
Step:12450 , train loss : 0.6717815399169922
Step:12450 , test loss : 0.690753698348999
\# Save into ./models/ckpt\_model/ckpt
Step:12500 , train loss : 0.6906347274780273
Step:12500 , test loss : 0.6925663352012634
\# Save into ./models/ckpt\_model/ckpt
Step:12550 , train loss : 0.6958236694335938
Step:12550 , test loss : 0.6927934885025024
\# Save into ./models/ckpt\_model/ckpt
Step:12600 , train loss : 0.6883179545402527
Step:12600 , test loss : 0.6918516755104065
\# Save into ./models/ckpt\_model/ckpt
Step:12650 , train loss : 0.7046105265617371
Step:12650 , test loss : 0.6915130615234375
\# Save into ./models/ckpt\_model/ckpt
Step:12700 , train loss : 0.6765662431716919
Step:12700 , test loss : 0.6907870769500732
\# Save into ./models/ckpt\_model/ckpt
Step:12750 , train loss : 0.6905027031898499
Step:12750 , test loss : 0.6924669146537781
\# Save into ./models/ckpt\_model/ckpt
Step:12800 , train loss : 0.6925514936447144
Step:12800 , test loss : 0.6915290951728821
\# Save into ./models/ckpt\_model/ckpt
Step:12850 , train loss : 0.6898993253707886
Step:12850 , test loss : 0.6926405429840088
\# Save into ./models/ckpt\_model/ckpt
Step:12900 , train loss : 0.6962502598762512
Step:12900 , test loss : 0.6925748586654663
\# Save into ./models/ckpt\_model/ckpt
Step:12950 , train loss : 0.6618916392326355
Step:12950 , test loss : 0.7004358768463135
\# Save into ./models/ckpt\_model/ckpt
Step:13000 , train loss : 0.6937339901924133
Step:13000 , test loss : 0.6944584250450134
\# Save into ./models/ckpt\_model/ckpt
Step:13050 , train loss : 0.6911881566047668
Step:13050 , test loss : 0.6928837895393372
\# Save into ./models/ckpt\_model/ckpt
Step:13100 , train loss : 0.6914310455322266
Step:13100 , test loss : 0.6927827596664429
\# Save into ./models/ckpt\_model/ckpt
Step:13150 , train loss : 0.6772682666778564
Step:13150 , test loss : 0.6917523145675659
\# Save into ./models/ckpt\_model/ckpt
Step:13200 , train loss : 0.6606776714324951
Step:13200 , test loss : 0.6920139789581299
\# Save into ./models/ckpt\_model/ckpt
Step:13250 , train loss : 0.6845359206199646
Step:13250 , test loss : 0.6908568143844604
\# Save into ./models/ckpt\_model/ckpt
Step:13300 , train loss : 0.7214786410331726
Step:13300 , test loss : 0.6950047016143799
\# Save into ./models/ckpt\_model/ckpt
Step:13350 , train loss : 0.8534442782402039
Step:13350 , test loss : 0.6935304403305054
\# Save into ./models/ckpt\_model/ckpt
Step:13400 , train loss : 0.6930127143859863
Step:13400 , test loss : 0.6928554177284241
\# Save into ./models/ckpt\_model/ckpt
Step:13450 , train loss : 0.6862497925758362
Step:13450 , test loss : 0.6910077929496765
\# Save into ./models/ckpt\_model/ckpt
Step:13500 , train loss : 0.6906887888908386
Step:13500 , test loss : 0.6927310228347778
\# Save into ./models/ckpt\_model/ckpt
Step:13550 , train loss : 0.6868493556976318
Step:13550 , test loss : 0.6911423802375793
\# Save into ./models/ckpt\_model/ckpt
Step:13600 , train loss : 0.6914297342300415
Step:13600 , test loss : 0.6921715140342712
\# Save into ./models/ckpt\_model/ckpt
Step:13650 , train loss : 0.6512806415557861
Step:13650 , test loss : 0.6915361881256104
\# Save into ./models/ckpt\_model/ckpt
Step:13700 , train loss : 0.7225152254104614
Step:13700 , test loss : 0.693276047706604
\# Save into ./models/ckpt\_model/ckpt
Step:13750 , train loss : 0.6901851892471313
Step:13750 , test loss : 0.6913566589355469
\# Save into ./models/ckpt\_model/ckpt
Step:13800 , train loss : 0.695690393447876
Step:13800 , test loss : 0.6909434199333191
\# Save into ./models/ckpt\_model/ckpt
Step:13850 , train loss : 0.6818817853927612
Step:13850 , test loss : 0.6915510296821594
\# Save into ./models/ckpt\_model/ckpt
Step:13900 , train loss : 0.7059526443481445
Step:13900 , test loss : 0.691858172416687
\# Save into ./models/ckpt\_model/ckpt
Step:13950 , train loss : 0.6367021203041077
Step:13950 , test loss : 0.6942780613899231
\# Save into ./models/ckpt\_model/ckpt
Step:14000 , train loss : 0.696832537651062
Step:14000 , test loss : 0.6912650465965271
\# Save into ./models/ckpt\_model/ckpt
Step:14050 , train loss : 0.6969881057739258
Step:14050 , test loss : 0.6906858682632446
\# Save into ./models/ckpt\_model/ckpt
Step:14100 , train loss : 0.7002637982368469
Step:14100 , test loss : 0.6925432085990906
\# Save into ./models/ckpt\_model/ckpt
Step:14150 , train loss : 0.6898808479309082
Step:14150 , test loss : 0.6925852298736572
\# Save into ./models/ckpt\_model/ckpt
Step:14200 , train loss : 0.7107335925102234
Step:14200 , test loss : 0.6911697387695312
\# Save into ./models/ckpt\_model/ckpt
Step:14250 , train loss : 0.6862062811851501
Step:14250 , test loss : 0.6918106079101562
\# Save into ./models/ckpt\_model/ckpt
Step:14300 , train loss : 0.6953109502792358
Step:14300 , test loss : 0.6906842589378357
\# Save into ./models/ckpt\_model/ckpt
Step:14350 , train loss : 0.6976444721221924
Step:14350 , test loss : 0.6954440474510193
\# Save into ./models/ckpt\_model/ckpt
Step:14400 , train loss : 0.7348892092704773
Step:14400 , test loss : 0.6944745779037476
\# Save into ./models/ckpt\_model/ckpt
Step:14450 , train loss : 0.6938471794128418
Step:14450 , test loss : 0.6913085579872131
\# Save into ./models/ckpt\_model/ckpt
Step:14500 , train loss : 0.6581190824508667
Step:14500 , test loss : 0.6917856931686401
\# Save into ./models/ckpt\_model/ckpt
Step:14550 , train loss : 0.6956050992012024
Step:14550 , test loss : 0.6917077898979187
\# Save into ./models/ckpt\_model/ckpt
Step:14600 , train loss : 0.6891555786132812
Step:14600 , test loss : 0.6914168000221252
\# Save into ./models/ckpt\_model/ckpt
Step:14650 , train loss : 0.6964765787124634
Step:14650 , test loss : 0.6911835670471191
\# Save into ./models/ckpt\_model/ckpt
Step:14700 , train loss : 0.683434247970581
Step:14700 , test loss : 0.6912891864776611
\# Save into ./models/ckpt\_model/ckpt
Step:14750 , train loss : 0.7036657333374023
Step:14750 , test loss : 0.6963014006614685
\# Save into ./models/ckpt\_model/ckpt
Step:14800 , train loss : 0.6718096733093262
Step:14800 , test loss : 0.6906909346580505
\# Save into ./models/ckpt\_model/ckpt
Step:14850 , train loss : 0.6840248703956604
Step:14850 , test loss : 0.6908292174339294
\# Save into ./models/ckpt\_model/ckpt
Step:14900 , train loss : 0.6903356313705444
Step:14900 , test loss : 0.6907010674476624
\# Save into ./models/ckpt\_model/ckpt
Step:14950 , train loss : 0.7020130157470703
Step:14950 , test loss : 0.6908071041107178
\# Save into ./models/ckpt\_model/ckpt
Step:15000 , train loss : 0.6870864033699036
Step:15000 , test loss : 0.6926356554031372
\# Save into ./models/ckpt\_model/ckpt
Step:15050 , train loss : 0.6529289484024048
Step:15050 , test loss : 0.6955216526985168
\# Save into ./models/ckpt\_model/ckpt
Step:15100 , train loss : 0.6696174144744873
Step:15100 , test loss : 0.6928191781044006
\# Save into ./models/ckpt\_model/ckpt
Step:15150 , train loss : 0.6807581782341003
Step:15150 , test loss : 0.6907638907432556
\# Save into ./models/ckpt\_model/ckpt
Step:15200 , train loss : 0.7131562829017639
Step:15200 , test loss : 0.6916223764419556
\# Save into ./models/ckpt\_model/ckpt
Step:15250 , train loss : 0.6992511749267578
Step:15250 , test loss : 0.6908674240112305
\# Save into ./models/ckpt\_model/ckpt
Step:15300 , train loss : 0.6858863830566406
Step:15300 , test loss : 0.6906919479370117
\# Save into ./models/ckpt\_model/ckpt
Step:15350 , train loss : 0.6927595138549805
Step:15350 , test loss : 0.6930769681930542
\# Save into ./models/ckpt\_model/ckpt
Step:15400 , train loss : 0.692512571811676
Step:15400 , test loss : 0.6930901408195496
\# Save into ./models/ckpt\_model/ckpt
Step:15450 , train loss : 0.6912714838981628
Step:15450 , test loss : 0.6930641531944275
\# Save into ./models/ckpt\_model/ckpt
Step:15500 , train loss : 0.6931828856468201
Step:15500 , test loss : 0.6930159330368042
\# Save into ./models/ckpt\_model/ckpt
Step:15550 , train loss : 0.6942475438117981
Step:15550 , test loss : 0.692889928817749
\# Save into ./models/ckpt\_model/ckpt
Step:15600 , train loss : 0.6812826991081238
Step:15600 , test loss : 0.6915510892868042
\# Save into ./models/ckpt\_model/ckpt
Step:15650 , train loss : 0.6919876337051392
Step:15650 , test loss : 0.6910120248794556
\# Save into ./models/ckpt\_model/ckpt
Step:15700 , train loss : 0.6842073202133179
Step:15700 , test loss : 0.6909948587417603
\# Save into ./models/ckpt\_model/ckpt
Step:15750 , train loss : 0.6835947632789612
Step:15750 , test loss : 0.6908096075057983
\# Save into ./models/ckpt\_model/ckpt
Step:15800 , train loss : 0.6950277090072632
Step:15800 , test loss : 0.6906834244728088
\# Save into ./models/ckpt\_model/ckpt
Step:15850 , train loss : 0.7090885639190674
Step:15850 , test loss : 0.6909670233726501
\# Save into ./models/ckpt\_model/ckpt
Step:15900 , train loss : 0.7002058029174805
Step:15900 , test loss : 0.6925578713417053
\# Save into ./models/ckpt\_model/ckpt
Step:15950 , train loss : 0.6799019575119019
Step:15950 , test loss : 0.690767228603363
\# Save into ./models/ckpt\_model/ckpt
Step:16000 , train loss : 0.6858617067337036
Step:16000 , test loss : 0.6912269592285156
\# Save into ./models/ckpt\_model/ckpt
Step:16050 , train loss : 0.727331817150116
Step:16050 , test loss : 0.6946667432785034
\# Save into ./models/ckpt\_model/ckpt
Step:16100 , train loss : 0.6423172950744629
Step:16100 , test loss : 0.7075954079627991
\# Save into ./models/ckpt\_model/ckpt
Step:16150 , train loss : 0.6858490109443665
Step:16150 , test loss : 0.6921106576919556
\# Save into ./models/ckpt\_model/ckpt
Step:16200 , train loss : 0.6904636025428772
Step:16200 , test loss : 0.6914168000221252
\# Save into ./models/ckpt\_model/ckpt
Step:16250 , train loss : 0.6878296136856079
Step:16250 , test loss : 0.6906852722167969
\# Save into ./models/ckpt\_model/ckpt
Step:16300 , train loss : 0.6821836233139038
Step:16300 , test loss : 0.6907490491867065
\# Save into ./models/ckpt\_model/ckpt
Step:16350 , train loss : 0.6796091198921204
Step:16350 , test loss : 0.6914128661155701
\# Save into ./models/ckpt\_model/ckpt
Step:16400 , train loss : 0.686332106590271
Step:16400 , test loss : 0.6914829015731812
\# Save into ./models/ckpt\_model/ckpt
Step:16450 , train loss : 0.6844291090965271
Step:16450 , test loss : 0.6907060742378235
\# Save into ./models/ckpt\_model/ckpt
Step:16500 , train loss : 0.6453404426574707
Step:16500 , test loss : 0.6906881332397461
\# Save into ./models/ckpt\_model/ckpt
Step:16550 , train loss : 0.7036601305007935
Step:16550 , test loss : 0.6993774771690369
\# Save into ./models/ckpt\_model/ckpt
Step:16600 , train loss : 0.6878796815872192
Step:16600 , test loss : 0.6908169984817505
\# Save into ./models/ckpt\_model/ckpt
Step:16650 , train loss : 0.6788862347602844
Step:16650 , test loss : 0.690920889377594
\# Save into ./models/ckpt\_model/ckpt
Step:16700 , train loss : 0.7043469548225403
Step:16700 , test loss : 0.6943773031234741
\# Save into ./models/ckpt\_model/ckpt
Step:16750 , train loss : 0.6886910796165466
Step:16750 , test loss : 0.6912328600883484
\# Save into ./models/ckpt\_model/ckpt
Step:16800 , train loss : 0.6613532900810242
Step:16800 , test loss : 0.6906862258911133
\# Save into ./models/ckpt\_model/ckpt
Step:16850 , train loss : 0.6844829320907593
Step:16850 , test loss : 0.691429078578949
\# Save into ./models/ckpt\_model/ckpt
Step:16900 , train loss : 0.6902462244033813
Step:16900 , test loss : 0.6923590302467346
\# Save into ./models/ckpt\_model/ckpt
Step:16950 , train loss : 0.7027342915534973
Step:16950 , test loss : 0.6909403204917908
\# Save into ./models/ckpt\_model/ckpt
Step:17000 , train loss : 0.6607992649078369
Step:17000 , test loss : 0.6915359497070312
\# Save into ./models/ckpt\_model/ckpt
Step:17050 , train loss : 0.7165688872337341
Step:17050 , test loss : 0.6918674111366272
\# Save into ./models/ckpt\_model/ckpt
Step:17100 , train loss : 0.68717360496521
Step:17100 , test loss : 0.692963182926178
\# Save into ./models/ckpt\_model/ckpt
Step:17150 , train loss : 0.6889893412590027
Step:17150 , test loss : 0.6925832629203796
\# Save into ./models/ckpt\_model/ckpt
Step:17200 , train loss : 0.6993184089660645
Step:17200 , test loss : 0.6908982992172241
\# Save into ./models/ckpt\_model/ckpt
Step:17250 , train loss : 0.6497198939323425
Step:17250 , test loss : 0.6917829513549805
\# Save into ./models/ckpt\_model/ckpt
Step:17300 , train loss : 0.6794483661651611
Step:17300 , test loss : 0.6907300353050232
\# Save into ./models/ckpt\_model/ckpt
Step:17350 , train loss : 0.6664602160453796
Step:17350 , test loss : 0.6906836032867432
\# Save into ./models/ckpt\_model/ckpt
Step:17400 , train loss : 0.6884594559669495
Step:17400 , test loss : 0.6915440559387207
\# Save into ./models/ckpt\_model/ckpt
Step:17450 , train loss : 0.6609170436859131
Step:17450 , test loss : 0.712207019329071
\# Save into ./models/ckpt\_model/ckpt
Step:17500 , train loss : 0.6920953392982483
Step:17500 , test loss : 0.6917616724967957
\# Save into ./models/ckpt\_model/ckpt
Step:17550 , train loss : 0.6887825131416321
Step:17550 , test loss : 0.6925477981567383
\# Save into ./models/ckpt\_model/ckpt
Step:17600 , train loss : 0.7516562938690186
Step:17600 , test loss : 0.726865291595459
\# Save into ./models/ckpt\_model/ckpt
Step:17650 , train loss : 0.6959221363067627
Step:17650 , test loss : 0.6928503513336182
\# Save into ./models/ckpt\_model/ckpt
Step:17700 , train loss : 0.6803712844848633
Step:17700 , test loss : 0.6922208070755005
\# Save into ./models/ckpt\_model/ckpt
Step:17750 , train loss : 0.6776818037033081
Step:17750 , test loss : 0.6908426880836487
\# Save into ./models/ckpt\_model/ckpt
Step:17800 , train loss : 0.6904364228248596
Step:17800 , test loss : 0.6908870935440063
\# Save into ./models/ckpt\_model/ckpt
Step:17850 , train loss : 0.7009860873222351
Step:17850 , test loss : 0.6932318210601807
\# Save into ./models/ckpt\_model/ckpt
Step:17900 , train loss : 0.6865663528442383
Step:17900 , test loss : 0.6944215297698975
\# Save into ./models/ckpt\_model/ckpt
Step:17950 , train loss : 0.6787227392196655
Step:17950 , test loss : 0.6907622218132019
\# Save into ./models/ckpt\_model/ckpt
Step:18000 , train loss : 0.676642894744873
Step:18000 , test loss : 0.6906834840774536
\# Save into ./models/ckpt\_model/ckpt
Step:18050 , train loss : 0.7026888132095337
Step:18050 , test loss : 0.6912983655929565
\# Save into ./models/ckpt\_model/ckpt
Step:18100 , train loss : 0.6815426349639893
Step:18100 , test loss : 0.690829336643219
\# Save into ./models/ckpt\_model/ckpt
Step:18150 , train loss : 0.6639297604560852
Step:18150 , test loss : 0.6909228563308716
\# Save into ./models/ckpt\_model/ckpt
Step:18200 , train loss : 0.6867651343345642
Step:18200 , test loss : 0.6913782954216003
\# Save into ./models/ckpt\_model/ckpt
Step:18250 , train loss : 0.6779149174690247
Step:18250 , test loss : 0.690701425075531
\# Save into ./models/ckpt\_model/ckpt
Step:18300 , train loss : 0.660692036151886
Step:18300 , test loss : 0.6993588209152222
\# Save into ./models/ckpt\_model/ckpt
Step:18350 , train loss : 0.6983475685119629
Step:18350 , test loss : 0.691590428352356
\# Save into ./models/ckpt\_model/ckpt
Step:18400 , train loss : 0.6954668164253235
Step:18400 , test loss : 0.6914154887199402
\# Save into ./models/ckpt\_model/ckpt
Step:18450 , train loss : 0.6643733382225037
Step:18450 , test loss : 0.6925113201141357
\# Save into ./models/ckpt\_model/ckpt
Step:18500 , train loss : 0.6915490627288818
Step:18500 , test loss : 0.6910258531570435
\# Save into ./models/ckpt\_model/ckpt
Step:18550 , train loss : 0.680095911026001
Step:18550 , test loss : 0.6906829476356506
\# Save into ./models/ckpt\_model/ckpt
Step:18600 , train loss : 0.6929224133491516
Step:18600 , test loss : 0.6925511956214905
\# Save into ./models/ckpt\_model/ckpt
Step:18650 , train loss : 0.7150493860244751
Step:18650 , test loss : 0.6970173120498657
\# Save into ./models/ckpt\_model/ckpt
Step:18700 , train loss : 0.6918732523918152
Step:18700 , test loss : 0.6953853964805603
\# Save into ./models/ckpt\_model/ckpt
Step:18750 , train loss : 0.767950713634491
Step:18750 , test loss : 0.6913928389549255
\# Save into ./models/ckpt\_model/ckpt
Step:18800 , train loss : 0.6924662590026855
Step:18800 , test loss : 0.690852701663971
\# Save into ./models/ckpt\_model/ckpt
Step:18850 , train loss : 0.6842588186264038
Step:18850 , test loss : 0.6910890936851501
\# Save into ./models/ckpt\_model/ckpt
Step:18900 , train loss : 0.7262463569641113
Step:18900 , test loss : 0.6907460689544678
\# Save into ./models/ckpt\_model/ckpt
Step:18950 , train loss : 0.6708939075469971
Step:18950 , test loss : 0.6912099123001099
\# Save into ./models/ckpt\_model/ckpt
Step:19000 , train loss : 0.6993175745010376
Step:19000 , test loss : 0.6994088292121887
\# Save into ./models/ckpt\_model/ckpt
Step:19050 , train loss : 0.689216136932373
Step:19050 , test loss : 0.692837119102478
\# Save into ./models/ckpt\_model/ckpt
Step:19100 , train loss : 0.6864709854125977
Step:19100 , test loss : 0.6910589933395386
\# Save into ./models/ckpt\_model/ckpt
Step:19150 , train loss : 0.6811336278915405
Step:19150 , test loss : 0.6910237073898315
\# Save into ./models/ckpt\_model/ckpt
Step:19200 , train loss : 0.7018411159515381
Step:19200 , test loss : 0.691604733467102
\# Save into ./models/ckpt\_model/ckpt
Step:19250 , train loss : 0.6927356719970703
Step:19250 , test loss : 0.69085693359375
\# Save into ./models/ckpt\_model/ckpt
Step:19300 , train loss : 0.7105458378791809
Step:19300 , test loss : 0.6929262280464172
\# Save into ./models/ckpt\_model/ckpt
Step:19350 , train loss : 0.6611701250076294
Step:19350 , test loss : 0.6938797235488892
\# Save into ./models/ckpt\_model/ckpt
Step:19400 , train loss : 0.6912233233451843
Step:19400 , test loss : 0.6928384900093079
\# Save into ./models/ckpt\_model/ckpt
Step:19450 , train loss : 0.6881241798400879
Step:19450 , test loss : 0.6918561458587646
\# Save into ./models/ckpt\_model/ckpt
Step:19500 , train loss : 0.6921641230583191
Step:19500 , test loss : 0.6909935474395752
\# Save into ./models/ckpt\_model/ckpt
Step:19550 , train loss : 0.6767953038215637
Step:19550 , test loss : 0.7001355290412903
\# Save into ./models/ckpt\_model/ckpt
Step:19600 , train loss : 0.6731065511703491
Step:19600 , test loss : 0.6910766363143921
\# Save into ./models/ckpt\_model/ckpt
Step:19650 , train loss : 0.6962218880653381
Step:19650 , test loss : 0.691524088382721
\# Save into ./models/ckpt\_model/ckpt
Step:19700 , train loss : 0.6786686182022095
Step:19700 , test loss : 0.6974101662635803
\# Save into ./models/ckpt\_model/ckpt
Step:19750 , train loss : 0.6731598377227783
Step:19750 , test loss : 0.6924638152122498
\# Save into ./models/ckpt\_model/ckpt
Step:19800 , train loss : 0.6885731816291809
Step:19800 , test loss : 0.6910847425460815
\# Save into ./models/ckpt\_model/ckpt
Step:19850 , train loss : 0.6931130886077881
Step:19850 , test loss : 0.690689206123352
\# Save into ./models/ckpt\_model/ckpt
Step:19900 , train loss : 0.6927672624588013
Step:19900 , test loss : 0.6921508312225342
\# Save into ./models/ckpt\_model/ckpt
Step:19950 , train loss : 0.6963579654693604
Step:19950 , test loss : 0.691473126411438
\# Save into ./models/ckpt\_model/ckpt
Step:20000 , train loss : 0.6695414781570435
Step:20000 , test loss : 0.6906945109367371
\# Save into ./models/ckpt\_model/ckpt
Step:20050 , train loss : 0.6777093410491943
Step:20050 , test loss : 0.6906869411468506
\# Save into ./models/ckpt\_model/ckpt
Step:20100 , train loss : 0.7043280601501465
Step:20100 , test loss : 0.6906983852386475
\# Save into ./models/ckpt\_model/ckpt
Step:20150 , train loss : 0.6790144443511963
Step:20150 , test loss : 0.6907695531845093
\# Save into ./models/ckpt\_model/ckpt
Step:20200 , train loss : 0.6937193870544434
Step:20200 , test loss : 0.6912447810173035
\# Save into ./models/ckpt\_model/ckpt
Step:20250 , train loss : 0.6826958656311035
Step:20250 , test loss : 0.691292405128479
\# Save into ./models/ckpt\_model/ckpt
Step:20300 , train loss : 0.6806602478027344
Step:20300 , test loss : 0.690696120262146
\# Save into ./models/ckpt\_model/ckpt
Step:20350 , train loss : 0.6908384561538696
Step:20350 , test loss : 0.6942862272262573
\# Save into ./models/ckpt\_model/ckpt
Step:20400 , train loss : 0.7217085957527161
Step:20400 , test loss : 0.6907386779785156
\# Save into ./models/ckpt\_model/ckpt
Step:20450 , train loss : 0.6740776300430298
Step:20450 , test loss : 0.6907098889350891
\# Save into ./models/ckpt\_model/ckpt
Step:20500 , train loss : 0.6917737722396851
Step:20500 , test loss : 0.6906998157501221
\# Save into ./models/ckpt\_model/ckpt
Step:20550 , train loss : 0.6794121861457825
Step:20550 , test loss : 0.6929970979690552
\# Save into ./models/ckpt\_model/ckpt
Step:20600 , train loss : 0.6835373044013977
Step:20600 , test loss : 0.6909868717193604
\# Save into ./models/ckpt\_model/ckpt
Step:20650 , train loss : 0.6904677152633667
Step:20650 , test loss : 0.6913855671882629
\# Save into ./models/ckpt\_model/ckpt
Step:20700 , train loss : 0.6777399182319641
Step:20700 , test loss : 0.6911388635635376
\# Save into ./models/ckpt\_model/ckpt
Step:20750 , train loss : 0.6797623634338379
Step:20750 , test loss : 0.6927680373191833
\# Save into ./models/ckpt\_model/ckpt
Step:20800 , train loss : 0.6894413232803345
Step:20800 , test loss : 0.6940763592720032
\# Save into ./models/ckpt\_model/ckpt
Step:20850 , train loss : 0.6984381675720215
Step:20850 , test loss : 0.69110506772995
\# Save into ./models/ckpt\_model/ckpt
Step:20900 , train loss : 0.6954981088638306
Step:20900 , test loss : 0.6912339925765991
\# Save into ./models/ckpt\_model/ckpt
Step:20950 , train loss : 0.6850005984306335
Step:20950 , test loss : 0.690740168094635
\# Save into ./models/ckpt\_model/ckpt
Step:21000 , train loss : 0.6746527552604675
Step:21000 , test loss : 0.6913663744926453
\# Save into ./models/ckpt\_model/ckpt
Step:21050 , train loss : 0.6911180019378662
Step:21050 , test loss : 0.6907129883766174
\# Save into ./models/ckpt\_model/ckpt
Step:21100 , train loss : 0.6961308121681213
Step:21100 , test loss : 0.691774308681488
\# Save into ./models/ckpt\_model/ckpt
Step:21150 , train loss : 0.6754376292228699
Step:21150 , test loss : 0.6918541193008423
\# Save into ./models/ckpt\_model/ckpt
Step:21200 , train loss : 0.6882981061935425
Step:21200 , test loss : 0.6919857263565063
\# Save into ./models/ckpt\_model/ckpt
Step:21250 , train loss : 0.6784420013427734
Step:21250 , test loss : 0.6913725137710571
\# Save into ./models/ckpt\_model/ckpt
Step:21300 , train loss : 0.6934677958488464
Step:21300 , test loss : 0.690688967704773
\# Save into ./models/ckpt\_model/ckpt
Step:21350 , train loss : 0.6957639455795288
Step:21350 , test loss : 0.6909983158111572
\# Save into ./models/ckpt\_model/ckpt
Step:21400 , train loss : 0.6904332041740417
Step:21400 , test loss : 0.6920292973518372
\# Save into ./models/ckpt\_model/ckpt
Step:21450 , train loss : 0.680922269821167
Step:21450 , test loss : 0.6908887624740601
\# Save into ./models/ckpt\_model/ckpt
Step:21500 , train loss : 0.7002758979797363
Step:21500 , test loss : 0.6906858086585999
\# Save into ./models/ckpt\_model/ckpt
Step:21550 , train loss : 0.6706404685974121
Step:21550 , test loss : 0.6930394172668457
\# Save into ./models/ckpt\_model/ckpt
Step:21600 , train loss : 0.6839222311973572
Step:21600 , test loss : 0.6917111873626709
\# Save into ./models/ckpt\_model/ckpt
Step:21650 , train loss : 0.6811028718948364
Step:21650 , test loss : 0.6914437413215637
\# Save into ./models/ckpt\_model/ckpt
Step:21700 , train loss : 0.6746246814727783
Step:21700 , test loss : 0.6910941004753113
\# Save into ./models/ckpt\_model/ckpt
Step:21750 , train loss : 0.7071094512939453
Step:21750 , test loss : 0.6906901597976685
\# Save into ./models/ckpt\_model/ckpt
Step:21800 , train loss : 0.6922661066055298
Step:21800 , test loss : 0.6914292573928833
\# Save into ./models/ckpt\_model/ckpt
Step:21850 , train loss : 0.6879241466522217
Step:21850 , test loss : 0.6913666725158691
\# Save into ./models/ckpt\_model/ckpt
Step:21900 , train loss : 0.695633590221405
Step:21900 , test loss : 0.690686821937561
\# Save into ./models/ckpt\_model/ckpt
Step:21950 , train loss : 0.6783841848373413
Step:21950 , test loss : 0.690941333770752
\# Save into ./models/ckpt\_model/ckpt
Step:22000 , train loss : 0.6866811513900757
Step:22000 , test loss : 0.6908483505249023
\# Save into ./models/ckpt\_model/ckpt
Step:22050 , train loss : 0.7091276049613953
Step:22050 , test loss : 0.6906836628913879
\# Save into ./models/ckpt\_model/ckpt
Step:22100 , train loss : 0.7023364305496216
Step:22100 , test loss : 0.6946774125099182
\# Save into ./models/ckpt\_model/ckpt
Step:22150 , train loss : 0.6885741949081421
Step:22150 , test loss : 0.6919776797294617
\# Save into ./models/ckpt\_model/ckpt
Step:22200 , train loss : 0.6521256566047668
Step:22200 , test loss : 0.69119793176651
\# Save into ./models/ckpt\_model/ckpt
Step:22250 , train loss : 0.6825275421142578
Step:22250 , test loss : 0.7033926844596863
\# Save into ./models/ckpt\_model/ckpt
Step:22300 , train loss : 0.6895531415939331
Step:22300 , test loss : 0.6920173168182373
\# Save into ./models/ckpt\_model/ckpt
Step:22350 , train loss : 0.67652827501297
Step:22350 , test loss : 0.6907397508621216
\# Save into ./models/ckpt\_model/ckpt
Step:22400 , train loss : 0.6801258325576782
Step:22400 , test loss : 0.6917799711227417
\# Save into ./models/ckpt\_model/ckpt
Step:22450 , train loss : 0.6919249296188354
Step:22450 , test loss : 0.6923190951347351
\# Save into ./models/ckpt\_model/ckpt
Step:22500 , train loss : 0.6789210438728333
Step:22500 , test loss : 0.690750002861023
\# Save into ./models/ckpt\_model/ckpt
Step:22550 , train loss : 0.691561222076416
Step:22550 , test loss : 0.6927769184112549
\# Save into ./models/ckpt\_model/ckpt
Step:22600 , train loss : 0.6936057806015015
Step:22600 , test loss : 0.6907089352607727
\# Save into ./models/ckpt\_model/ckpt
Step:22650 , train loss : 0.739504337310791
Step:22650 , test loss : 0.6907364726066589
\# Save into ./models/ckpt\_model/ckpt
Step:22700 , train loss : 0.6908410787582397
Step:22700 , test loss : 0.6911016702651978
\# Save into ./models/ckpt\_model/ckpt
Step:22750 , train loss : 0.6839421987533569
Step:22750 , test loss : 0.6906854510307312
\# Save into ./models/ckpt\_model/ckpt
Step:22800 , train loss : 0.6764307022094727
Step:22800 , test loss : 0.6950682997703552
\# Save into ./models/ckpt\_model/ckpt
Step:22850 , train loss : 0.7243898510932922
Step:22850 , test loss : 0.6920595169067383
\# Save into ./models/ckpt\_model/ckpt
Step:22900 , train loss : 0.7000548839569092
Step:22900 , test loss : 0.6913162469863892
\# Save into ./models/ckpt\_model/ckpt
Step:22950 , train loss : 0.6884205341339111
Step:22950 , test loss : 0.69100421667099
\# Save into ./models/ckpt\_model/ckpt
Step:23000 , train loss : 0.6938738822937012
Step:23000 , test loss : 0.6906840205192566
\# Save into ./models/ckpt\_model/ckpt
Step:23050 , train loss : 0.7135982513427734
Step:23050 , test loss : 0.6935735940933228
\# Save into ./models/ckpt\_model/ckpt
Step:23100 , train loss : 0.7178339958190918
Step:23100 , test loss : 0.6908390522003174
\# Save into ./models/ckpt\_model/ckpt
Step:23150 , train loss : 0.6913487315177917
Step:23150 , test loss : 0.6909384727478027
\# Save into ./models/ckpt\_model/ckpt
Step:23200 , train loss : 0.6872766017913818
Step:23200 , test loss : 0.690748929977417
\# Save into ./models/ckpt\_model/ckpt
Step:23250 , train loss : 0.6630160808563232
Step:23250 , test loss : 0.6920296549797058
\# Save into ./models/ckpt\_model/ckpt
Step:23300 , train loss : 0.6885660290718079
Step:23300 , test loss : 0.6920041441917419
\# Save into ./models/ckpt\_model/ckpt
Step:23350 , train loss : 0.6622994542121887
Step:23350 , test loss : 0.692051887512207
\# Save into ./models/ckpt\_model/ckpt
Step:23400 , train loss : 0.6792583465576172
Step:23400 , test loss : 0.6909334063529968
\# Save into ./models/ckpt\_model/ckpt
Step:23450 , train loss : 0.6846767663955688
Step:23450 , test loss : 0.6907528042793274
\# Save into ./models/ckpt\_model/ckpt
Step:23500 , train loss : 0.6864854097366333
Step:23500 , test loss : 0.6925411820411682
\# Save into ./models/ckpt\_model/ckpt
Step:23550 , train loss : 0.6460862755775452
Step:23550 , test loss : 0.6923426985740662
\# Save into ./models/ckpt\_model/ckpt
Step:23600 , train loss : 0.6659126281738281
Step:23600 , test loss : 0.6909662485122681
\# Save into ./models/ckpt\_model/ckpt
Step:23650 , train loss : 0.6835072040557861
Step:23650 , test loss : 0.6915826797485352
\# Save into ./models/ckpt\_model/ckpt
Step:23700 , train loss : 0.6847190856933594
Step:23700 , test loss : 0.6907262206077576
\# Save into ./models/ckpt\_model/ckpt
Step:23750 , train loss : 0.6887686252593994
Step:23750 , test loss : 0.6906996369361877
\# Save into ./models/ckpt\_model/ckpt
Step:23800 , train loss : 0.6744797229766846
Step:23800 , test loss : 0.6915867328643799
\# Save into ./models/ckpt\_model/ckpt
Step:23850 , train loss : 0.6447386145591736
Step:23850 , test loss : 0.6916257739067078
\# Save into ./models/ckpt\_model/ckpt
Step:23900 , train loss : 0.6917864084243774
Step:23900 , test loss : 0.6926575899124146
\# Save into ./models/ckpt\_model/ckpt
Step:23950 , train loss : 0.6811977028846741
Step:23950 , test loss : 0.6947014927864075
\# Save into ./models/ckpt\_model/ckpt
Step:24000 , train loss : 0.6760664582252502
Step:24000 , test loss : 0.6907960176467896
\# Save into ./models/ckpt\_model/ckpt
Step:24050 , train loss : 0.6868583559989929
Step:24050 , test loss : 0.6913649439811707
\# Save into ./models/ckpt\_model/ckpt
Step:24100 , train loss : 0.6853914260864258
Step:24100 , test loss : 0.6915801763534546
\# Save into ./models/ckpt\_model/ckpt
Step:24150 , train loss : 0.6949823498725891
Step:24150 , test loss : 0.6924759745597839
\# Save into ./models/ckpt\_model/ckpt
Step:24200 , train loss : 0.6837380528450012
Step:24200 , test loss : 0.6908202767372131
\# Save into ./models/ckpt\_model/ckpt
Step:24250 , train loss : 0.6803234815597534
Step:24250 , test loss : 0.6925184726715088
\# Save into ./models/ckpt\_model/ckpt
Step:24300 , train loss : 0.6993622779846191
Step:24300 , test loss : 0.6906827688217163
\# Save into ./models/ckpt\_model/ckpt
Step:24350 , train loss : 0.6823959350585938
Step:24350 , test loss : 0.6910815834999084
\# Save into ./models/ckpt\_model/ckpt
Step:24400 , train loss : 0.6736738085746765
Step:24400 , test loss : 0.6908259987831116
\# Save into ./models/ckpt\_model/ckpt
Step:24450 , train loss : 0.6545445322990417
Step:24450 , test loss : 0.6952657103538513
\# Save into ./models/ckpt\_model/ckpt
Step:24500 , train loss : 0.6830778121948242
Step:24500 , test loss : 0.6919805407524109
\# Save into ./models/ckpt\_model/ckpt
Step:24550 , train loss : 0.6836188435554504
Step:24550 , test loss : 0.6914249658584595
\# Save into ./models/ckpt\_model/ckpt
Step:24600 , train loss : 0.725837767124176
Step:24600 , test loss : 0.6907798647880554
\# Save into ./models/ckpt\_model/ckpt
Step:24650 , train loss : 0.6757643222808838
Step:24650 , test loss : 0.6909855008125305
\# Save into ./models/ckpt\_model/ckpt
Step:24700 , train loss : 0.6872748136520386
Step:24700 , test loss : 0.6925355195999146
\# Save into ./models/ckpt\_model/ckpt
Step:24750 , train loss : 0.7093251347541809
Step:24750 , test loss : 0.6917991638183594
\# Save into ./models/ckpt\_model/ckpt
Step:24800 , train loss : 0.7012379169464111
Step:24800 , test loss : 0.6922188997268677
\# Save into ./models/ckpt\_model/ckpt
Step:24850 , train loss : 0.6887258291244507
Step:24850 , test loss : 0.6907880306243896
\# Save into ./models/ckpt\_model/ckpt
Step:24900 , train loss : 0.6955987811088562
Step:24900 , test loss : 0.691279947757721
\# Save into ./models/ckpt\_model/ckpt
Step:24950 , train loss : 0.6870527267456055
Step:24950 , test loss : 0.6917431354522705
\# Save into ./models/ckpt\_model/ckpt
Step:25000 , train loss : 0.6756285429000854
Step:25000 , test loss : 0.6917389035224915
\# Save into ./models/ckpt\_model/ckpt
Step:25050 , train loss : 0.7173188328742981
Step:25050 , test loss : 0.6911240816116333
\# Save into ./models/ckpt\_model/ckpt
Step:25100 , train loss : 0.693644642829895
Step:25100 , test loss : 0.6912015676498413
\# Save into ./models/ckpt\_model/ckpt
Step:25150 , train loss : 0.6908894777297974
Step:25150 , test loss : 0.6925807595252991
\# Save into ./models/ckpt\_model/ckpt
Step:25200 , train loss : 0.7218602299690247
Step:25200 , test loss : 0.6918612122535706
\# Save into ./models/ckpt\_model/ckpt
Step:25250 , train loss : 0.6891119480133057
Step:25250 , test loss : 0.6908307671546936
\# Save into ./models/ckpt\_model/ckpt
Step:25300 , train loss : 0.6866616010665894
Step:25300 , test loss : 0.6914253830909729
\# Save into ./models/ckpt\_model/ckpt
Step:25350 , train loss : 0.6958999633789062
Step:25350 , test loss : 0.6915348768234253
\# Save into ./models/ckpt\_model/ckpt
Step:25400 , train loss : 0.701552152633667
Step:25400 , test loss : 0.6921589970588684
\# Save into ./models/ckpt\_model/ckpt
Step:25450 , train loss : 0.6917814612388611
Step:25450 , test loss : 0.6908299922943115
\# Save into ./models/ckpt\_model/ckpt
Step:25500 , train loss : 0.7311074733734131
Step:25500 , test loss : 0.6939979195594788
\# Save into ./models/ckpt\_model/ckpt
Step:25550 , train loss : 0.661824643611908
Step:25550 , test loss : 0.6914711594581604
\# Save into ./models/ckpt\_model/ckpt
Step:25600 , train loss : 0.6946297883987427
Step:25600 , test loss : 0.6928350329399109
\# Save into ./models/ckpt\_model/ckpt
Step:25650 , train loss : 0.699622631072998
Step:25650 , test loss : 0.6915174126625061
\# Save into ./models/ckpt\_model/ckpt
Step:25700 , train loss : 0.687841534614563
Step:25700 , test loss : 0.6907139420509338
\# Save into ./models/ckpt\_model/ckpt
Step:25750 , train loss : 0.6785387992858887
Step:25750 , test loss : 0.6927602291107178
\# Save into ./models/ckpt\_model/ckpt
Step:25800 , train loss : 0.6896610856056213
Step:25800 , test loss : 0.6926289796829224
\# Save into ./models/ckpt\_model/ckpt
Step:25850 , train loss : 0.6742849349975586
Step:25850 , test loss : 0.6906903386116028
\# Save into ./models/ckpt\_model/ckpt
Step:25900 , train loss : 0.6978513598442078
Step:25900 , test loss : 0.6910126805305481
\# Save into ./models/ckpt\_model/ckpt
Step:25950 , train loss : 0.6991893649101257
Step:25950 , test loss : 0.6924237608909607
\# Save into ./models/ckpt\_model/ckpt
Step:26000 , train loss : 0.7063595056533813
Step:26000 , test loss : 0.6911660432815552
\# Save into ./models/ckpt\_model/ckpt
Step:26050 , train loss : 0.689802885055542
Step:26050 , test loss : 0.6909521818161011
\# Save into ./models/ckpt\_model/ckpt
Step:26100 , train loss : 0.6986944675445557
Step:26100 , test loss : 0.692051351070404
\# Save into ./models/ckpt\_model/ckpt
Step:26150 , train loss : 0.7064237594604492
Step:26150 , test loss : 0.6906865239143372
\# Save into ./models/ckpt\_model/ckpt
Step:26200 , train loss : 0.6926235556602478
Step:26200 , test loss : 0.6929908394813538
\# Save into ./models/ckpt\_model/ckpt
Step:26250 , train loss : 0.6914899945259094
Step:26250 , test loss : 0.6928569674491882
\# Save into ./models/ckpt\_model/ckpt
Step:26300 , train loss : 0.6892942190170288
Step:26300 , test loss : 0.6918976902961731
\# Save into ./models/ckpt\_model/ckpt
Step:26350 , train loss : 0.6536694765090942
Step:26350 , test loss : 0.6982429027557373
\# Save into ./models/ckpt\_model/ckpt
Step:26400 , train loss : 0.6491332054138184
Step:26400 , test loss : 0.6906973719596863
\# Save into ./models/ckpt\_model/ckpt
Step:26450 , train loss : 0.6957896947860718
Step:26450 , test loss : 0.6909052133560181
\# Save into ./models/ckpt\_model/ckpt
Step:26500 , train loss : 0.6973174810409546
Step:26500 , test loss : 0.6909385919570923
\# Save into ./models/ckpt\_model/ckpt
Step:26550 , train loss : 0.6804542541503906
Step:26550 , test loss : 0.6918808221817017
\# Save into ./models/ckpt\_model/ckpt
Step:26600 , train loss : 0.6829931139945984
Step:26600 , test loss : 0.6907330751419067
\# Save into ./models/ckpt\_model/ckpt
Step:26650 , train loss : 0.6808619499206543
Step:26650 , test loss : 0.690700113773346
\# Save into ./models/ckpt\_model/ckpt
Step:26700 , train loss : 0.7056789994239807
Step:26700 , test loss : 0.6907018423080444
\# Save into ./models/ckpt\_model/ckpt
Step:26750 , train loss : 0.6917310953140259
Step:26750 , test loss : 0.6928741335868835
\# Save into ./models/ckpt\_model/ckpt
Step:26800 , train loss : 0.6942757368087769
Step:26800 , test loss : 0.6926473379135132
\# Save into ./models/ckpt\_model/ckpt
Step:26850 , train loss : 0.6901800632476807
Step:26850 , test loss : 0.6968950629234314
\# Save into ./models/ckpt\_model/ckpt
Step:26900 , train loss : 0.7034879922866821
Step:26900 , test loss : 0.6909831762313843
\# Save into ./models/ckpt\_model/ckpt
Step:26950 , train loss : 0.6849043369293213
Step:26950 , test loss : 0.6914793252944946
\# Save into ./models/ckpt\_model/ckpt
Step:27000 , train loss : 0.6909288763999939
Step:27000 , test loss : 0.6906830668449402
\# Save into ./models/ckpt\_model/ckpt
Step:27050 , train loss : 0.6851781606674194
Step:27050 , test loss : 0.6906890273094177
\# Save into ./models/ckpt\_model/ckpt
Step:27100 , train loss : 0.6885944604873657
Step:27100 , test loss : 0.6908431649208069
\# Save into ./models/ckpt\_model/ckpt
Step:27150 , train loss : 0.6845256686210632
Step:27150 , test loss : 0.6919857263565063
\# Save into ./models/ckpt\_model/ckpt
Step:27200 , train loss : 0.6463042497634888
Step:27200 , test loss : 0.6957675814628601
\# Save into ./models/ckpt\_model/ckpt
Step:27250 , train loss : 0.665335476398468
Step:27250 , test loss : 0.7038044333457947
\# Save into ./models/ckpt\_model/ckpt
Step:27300 , train loss : 0.6529335975646973
Step:27300 , test loss : 0.6921938061714172
\# Save into ./models/ckpt\_model/ckpt
Step:27350 , train loss : 0.6873407363891602
Step:27350 , test loss : 0.69112229347229
\# Save into ./models/ckpt\_model/ckpt
Step:27400 , train loss : 0.6818908452987671
Step:27400 , test loss : 0.6914060115814209
\# Save into ./models/ckpt\_model/ckpt
Step:27450 , train loss : 0.6791933178901672
Step:27450 , test loss : 0.6916438341140747
\# Save into ./models/ckpt\_model/ckpt
Step:27500 , train loss : 0.6871541738510132
Step:27500 , test loss : 0.6907265782356262
\# Save into ./models/ckpt\_model/ckpt
Step:27550 , train loss : 0.6779201030731201
Step:27550 , test loss : 0.6912189722061157
\# Save into ./models/ckpt\_model/ckpt
Step:27600 , train loss : 0.6735749244689941
Step:27600 , test loss : 0.6915848255157471
\# Save into ./models/ckpt\_model/ckpt
Step:27650 , train loss : 0.6891012787818909
Step:27650 , test loss : 0.6915292143821716
\# Save into ./models/ckpt\_model/ckpt
Step:27700 , train loss : 0.6800488829612732
Step:27700 , test loss : 0.6915371417999268
\# Save into ./models/ckpt\_model/ckpt
Step:27750 , train loss : 0.763172447681427
Step:27750 , test loss : 0.691012442111969
\# Save into ./models/ckpt\_model/ckpt
Step:27800 , train loss : 0.6909100413322449
Step:27800 , test loss : 0.6922488808631897
\# Save into ./models/ckpt\_model/ckpt
Step:27850 , train loss : 0.6893736720085144
Step:27850 , test loss : 0.6925270557403564
\# Save into ./models/ckpt\_model/ckpt
Step:27900 , train loss : 0.7221782207489014
Step:27900 , test loss : 0.6923372745513916
\# Save into ./models/ckpt\_model/ckpt
Step:27950 , train loss : 0.688021183013916
Step:27950 , test loss : 0.6910828948020935
\# Save into ./models/ckpt\_model/ckpt
Step:28000 , train loss : 0.6804697513580322
Step:28000 , test loss : 0.6911804676055908
\# Save into ./models/ckpt\_model/ckpt
Step:28050 , train loss : 0.7272493839263916
Step:28050 , test loss : 0.6907876133918762
\# Save into ./models/ckpt\_model/ckpt
Step:28100 , train loss : 0.6918032169342041
Step:28100 , test loss : 0.692801296710968
\# Save into ./models/ckpt\_model/ckpt
Step:28150 , train loss : 0.6801884174346924
Step:28150 , test loss : 0.6910026669502258
\# Save into ./models/ckpt\_model/ckpt
Step:28200 , train loss : 0.6844231486320496
Step:28200 , test loss : 0.6919904351234436
\# Save into ./models/ckpt\_model/ckpt
Step:28250 , train loss : 0.6692981719970703
Step:28250 , test loss : 0.6907030344009399
\# Save into ./models/ckpt\_model/ckpt
Step:28300 , train loss : 0.6671944260597229
Step:28300 , test loss : 0.6926741600036621
\# Save into ./models/ckpt\_model/ckpt
Step:28350 , train loss : 0.7141993641853333
Step:28350 , test loss : 0.6906874179840088
\# Save into ./models/ckpt\_model/ckpt
Step:28400 , train loss : 0.688129186630249
Step:28400 , test loss : 0.691204309463501
\# Save into ./models/ckpt\_model/ckpt
Step:28450 , train loss : 0.6848495006561279
Step:28450 , test loss : 0.6919540166854858
\# Save into ./models/ckpt\_model/ckpt
Step:28500 , train loss : 0.7219552993774414
Step:28500 , test loss : 0.6906932592391968
\# Save into ./models/ckpt\_model/ckpt
Step:28550 , train loss : 0.6967630982398987
Step:28550 , test loss : 0.6906946897506714
\# Save into ./models/ckpt\_model/ckpt
Step:28600 , train loss : 0.6950794458389282
Step:28600 , test loss : 0.6924421191215515
\# Save into ./models/ckpt\_model/ckpt
Step:28650 , train loss : 0.7000502943992615
Step:28650 , test loss : 0.6913766860961914
\# Save into ./models/ckpt\_model/ckpt
Step:28700 , train loss : 0.6628899574279785
Step:28700 , test loss : 0.6978549361228943
\# Save into ./models/ckpt\_model/ckpt
Step:28750 , train loss : 0.6760101318359375
Step:28750 , test loss : 0.6915518641471863
\# Save into ./models/ckpt\_model/ckpt
Step:28800 , train loss : 0.7208617329597473
Step:28800 , test loss : 0.6969309449195862
\# Save into ./models/ckpt\_model/ckpt
Step:28850 , train loss : 0.7092680931091309
Step:28850 , test loss : 0.6937115788459778
\# Save into ./models/ckpt\_model/ckpt
Step:28900 , train loss : 0.6962370872497559
Step:28900 , test loss : 0.6932771801948547
\# Save into ./models/ckpt\_model/ckpt
Step:28950 , train loss : 0.6597168445587158
Step:28950 , test loss : 0.6922687888145447
\# Save into ./models/ckpt\_model/ckpt
Step:29000 , train loss : 0.693474292755127
Step:29000 , test loss : 0.6908302307128906
\# Save into ./models/ckpt\_model/ckpt
Step:29050 , train loss : 0.682956337928772
Step:29050 , test loss : 0.6910666227340698
\# Save into ./models/ckpt\_model/ckpt
Step:29100 , train loss : 0.6909204125404358
Step:29100 , test loss : 0.69258052110672
\# Save into ./models/ckpt\_model/ckpt
Step:29150 , train loss : 0.7174887657165527
Step:29150 , test loss : 0.6919224858283997
\# Save into ./models/ckpt\_model/ckpt
Step:29200 , train loss : 0.6768773794174194
Step:29200 , test loss : 0.690869927406311
\# Save into ./models/ckpt\_model/ckpt
Step:29250 , train loss : 0.665277898311615
Step:29250 , test loss : 0.6909416317939758
\# Save into ./models/ckpt\_model/ckpt
Step:29300 , train loss : 0.6858372688293457
Step:29300 , test loss : 0.6911369562149048
\# Save into ./models/ckpt\_model/ckpt
Step:29350 , train loss : 0.6946361064910889
Step:29350 , test loss : 0.6926143765449524
\# Save into ./models/ckpt\_model/ckpt
Step:29400 , train loss : 0.6588383316993713
Step:29400 , test loss : 0.6915204524993896
\# Save into ./models/ckpt\_model/ckpt
Step:29450 , train loss : 0.6912553906440735
Step:29450 , test loss : 0.6912080645561218
\# Save into ./models/ckpt\_model/ckpt
Step:29500 , train loss : 0.6932992339134216
Step:29500 , test loss : 0.6926991939544678
\# Save into ./models/ckpt\_model/ckpt
Step:29550 , train loss : 0.7108885645866394
Step:29550 , test loss : 0.694006085395813
\# Save into ./models/ckpt\_model/ckpt
Step:29600 , train loss : 0.6873266100883484
Step:29600 , test loss : 0.6918706297874451
\# Save into ./models/ckpt\_model/ckpt
Step:29650 , train loss : 0.6840858459472656
Step:29650 , test loss : 0.6907297968864441
\# Save into ./models/ckpt\_model/ckpt
Step:29700 , train loss : 0.6873483657836914
Step:29700 , test loss : 0.6910352110862732
\# Save into ./models/ckpt\_model/ckpt
Step:29750 , train loss : 0.6866054534912109
Step:29750 , test loss : 0.6907350420951843
\# Save into ./models/ckpt\_model/ckpt
Step:29800 , train loss : 0.6880741715431213
Step:29800 , test loss : 0.6909586191177368
\# Save into ./models/ckpt\_model/ckpt
Step:29850 , train loss : 0.6564744114875793
Step:29850 , test loss : 0.69094318151474
\# Save into ./models/ckpt\_model/ckpt
Step:29900 , train loss : 0.6706798076629639
Step:29900 , test loss : 0.7020301818847656
\# Save into ./models/ckpt\_model/ckpt
Step:29950 , train loss : 0.6792948246002197
Step:29950 , test loss : 0.6914560198783875
\# Save into ./models/ckpt\_model/ckpt
Step:30000 , train loss : 0.683636486530304
Step:30000 , test loss : 0.6919747591018677
\# Save into ./models/ckpt\_model/ckpt
Step:30050 , train loss : 0.6954565048217773
Step:30050 , test loss : 0.6913920640945435
\# Save into ./models/ckpt\_model/ckpt
Step:30100 , train loss : 0.674742579460144
Step:30100 , test loss : 0.6941162347793579
\# Save into ./models/ckpt\_model/ckpt
Step:30150 , train loss : 0.6735287308692932
Step:30150 , test loss : 0.6910226941108704
\# Save into ./models/ckpt\_model/ckpt
Step:30200 , train loss : 0.6900745630264282
Step:30200 , test loss : 0.6907480359077454
\# Save into ./models/ckpt\_model/ckpt
Step:30250 , train loss : 0.6735060214996338
Step:30250 , test loss : 0.6936267614364624
\# Save into ./models/ckpt\_model/ckpt
Step:30300 , train loss : 0.6740427017211914
Step:30300 , test loss : 0.6907039284706116
\# Save into ./models/ckpt\_model/ckpt
Step:30350 , train loss : 0.6921988725662231
Step:30350 , test loss : 0.691071629524231
\# Save into ./models/ckpt\_model/ckpt
Step:30400 , train loss : 0.6898794174194336
Step:30400 , test loss : 0.6913759112358093
\# Save into ./models/ckpt\_model/ckpt
Step:30450 , train loss : 0.6618282794952393
Step:30450 , test loss : 0.6907423734664917
\# Save into ./models/ckpt\_model/ckpt
Step:30500 , train loss : 0.677325963973999
Step:30500 , test loss : 0.6909893155097961
\# Save into ./models/ckpt\_model/ckpt
Step:30550 , train loss : 0.6855005025863647
Step:30550 , test loss : 0.691800057888031
\# Save into ./models/ckpt\_model/ckpt
Step:30600 , train loss : 0.6834850907325745
Step:30600 , test loss : 0.6918392777442932
\# Save into ./models/ckpt\_model/ckpt
Step:30650 , train loss : 0.6839863061904907
Step:30650 , test loss : 0.6907705068588257
\# Save into ./models/ckpt\_model/ckpt
Step:30700 , train loss : 0.7177891135215759
Step:30700 , test loss : 0.6949125528335571
\# Save into ./models/ckpt\_model/ckpt
Step:30750 , train loss : 0.6774303913116455
Step:30750 , test loss : 0.690723180770874
\# Save into ./models/ckpt\_model/ckpt
Step:30800 , train loss : 0.6834619045257568
Step:30800 , test loss : 0.6907497048377991
\# Save into ./models/ckpt\_model/ckpt
Step:30850 , train loss : 0.6705309152603149
Step:30850 , test loss : 0.6928256750106812
\# Save into ./models/ckpt\_model/ckpt
Step:30900 , train loss : 0.6500115990638733
Step:30900 , test loss : 0.6906890869140625
\# Save into ./models/ckpt\_model/ckpt
Step:30950 , train loss : 0.7050498723983765
Step:30950 , test loss : 0.6911183595657349
\# Save into ./models/ckpt\_model/ckpt
Step:31000 , train loss : 0.7240290641784668
Step:31000 , test loss : 0.6938496232032776
\# Save into ./models/ckpt\_model/ckpt
Step:31050 , train loss : 0.6886115670204163
Step:31050 , test loss : 0.6907767057418823
\# Save into ./models/ckpt\_model/ckpt
Step:31100 , train loss : 0.6905908584594727
Step:31100 , test loss : 0.6915778517723083
\# Save into ./models/ckpt\_model/ckpt
Step:31150 , train loss : 0.6715431213378906
Step:31150 , test loss : 0.6972469687461853
\# Save into ./models/ckpt\_model/ckpt
Step:31200 , train loss : 0.6990532279014587
Step:31200 , test loss : 0.6912217140197754
\# Save into ./models/ckpt\_model/ckpt
Step:31250 , train loss : 0.669330894947052
Step:31250 , test loss : 0.694975733757019
\# Save into ./models/ckpt\_model/ckpt
Step:31300 , train loss : 0.6822577714920044
Step:31300 , test loss : 0.691307544708252
\# Save into ./models/ckpt\_model/ckpt
Step:31350 , train loss : 0.6738222241401672
Step:31350 , test loss : 0.6907829642295837
\# Save into ./models/ckpt\_model/ckpt
Step:31400 , train loss : 0.6856510043144226
Step:31400 , test loss : 0.6912757754325867
\# Save into ./models/ckpt\_model/ckpt
Step:31450 , train loss : 0.6899935007095337
Step:31450 , test loss : 0.6906870007514954
\# Save into ./models/ckpt\_model/ckpt
Step:31500 , train loss : 0.6802765727043152
Step:31500 , test loss : 0.6925867795944214
\# Save into ./models/ckpt\_model/ckpt
Step:31550 , train loss : 0.6819169521331787
Step:31550 , test loss : 0.6907401084899902
\# Save into ./models/ckpt\_model/ckpt
Step:31600 , train loss : 0.6914545297622681
Step:31600 , test loss : 0.6908712983131409
\# Save into ./models/ckpt\_model/ckpt
Step:31650 , train loss : 0.6465102434158325
Step:31650 , test loss : 0.6955180764198303
\# Save into ./models/ckpt\_model/ckpt
Step:31700 , train loss : 0.6885097026824951
Step:31700 , test loss : 0.6928297281265259
\# Save into ./models/ckpt\_model/ckpt
Step:31750 , train loss : 0.674910843372345
Step:31750 , test loss : 0.6915448307991028
\# Save into ./models/ckpt\_model/ckpt
Step:31800 , train loss : 0.7094613909721375
Step:31800 , test loss : 0.6909697651863098
\# Save into ./models/ckpt\_model/ckpt
Step:31850 , train loss : 0.703574538230896
Step:31850 , test loss : 0.6906829476356506
\# Save into ./models/ckpt\_model/ckpt
Step:31900 , train loss : 0.707832396030426
Step:31900 , test loss : 0.6927000284194946
\# Save into ./models/ckpt\_model/ckpt
Step:31950 , train loss : 0.6748640537261963
Step:31950 , test loss : 0.690909206867218
\# Save into ./models/ckpt\_model/ckpt
Step:32000 , train loss : 0.6762403845787048
Step:32000 , test loss : 0.69086092710495
\# Save into ./models/ckpt\_model/ckpt
Step:32050 , train loss : 0.6937704086303711
Step:32050 , test loss : 0.6920843124389648
\# Save into ./models/ckpt\_model/ckpt
Step:32100 , train loss : 0.7181033492088318
Step:32100 , test loss : 0.6906933784484863
\# Save into ./models/ckpt\_model/ckpt
Step:32150 , train loss : 0.6886297464370728
Step:32150 , test loss : 0.6906909346580505
\# Save into ./models/ckpt\_model/ckpt
Step:32200 , train loss : 0.6689740419387817
Step:32200 , test loss : 0.6923575401306152
\# Save into ./models/ckpt\_model/ckpt
Step:32250 , train loss : 0.6726688742637634
Step:32250 , test loss : 0.6911401748657227
\# Save into ./models/ckpt\_model/ckpt
Step:32300 , train loss : 0.6989285349845886
Step:32300 , test loss : 0.6912094950675964
\# Save into ./models/ckpt\_model/ckpt
Step:32350 , train loss : 0.6882789134979248
Step:32350 , test loss : 0.6920152902603149
\# Save into ./models/ckpt\_model/ckpt
Step:32400 , train loss : 0.6948370337486267
Step:32400 , test loss : 0.6907143592834473
\# Save into ./models/ckpt\_model/ckpt
Step:32450 , train loss : 0.6722900867462158
Step:32450 , test loss : 0.6906868815422058
\# Save into ./models/ckpt\_model/ckpt
Step:32500 , train loss : 0.673837423324585
Step:32500 , test loss : 0.6906858682632446
\# Save into ./models/ckpt\_model/ckpt
Step:32550 , train loss : 0.6291856169700623
Step:32550 , test loss : 0.6973984837532043
\# Save into ./models/ckpt\_model/ckpt
Step:32600 , train loss : 0.6757440567016602
Step:32600 , test loss : 0.690764844417572
\# Save into ./models/ckpt\_model/ckpt
Step:32650 , train loss : 0.6808619499206543
Step:32650 , test loss : 0.6908859014511108
\# Save into ./models/ckpt\_model/ckpt
Step:32700 , train loss : 0.71585613489151
Step:32700 , test loss : 0.6914093494415283
\# Save into ./models/ckpt\_model/ckpt
Step:32750 , train loss : 0.6902650594711304
Step:32750 , test loss : 0.6924004554748535
\# Save into ./models/ckpt\_model/ckpt
Step:32800 , train loss : 0.6921185255050659
Step:32800 , test loss : 0.6927316188812256
\# Save into ./models/ckpt\_model/ckpt
Step:32850 , train loss : 0.7182970643043518
Step:32850 , test loss : 0.6916934251785278
\# Save into ./models/ckpt\_model/ckpt
Step:32900 , train loss : 0.6826420426368713
Step:32900 , test loss : 0.6907036900520325
\# Save into ./models/ckpt\_model/ckpt
Step:32950 , train loss : 0.6636956930160522
Step:32950 , test loss : 0.6921032071113586
\# Save into ./models/ckpt\_model/ckpt
Step:33000 , train loss : 0.6735723614692688
Step:33000 , test loss : 0.6907145380973816
\# Save into ./models/ckpt\_model/ckpt
Step:33050 , train loss : 0.6788852214813232
Step:33050 , test loss : 0.6925795674324036
\# Save into ./models/ckpt\_model/ckpt
Step:33100 , train loss : 0.6795825958251953
Step:33100 , test loss : 0.69071364402771
\# Save into ./models/ckpt\_model/ckpt
Step:33150 , train loss : 0.6554363369941711
Step:33150 , test loss : 0.6944108009338379
\# Save into ./models/ckpt\_model/ckpt
Step:33200 , train loss : 0.6921268701553345
Step:33200 , test loss : 0.6919429302215576
\# Save into ./models/ckpt\_model/ckpt
Step:33250 , train loss : 0.6851900219917297
Step:33250 , test loss : 0.6912703514099121
\# Save into ./models/ckpt\_model/ckpt
Step:33300 , train loss : 0.6909162402153015
Step:33300 , test loss : 0.6924944519996643
\# Save into ./models/ckpt\_model/ckpt
Step:33350 , train loss : 0.7018148899078369
Step:33350 , test loss : 0.6919190883636475
\# Save into ./models/ckpt\_model/ckpt
Step:33400 , train loss : 0.6591789722442627
Step:33400 , test loss : 0.6922954320907593
\# Save into ./models/ckpt\_model/ckpt
Step:33450 , train loss : 0.6886650919914246
Step:33450 , test loss : 0.6912164092063904
\# Save into ./models/ckpt\_model/ckpt
Step:33500 , train loss : 0.6817743182182312
Step:33500 , test loss : 0.6906969547271729
\# Save into ./models/ckpt\_model/ckpt
Step:33550 , train loss : 0.6854367256164551
Step:33550 , test loss : 0.6915473341941833
\# Save into ./models/ckpt\_model/ckpt
Step:33600 , train loss : 0.6510953307151794
Step:33600 , test loss : 0.6916661262512207
\# Save into ./models/ckpt\_model/ckpt
Step:33650 , train loss : 0.6823815107345581
Step:33650 , test loss : 0.691601574420929
\# Save into ./models/ckpt\_model/ckpt
Step:33700 , train loss : 0.6862666606903076
Step:33700 , test loss : 0.6910626888275146
\# Save into ./models/ckpt\_model/ckpt
Step:33750 , train loss : 0.6956483721733093
Step:33750 , test loss : 0.6907352209091187
\# Save into ./models/ckpt\_model/ckpt
Step:33800 , train loss : 0.6784435510635376
Step:33800 , test loss : 0.6914568543434143
\# Save into ./models/ckpt\_model/ckpt
Step:33850 , train loss : 0.6805362701416016
Step:33850 , test loss : 0.6914987564086914
\# Save into ./models/ckpt\_model/ckpt
Step:33900 , train loss : 0.6626579761505127
Step:33900 , test loss : 0.6907938718795776
\# Save into ./models/ckpt\_model/ckpt
Step:33950 , train loss : 0.675624430179596
Step:33950 , test loss : 0.6938380002975464
\# Save into ./models/ckpt\_model/ckpt
Step:34000 , train loss : 0.6836282014846802
Step:34000 , test loss : 0.6907198429107666
\# Save into ./models/ckpt\_model/ckpt
Step:34050 , train loss : 0.7078860402107239
Step:34050 , test loss : 0.6934888362884521
\# Save into ./models/ckpt\_model/ckpt
Step:34100 , train loss : 0.677599310874939
Step:34100 , test loss : 0.6927184462547302
\# Save into ./models/ckpt\_model/ckpt
Step:34150 , train loss : 0.6953061819076538
Step:34150 , test loss : 0.6917909979820251
\# Save into ./models/ckpt\_model/ckpt
Step:34200 , train loss : 0.6874553561210632
Step:34200 , test loss : 0.691809892654419
\# Save into ./models/ckpt\_model/ckpt
Step:34250 , train loss : 0.691442608833313
Step:34250 , test loss : 0.6929494738578796
\# Save into ./models/ckpt\_model/ckpt
Step:34300 , train loss : 0.6925561428070068
Step:34300 , test loss : 0.6931043267250061
\# Save into ./models/ckpt\_model/ckpt
Step:34350 , train loss : 0.6932923793792725
Step:34350 , test loss : 0.6930904984474182
\# Save into ./models/ckpt\_model/ckpt
Step:34400 , train loss : 0.6931580305099487
Step:34400 , test loss : 0.6930662989616394
\# Save into ./models/ckpt\_model/ckpt
Step:34450 , train loss : 0.6931892037391663
Step:34450 , test loss : 0.6930087804794312
\# Save into ./models/ckpt\_model/ckpt
Step:34500 , train loss : 0.6987455487251282
Step:34500 , test loss : 0.6927596926689148
\# Save into ./models/ckpt\_model/ckpt
Step:34550 , train loss : 0.696208655834198
Step:34550 , test loss : 0.6907157897949219
\# Save into ./models/ckpt\_model/ckpt
Step:34600 , train loss : 0.6715813875198364
Step:34600 , test loss : 0.6918790340423584
\# Save into ./models/ckpt\_model/ckpt
Step:34650 , train loss : 0.6854462623596191
Step:34650 , test loss : 0.6907714009284973
\# Save into ./models/ckpt\_model/ckpt
Step:34700 , train loss : 0.6868979930877686
Step:34700 , test loss : 0.6921055912971497
\# Save into ./models/ckpt\_model/ckpt
Step:34750 , train loss : 0.6894179582595825
Step:34750 , test loss : 0.6924487948417664
\# Save into ./models/ckpt\_model/ckpt
Step:34800 , train loss : 0.7117231488227844
Step:34800 , test loss : 0.6915071606636047
\# Save into ./models/ckpt\_model/ckpt
Step:34850 , train loss : 0.6785107851028442
Step:34850 , test loss : 0.6906903386116028
\# Save into ./models/ckpt\_model/ckpt
Step:34900 , train loss : 0.6790099143981934
Step:34900 , test loss : 0.6915401816368103
\# Save into ./models/ckpt\_model/ckpt
Step:34950 , train loss : 0.7214763164520264
Step:34950 , test loss : 0.6912502646446228
\# Save into ./models/ckpt\_model/ckpt
Step:35000 , train loss : 0.6916121244430542
Step:35000 , test loss : 0.6921998262405396
\# Save into ./models/ckpt\_model/ckpt
Step:35050 , train loss : 0.6985001564025879
Step:35050 , test loss : 0.6908794641494751
\# Save into ./models/ckpt\_model/ckpt
Step:35100 , train loss : 0.6320289969444275
Step:35100 , test loss : 0.6906845569610596
\# Save into ./models/ckpt\_model/ckpt
Step:35150 , train loss : 0.6880332231521606
Step:35150 , test loss : 0.6951543092727661
\# Save into ./models/ckpt\_model/ckpt
Step:35200 , train loss : 0.6807740330696106
Step:35200 , test loss : 0.6913232803344727
\# Save into ./models/ckpt\_model/ckpt
Step:35250 , train loss : 0.7296445965766907
Step:35250 , test loss : 0.6908838152885437
\# Save into ./models/ckpt\_model/ckpt
Step:35300 , train loss : 0.690442681312561
Step:35300 , test loss : 0.7029425501823425
\# Save into ./models/ckpt\_model/ckpt
Step:35350 , train loss : 0.6983868479728699
Step:35350 , test loss : 0.6914291381835938
\# Save into ./models/ckpt\_model/ckpt
Step:35400 , train loss : 0.6866320967674255
Step:35400 , test loss : 0.6917031407356262
\# Save into ./models/ckpt\_model/ckpt
Step:35450 , train loss : 0.6828746795654297
Step:35450 , test loss : 0.6907486915588379
\# Save into ./models/ckpt\_model/ckpt
Step:35500 , train loss : 0.6816391944885254
Step:35500 , test loss : 0.692112386226654
\# Save into ./models/ckpt\_model/ckpt
Step:35550 , train loss : 0.6977570652961731
Step:35550 , test loss : 0.6923536062240601
\# Save into ./models/ckpt\_model/ckpt
Step:35600 , train loss : 0.6720901727676392
Step:35600 , test loss : 0.6963064074516296
\# Save into ./models/ckpt\_model/ckpt
Step:35650 , train loss : 0.6819351315498352
Step:35650 , test loss : 0.7056581974029541
\# Save into ./models/ckpt\_model/ckpt
Step:35700 , train loss : 0.687781035900116
Step:35700 , test loss : 0.6925105452537537
\# Save into ./models/ckpt\_model/ckpt
Step:35750 , train loss : 0.6470636129379272
Step:35750 , test loss : 0.7018790245056152
\# Save into ./models/ckpt\_model/ckpt
Step:35800 , train loss : 0.687998354434967
Step:35800 , test loss : 0.6916109919548035
\# Save into ./models/ckpt\_model/ckpt
Step:35850 , train loss : 0.6890109181404114
Step:35850 , test loss : 0.6918113231658936
\# Save into ./models/ckpt\_model/ckpt
Step:35900 , train loss : 0.6915162801742554
Step:35900 , test loss : 0.6930105686187744
\# Save into ./models/ckpt\_model/ckpt
Step:35950 , train loss : 0.6822792291641235
Step:35950 , test loss : 0.6921756863594055
\# Save into ./models/ckpt\_model/ckpt
Step:36000 , train loss : 0.6593762636184692
Step:36000 , test loss : 0.6907479763031006
\# Save into ./models/ckpt\_model/ckpt
Step:36050 , train loss : 0.6694761514663696
Step:36050 , test loss : 0.6935145854949951
\# Save into ./models/ckpt\_model/ckpt
Step:36100 , train loss : 0.6649416089057922
Step:36100 , test loss : 0.6907086372375488
\# Save into ./models/ckpt\_model/ckpt
Step:36150 , train loss : 0.7044849991798401
Step:36150 , test loss : 0.6929450035095215
\# Save into ./models/ckpt\_model/ckpt
Step:36200 , train loss : 0.6807042956352234
Step:36200 , test loss : 0.6940538287162781
\# Save into ./models/ckpt\_model/ckpt
Step:36250 , train loss : 0.6567384004592896
Step:36250 , test loss : 0.6908291578292847
\# Save into ./models/ckpt\_model/ckpt
Step:36300 , train loss : 0.6897492408752441
Step:36300 , test loss : 0.6915647983551025
\# Save into ./models/ckpt\_model/ckpt
Step:36350 , train loss : 0.6759674549102783
Step:36350 , test loss : 0.6909878849983215
\# Save into ./models/ckpt\_model/ckpt
Step:36400 , train loss : 0.6925045251846313
Step:36400 , test loss : 0.6925768256187439
\# Save into ./models/ckpt\_model/ckpt
Step:36450 , train loss : 0.7523472905158997
Step:36450 , test loss : 0.6918654441833496
\# Save into ./models/ckpt\_model/ckpt
Step:36500 , train loss : 0.6924405097961426
Step:36500 , test loss : 0.6906828880310059
\# Save into ./models/ckpt\_model/ckpt
Step:36550 , train loss : 0.6859662532806396
Step:36550 , test loss : 0.6923164129257202
\# Save into ./models/ckpt\_model/ckpt
Step:36600 , train loss : 0.6615656018257141
Step:36600 , test loss : 0.6908918619155884
\# Save into ./models/ckpt\_model/ckpt
Step:36650 , train loss : 0.6972053050994873
Step:36650 , test loss : 0.6907147765159607
\# Save into ./models/ckpt\_model/ckpt
Step:36700 , train loss : 0.6887778043746948
Step:36700 , test loss : 0.6908154487609863
\# Save into ./models/ckpt\_model/ckpt
Step:36750 , train loss : 0.7599992752075195
Step:36750 , test loss : 0.6911495327949524
\# Save into ./models/ckpt\_model/ckpt
Step:36800 , train loss : 0.681965708732605
Step:36800 , test loss : 0.690692663192749
\# Save into ./models/ckpt\_model/ckpt
Step:36850 , train loss : 0.659945547580719
Step:36850 , test loss : 0.692712128162384
\# Save into ./models/ckpt\_model/ckpt
Step:36900 , train loss : 0.6705401539802551
Step:36900 , test loss : 0.6907631158828735
\# Save into ./models/ckpt\_model/ckpt
Step:36950 , train loss : 0.6700334548950195
Step:36950 , test loss : 0.7182601690292358
\# Save into ./models/ckpt\_model/ckpt
Step:37000 , train loss : 0.6914229989051819
Step:37000 , test loss : 0.693020224571228
\# Save into ./models/ckpt\_model/ckpt
Step:37050 , train loss : 0.6922454833984375
Step:37050 , test loss : 0.6929194331169128
\# Save into ./models/ckpt\_model/ckpt
Step:37100 , train loss : 0.6905854940414429
Step:37100 , test loss : 0.6923435926437378
\# Save into ./models/ckpt\_model/ckpt
Step:37150 , train loss : 0.6755057573318481
Step:37150 , test loss : 0.6906874775886536
\# Save into ./models/ckpt\_model/ckpt
Step:37200 , train loss : 0.6787001490592957
Step:37200 , test loss : 0.6911709904670715
\# Save into ./models/ckpt\_model/ckpt
Step:37250 , train loss : 0.693044900894165
Step:37250 , test loss : 0.6928929090499878
\# Save into ./models/ckpt\_model/ckpt
Step:37300 , train loss : 0.6923045516014099
Step:37300 , test loss : 0.6919931173324585
\# Save into ./models/ckpt\_model/ckpt
Step:37350 , train loss : 0.7011153101921082
Step:37350 , test loss : 0.6939558982849121
\# Save into ./models/ckpt\_model/ckpt
Step:37400 , train loss : 0.7067872285842896
Step:37400 , test loss : 0.6917608976364136
\# Save into ./models/ckpt\_model/ckpt
Step:37450 , train loss : 0.6918319463729858
Step:37450 , test loss : 0.6907116174697876
\# Save into ./models/ckpt\_model/ckpt
Step:37500 , train loss : 0.6774234771728516
Step:37500 , test loss : 0.6917612552642822
\# Save into ./models/ckpt\_model/ckpt
Step:37550 , train loss : 0.6988284587860107
Step:37550 , test loss : 0.6919410228729248
\# Save into ./models/ckpt\_model/ckpt
Step:37600 , train loss : 0.6873550415039062
Step:37600 , test loss : 0.691085934638977
\# Save into ./models/ckpt\_model/ckpt
Step:37650 , train loss : 0.6883830428123474
Step:37650 , test loss : 0.6971127986907959
\# Save into ./models/ckpt\_model/ckpt
Step:37700 , train loss : 0.6914008259773254
Step:37700 , test loss : 0.7009397745132446
\# Save into ./models/ckpt\_model/ckpt
Step:37750 , train loss : 0.6915502548217773
Step:37750 , test loss : 0.6919801235198975
\# Save into ./models/ckpt\_model/ckpt
Step:37800 , train loss : 0.7085637450218201
Step:37800 , test loss : 0.6906829476356506
\# Save into ./models/ckpt\_model/ckpt
Step:37850 , train loss : 0.6815181374549866
Step:37850 , test loss : 0.690830647945404
\# Save into ./models/ckpt\_model/ckpt
Step:37900 , train loss : 0.6608192920684814
Step:37900 , test loss : 0.6940778493881226
\# Save into ./models/ckpt\_model/ckpt
Step:37950 , train loss : 0.677377462387085
Step:37950 , test loss : 0.690917432308197
\# Save into ./models/ckpt\_model/ckpt
Step:38000 , train loss : 0.661137580871582
Step:38000 , test loss : 0.6963745951652527
\# Save into ./models/ckpt\_model/ckpt
Step:38050 , train loss : 0.6958445310592651
Step:38050 , test loss : 0.6910447478294373
\# Save into ./models/ckpt\_model/ckpt
Step:38100 , train loss : 0.629971444606781
Step:38100 , test loss : 0.6940550804138184
\# Save into ./models/ckpt\_model/ckpt
Step:38150 , train loss : 0.6736550331115723
Step:38150 , test loss : 0.705059289932251
\# Save into ./models/ckpt\_model/ckpt
Step:38200 , train loss : 0.6888786554336548
Step:38200 , test loss : 0.6910994648933411
\# Save into ./models/ckpt\_model/ckpt
Step:38250 , train loss : 0.699613094329834
Step:38250 , test loss : 0.6922042965888977
\# Save into ./models/ckpt\_model/ckpt
Step:38300 , train loss : 0.6843369007110596
Step:38300 , test loss : 0.6907070279121399
\# Save into ./models/ckpt\_model/ckpt
Step:38350 , train loss : 0.6733897924423218
Step:38350 , test loss : 0.6962313652038574
\# Save into ./models/ckpt\_model/ckpt
Step:38400 , train loss : 0.6357784867286682
Step:38400 , test loss : 0.6942744255065918
\# Save into ./models/ckpt\_model/ckpt
Step:38450 , train loss : 0.6803877353668213
Step:38450 , test loss : 0.6972543001174927
\# Save into ./models/ckpt\_model/ckpt
Step:38500 , train loss : 0.6913068890571594
Step:38500 , test loss : 0.6929642558097839
\# Save into ./models/ckpt\_model/ckpt
Step:38550 , train loss : 0.6878530383110046
Step:38550 , test loss : 0.6925333738327026
\# Save into ./models/ckpt\_model/ckpt
Step:38600 , train loss : 0.6851952075958252
Step:38600 , test loss : 0.6947588920593262
\# Save into ./models/ckpt\_model/ckpt
Step:38650 , train loss : 0.6904436349868774
Step:38650 , test loss : 0.6909021735191345
\# Save into ./models/ckpt\_model/ckpt
Step:38700 , train loss : 0.7215266823768616
Step:38700 , test loss : 0.6911615133285522
\# Save into ./models/ckpt\_model/ckpt
Step:38750 , train loss : 0.673943817615509
Step:38750 , test loss : 0.6923961043357849
\# Save into ./models/ckpt\_model/ckpt
Step:38800 , train loss : 0.6887339353561401
Step:38800 , test loss : 0.6918715834617615
\# Save into ./models/ckpt\_model/ckpt
Step:38850 , train loss : 0.6337718367576599
Step:38850 , test loss : 0.6946003437042236
\# Save into ./models/ckpt\_model/ckpt
Step:38900 , train loss : 0.6880808472633362
Step:38900 , test loss : 0.6917763352394104
\# Save into ./models/ckpt\_model/ckpt
Step:38950 , train loss : 0.6989432573318481
Step:38950 , test loss : 0.6908811330795288
\# Save into ./models/ckpt\_model/ckpt
Step:39000 , train loss : 0.7449894547462463
Step:39000 , test loss : 0.6921315789222717
\# Save into ./models/ckpt\_model/ckpt
Step:39050 , train loss : 0.6901264786720276
Step:39050 , test loss : 0.698227047920227
\# Save into ./models/ckpt\_model/ckpt
Step:39100 , train loss : 0.6789053678512573
Step:39100 , test loss : 0.6929526925086975
\# Save into ./models/ckpt\_model/ckpt
Step:39150 , train loss : 0.6949595808982849
Step:39150 , test loss : 0.6911752820014954
\# Save into ./models/ckpt\_model/ckpt
Step:39200 , train loss : 0.6889826059341431
Step:39200 , test loss : 0.6923712491989136
\# Save into ./models/ckpt\_model/ckpt
Step:39250 , train loss : 0.6816175580024719
Step:39250 , test loss : 0.6907036900520325
\# Save into ./models/ckpt\_model/ckpt
Step:39300 , train loss : 0.6382017731666565
Step:39300 , test loss : 0.6945591568946838
\# Save into ./models/ckpt\_model/ckpt
Step:39350 , train loss : 0.6758774518966675
Step:39350 , test loss : 0.6927966475486755
\# Save into ./models/ckpt\_model/ckpt
Step:39400 , train loss : 0.6760401129722595
Step:39400 , test loss : 0.6913110613822937
\# Save into ./models/ckpt\_model/ckpt
Step:39450 , train loss : 0.6665257811546326
Step:39450 , test loss : 0.6911970973014832
\# Save into ./models/ckpt\_model/ckpt
Step:39500 , train loss : 0.6932882070541382
Step:39500 , test loss : 0.6913763284683228
\# Save into ./models/ckpt\_model/ckpt
Step:39550 , train loss : 0.6790651679039001
Step:39550 , test loss : 0.6907185912132263
\# Save into ./models/ckpt\_model/ckpt
Step:39600 , train loss : 0.6780654788017273
Step:39600 , test loss : 0.6913474798202515
\# Save into ./models/ckpt\_model/ckpt
Step:39650 , train loss : 0.6824517250061035
Step:39650 , test loss : 0.6910313963890076
\# Save into ./models/ckpt\_model/ckpt
Step:39700 , train loss : 0.6941245794296265
Step:39700 , test loss : 0.6916927695274353
\# Save into ./models/ckpt\_model/ckpt
Step:39750 , train loss : 0.7164371013641357
Step:39750 , test loss : 0.690697193145752
\# Save into ./models/ckpt\_model/ckpt
Step:39800 , train loss : 0.7148747444152832
Step:39800 , test loss : 0.7023276686668396
\# Save into ./models/ckpt\_model/ckpt
Step:39850 , train loss : 0.6863390803337097
Step:39850 , test loss : 0.6906845569610596
\# Save into ./models/ckpt\_model/ckpt
Step:39900 , train loss : 0.7372920513153076
Step:39900 , test loss : 0.6911156177520752
\# Save into ./models/ckpt\_model/ckpt
Step:39950 , train loss : 0.6793808341026306
Step:39950 , test loss : 0.6933672428131104
\# Save into ./models/ckpt\_model/ckpt
Step:40000 , train loss : 0.6936896443367004
Step:40000 , test loss : 0.690696656703949
\# Save into ./models/ckpt\_model/ckpt
Step:40050 , train loss : 0.6797831654548645
Step:40050 , test loss : 0.6968645453453064
\# Save into ./models/ckpt\_model/ckpt
Step:40100 , train loss : 0.6696664094924927
Step:40100 , test loss : 0.6946367621421814
\# Save into ./models/ckpt\_model/ckpt
Step:40150 , train loss : 0.7010542154312134
Step:40150 , test loss : 0.6932794451713562
\# Save into ./models/ckpt\_model/ckpt
Step:40200 , train loss : 0.6658896803855896
Step:40200 , test loss : 0.6912673711776733
\# Save into ./models/ckpt\_model/ckpt
Step:40250 , train loss : 0.6902183890342712
Step:40250 , test loss : 0.6924304366111755
\# Save into ./models/ckpt\_model/ckpt
Step:40300 , train loss : 0.6871868968009949
Step:40300 , test loss : 0.6918965578079224
\# Save into ./models/ckpt\_model/ckpt
Step:40350 , train loss : 0.6906846165657043
Step:40350 , test loss : 0.6909615397453308
\# Save into ./models/ckpt\_model/ckpt
Step:40400 , train loss : 0.6597805619239807
Step:40400 , test loss : 0.7011480331420898
\# Save into ./models/ckpt\_model/ckpt
Step:40450 , train loss : 0.7375270128250122
Step:40450 , test loss : 0.6952176690101624
\# Save into ./models/ckpt\_model/ckpt
Step:40500 , train loss : 0.6916578412055969
Step:40500 , test loss : 0.6928098797798157
\# Save into ./models/ckpt\_model/ckpt
Step:40550 , train loss : 0.685988187789917
Step:40550 , test loss : 0.6919420957565308
\# Save into ./models/ckpt\_model/ckpt
Step:40600 , train loss : 0.6759701371192932
Step:40600 , test loss : 0.6907156705856323
\# Save into ./models/ckpt\_model/ckpt
Step:40650 , train loss : 0.6567156910896301
Step:40650 , test loss : 0.69081711769104
\# Save into ./models/ckpt\_model/ckpt
Step:40700 , train loss : 0.6769030094146729
Step:40700 , test loss : 0.6907438039779663
\# Save into ./models/ckpt\_model/ckpt
Step:40750 , train loss : 0.6880089640617371
Step:40750 , test loss : 0.6913105249404907
\# Save into ./models/ckpt\_model/ckpt
Step:40800 , train loss : 0.67916339635849
Step:40800 , test loss : 0.6912297606468201
\# Save into ./models/ckpt\_model/ckpt
Step:40850 , train loss : 0.6926811933517456
Step:40850 , test loss : 0.6918507218360901
\# Save into ./models/ckpt\_model/ckpt
Step:40900 , train loss : 0.6926869750022888
Step:40900 , test loss : 0.6922038793563843
\# Save into ./models/ckpt\_model/ckpt
Step:40950 , train loss : 0.6969261765480042
Step:40950 , test loss : 0.6907142996788025
\# Save into ./models/ckpt\_model/ckpt
Step:41000 , train loss : 0.7116549015045166
Step:41000 , test loss : 0.6911002993583679
\# Save into ./models/ckpt\_model/ckpt
Step:41050 , train loss : 0.6870546340942383
Step:41050 , test loss : 0.6919782161712646
\# Save into ./models/ckpt\_model/ckpt
Step:41100 , train loss : 0.6644608974456787
Step:41100 , test loss : 0.6907722353935242
\# Save into ./models/ckpt\_model/ckpt
Step:41150 , train loss : 0.6955791711807251
Step:41150 , test loss : 0.6915717720985413
\# Save into ./models/ckpt\_model/ckpt
Step:41200 , train loss : 0.6674215793609619
Step:41200 , test loss : 0.692624032497406
\# Save into ./models/ckpt\_model/ckpt
Step:41250 , train loss : 0.6960182189941406
Step:41250 , test loss : 0.6929200887680054
\# Save into ./models/ckpt\_model/ckpt
Step:41300 , train loss : 0.6918965578079224
Step:41300 , test loss : 0.6924891471862793
\# Save into ./models/ckpt\_model/ckpt
Step:41350 , train loss : 0.6859354972839355
Step:41350 , test loss : 0.6909083724021912
\# Save into ./models/ckpt\_model/ckpt
Step:41400 , train loss : 0.733131468296051
Step:41400 , test loss : 0.6916196942329407
\# Save into ./models/ckpt\_model/ckpt
Step:41450 , train loss : 0.6873248219490051
Step:41450 , test loss : 0.6906918287277222
\# Save into ./models/ckpt\_model/ckpt
Step:41500 , train loss : 0.6779972910881042
Step:41500 , test loss : 0.6938700675964355
\# Save into ./models/ckpt\_model/ckpt
Step:41550 , train loss : 0.6960843205451965
Step:41550 , test loss : 0.6906856894493103
\# Save into ./models/ckpt\_model/ckpt
Step:41600 , train loss : 0.687538743019104
Step:41600 , test loss : 0.6906828880310059
\# Save into ./models/ckpt\_model/ckpt
Step:41650 , train loss : 0.6759738326072693
Step:41650 , test loss : 0.6941977143287659
\# Save into ./models/ckpt\_model/ckpt
Step:41700 , train loss : 0.683967113494873
Step:41700 , test loss : 0.6909469962120056
\# Save into ./models/ckpt\_model/ckpt
Step:41750 , train loss : 0.6934207677841187
Step:41750 , test loss : 0.692808985710144
\# Save into ./models/ckpt\_model/ckpt
Step:41800 , train loss : 0.6939407587051392
Step:41800 , test loss : 0.691737711429596
\# Save into ./models/ckpt\_model/ckpt
Step:41850 , train loss : 0.6655991673469543
Step:41850 , test loss : 0.6908652186393738
\# Save into ./models/ckpt\_model/ckpt
Step:41900 , train loss : 0.6857722401618958
Step:41900 , test loss : 0.6915882229804993
\# Save into ./models/ckpt\_model/ckpt
Step:41950 , train loss : 0.6937564611434937
Step:41950 , test loss : 0.6955397725105286
\# Save into ./models/ckpt\_model/ckpt
Step:42000 , train loss : 0.6849424242973328
Step:42000 , test loss : 0.6913415789604187
\# Save into ./models/ckpt\_model/ckpt
Step:42050 , train loss : 0.687990665435791
Step:42050 , test loss : 0.690720796585083
\# Save into ./models/ckpt\_model/ckpt
Step:42100 , train loss : 0.6778629422187805
Step:42100 , test loss : 0.6907021403312683
\# Save into ./models/ckpt\_model/ckpt
Step:42150 , train loss : 0.686182975769043
Step:42150 , test loss : 0.6922124028205872
\# Save into ./models/ckpt\_model/ckpt
Step:42200 , train loss : 0.7093194127082825
Step:42200 , test loss : 0.6914714574813843
\# Save into ./models/ckpt\_model/ckpt
Step:42250 , train loss : 0.6879656314849854
Step:42250 , test loss : 0.6924535036087036
\# Save into ./models/ckpt\_model/ckpt
Step:42300 , train loss : 0.6801878809928894
Step:42300 , test loss : 0.6914428472518921
\# Save into ./models/ckpt\_model/ckpt
Step:42350 , train loss : 0.7152777910232544
Step:42350 , test loss : 0.6908215880393982
\# Save into ./models/ckpt\_model/ckpt
Step:42400 , train loss : 0.7003373503684998
Step:42400 , test loss : 0.6948959827423096
\# Save into ./models/ckpt\_model/ckpt
Step:42450 , train loss : 0.676368236541748
Step:42450 , test loss : 0.6912638545036316
\# Save into ./models/ckpt\_model/ckpt
Step:42500 , train loss : 0.6893302798271179
Step:42500 , test loss : 0.6913027167320251
\# Save into ./models/ckpt\_model/ckpt
Step:42550 , train loss : 0.6741818189620972
Step:42550 , test loss : 0.6916297674179077
\# Save into ./models/ckpt\_model/ckpt
Step:42600 , train loss : 0.6993810534477234
Step:42600 , test loss : 0.6909542679786682
\# Save into ./models/ckpt\_model/ckpt
Step:42650 , train loss : 0.6810519695281982
Step:42650 , test loss : 0.6906959414482117
\# Save into ./models/ckpt\_model/ckpt
Step:42700 , train loss : 0.6914514899253845
Step:42700 , test loss : 0.6919108629226685
\# Save into ./models/ckpt\_model/ckpt
Step:42750 , train loss : 0.662635862827301
Step:42750 , test loss : 0.6907140612602234
\# Save into ./models/ckpt\_model/ckpt
Step:42800 , train loss : 0.6880333423614502
Step:42800 , test loss : 0.6907017230987549
\# Save into ./models/ckpt\_model/ckpt
Step:42850 , train loss : 0.6773654222488403
Step:42850 , test loss : 0.6909604668617249
\# Save into ./models/ckpt\_model/ckpt
Step:42900 , train loss : 0.6980576515197754
Step:42900 , test loss : 0.6919351816177368
\# Save into ./models/ckpt\_model/ckpt
Step:42950 , train loss : 0.6805462837219238
Step:42950 , test loss : 0.695618212223053
\# Save into ./models/ckpt\_model/ckpt
Step:43000 , train loss : 0.6953296065330505
Step:43000 , test loss : 0.6988630294799805
\# Save into ./models/ckpt\_model/ckpt
Step:43050 , train loss : 0.7020251154899597
Step:43050 , test loss : 0.6918283700942993
\# Save into ./models/ckpt\_model/ckpt
Step:43100 , train loss : 0.7335464954376221
Step:43100 , test loss : 0.7018697261810303
\# Save into ./models/ckpt\_model/ckpt
Step:43150 , train loss : 0.6841615438461304
Step:43150 , test loss : 0.6921104192733765
\# Save into ./models/ckpt\_model/ckpt
Step:43200 , train loss : 0.6984477639198303
Step:43200 , test loss : 0.6917728781700134
\# Save into ./models/ckpt\_model/ckpt
Step:43250 , train loss : 0.6762211322784424
Step:43250 , test loss : 0.6907974481582642
\# Save into ./models/ckpt\_model/ckpt
Step:43300 , train loss : 0.687574028968811
Step:43300 , test loss : 0.6911153793334961
\# Save into ./models/ckpt\_model/ckpt
Step:43350 , train loss : 0.6787629723548889
Step:43350 , test loss : 0.6935495138168335
\# Save into ./models/ckpt\_model/ckpt
Step:43400 , train loss : 0.659493625164032
Step:43400 , test loss : 0.6948025226593018
\# Save into ./models/ckpt\_model/ckpt
Step:43450 , train loss : 0.6823574304580688
Step:43450 , test loss : 0.6948210000991821
\# Save into ./models/ckpt\_model/ckpt
Step:43500 , train loss : 0.7475625872612
Step:43500 , test loss : 0.6906918883323669
\# Save into ./models/ckpt\_model/ckpt
Step:43550 , train loss : 0.6907253265380859
Step:43550 , test loss : 0.691159188747406
\# Save into ./models/ckpt\_model/ckpt
Step:43600 , train loss : 0.6811846494674683
Step:43600 , test loss : 0.6920126080513
\# Save into ./models/ckpt\_model/ckpt
Step:43650 , train loss : 0.6562004089355469
Step:43650 , test loss : 0.6948450207710266
\# Save into ./models/ckpt\_model/ckpt
Step:43700 , train loss : 0.6780356168746948
Step:43700 , test loss : 0.6907428503036499
\# Save into ./models/ckpt\_model/ckpt
Step:43750 , train loss : 0.6924489736557007
Step:43750 , test loss : 0.6906918287277222
\# Save into ./models/ckpt\_model/ckpt
Step:43800 , train loss : 0.6912710070610046
Step:43800 , test loss : 0.6906914710998535
\# Save into ./models/ckpt\_model/ckpt
Step:43850 , train loss : 0.674494743347168
Step:43850 , test loss : 0.6906876564025879
\# Save into ./models/ckpt\_model/ckpt
Step:43900 , train loss : 0.6760525703430176
Step:43900 , test loss : 0.6909272074699402
\# Save into ./models/ckpt\_model/ckpt
Step:43950 , train loss : 0.6831531524658203
Step:43950 , test loss : 0.6909877061843872
\# Save into ./models/ckpt\_model/ckpt
Step:44000 , train loss : 0.6861075162887573
Step:44000 , test loss : 0.6913083791732788
\# Save into ./models/ckpt\_model/ckpt
Step:44050 , train loss : 0.7237876057624817
Step:44050 , test loss : 0.6922463774681091
\# Save into ./models/ckpt\_model/ckpt
Step:44100 , train loss : 0.6597585082054138
Step:44100 , test loss : 0.6909075379371643
\# Save into ./models/ckpt\_model/ckpt
Step:44150 , train loss : 0.6890586614608765
Step:44150 , test loss : 0.692116379737854
\# Save into ./models/ckpt\_model/ckpt
Step:44200 , train loss : 0.6853140592575073
Step:44200 , test loss : 0.6907913088798523
\# Save into ./models/ckpt\_model/ckpt
Step:44250 , train loss : 0.6518099904060364
Step:44250 , test loss : 0.6945136785507202
\# Save into ./models/ckpt\_model/ckpt
Step:44300 , train loss : 0.6914064884185791
Step:44300 , test loss : 0.6906828880310059
\# Save into ./models/ckpt\_model/ckpt
Step:44350 , train loss : 0.6828389167785645
Step:44350 , test loss : 0.6925544142723083
\# Save into ./models/ckpt\_model/ckpt
Step:44400 , train loss : 0.6863328814506531
Step:44400 , test loss : 0.6915010213851929
\# Save into ./models/ckpt\_model/ckpt
Step:44450 , train loss : 0.7057852745056152
Step:44450 , test loss : 0.6926002502441406
\# Save into ./models/ckpt\_model/ckpt
Step:44500 , train loss : 0.7007631063461304
Step:44500 , test loss : 0.6912631392478943
\# Save into ./models/ckpt\_model/ckpt
Step:44550 , train loss : 0.7033866047859192
Step:44550 , test loss : 0.6915627121925354
\# Save into ./models/ckpt\_model/ckpt
Step:44600 , train loss : 0.6865982413291931
Step:44600 , test loss : 0.6911184787750244
\# Save into ./models/ckpt\_model/ckpt
Step:44650 , train loss : 0.6698864102363586
Step:44650 , test loss : 0.6911399960517883
\# Save into ./models/ckpt\_model/ckpt
Step:44700 , train loss : 0.7010121941566467
Step:44700 , test loss : 0.6908049583435059
\# Save into ./models/ckpt\_model/ckpt
Step:44750 , train loss : 0.7018960118293762
Step:44750 , test loss : 0.6933358907699585
\# Save into ./models/ckpt\_model/ckpt
Step:44800 , train loss : 0.6940814256668091
Step:44800 , test loss : 0.6908032894134521
\# Save into ./models/ckpt\_model/ckpt
Step:44850 , train loss : 0.6502984166145325
Step:44850 , test loss : 0.6976146101951599
\# Save into ./models/ckpt\_model/ckpt
Step:44900 , train loss : 0.6894592046737671
Step:44900 , test loss : 0.6907323002815247
\# Save into ./models/ckpt\_model/ckpt
Step:44950 , train loss : 0.6639306545257568
Step:44950 , test loss : 0.6928674578666687
\# Save into ./models/ckpt\_model/ckpt
Step:45000 , train loss : 0.685036838054657
Step:45000 , test loss : 0.6923328042030334
\# Save into ./models/ckpt\_model/ckpt
Step:45050 , train loss : 0.6689760684967041
Step:45050 , test loss : 0.7049334049224854
\# Save into ./models/ckpt\_model/ckpt
Step:45100 , train loss : 0.6968841552734375
Step:45100 , test loss : 0.6922355890274048
\# Save into ./models/ckpt\_model/ckpt
Step:45150 , train loss : 0.7133012413978577
Step:45150 , test loss : 0.6909800171852112
\# Save into ./models/ckpt\_model/ckpt
Step:45200 , train loss : 0.6688551306724548
Step:45200 , test loss : 0.6981887817382812
\# Save into ./models/ckpt\_model/ckpt
Step:45250 , train loss : 0.6825404167175293
Step:45250 , test loss : 0.6937990784645081
\# Save into ./models/ckpt\_model/ckpt
Step:45300 , train loss : 0.6983968615531921
Step:45300 , test loss : 0.6913566589355469
\# Save into ./models/ckpt\_model/ckpt
Step:45350 , train loss : 0.6868389844894409
Step:45350 , test loss : 0.6910253763198853
\# Save into ./models/ckpt\_model/ckpt
Step:45400 , train loss : 0.6932017803192139
Step:45400 , test loss : 0.6931048631668091
\# Save into ./models/ckpt\_model/ckpt
Step:45450 , train loss : 0.6927242875099182
Step:45450 , test loss : 0.6931116580963135
\# Save into ./models/ckpt\_model/ckpt
Step:45500 , train loss : 0.6935716271400452
Step:45500 , test loss : 0.6931021213531494
\# Save into ./models/ckpt\_model/ckpt
Step:45550 , train loss : 0.6932103037834167
Step:45550 , test loss : 0.6930862069129944
\# Save into ./models/ckpt\_model/ckpt
Step:45600 , train loss : 0.6952865123748779
Step:45600 , test loss : 0.6930646300315857
\# Save into ./models/ckpt\_model/ckpt
Step:45650 , train loss : 0.6910002827644348
Step:45650 , test loss : 0.693008542060852
\# Save into ./models/ckpt\_model/ckpt
Step:45700 , train loss : 0.6935311555862427
Step:45700 , test loss : 0.6927691102027893
\# Save into ./models/ckpt\_model/ckpt
Step:45750 , train loss : 0.6288120150566101
Step:45750 , test loss : 0.6953431963920593
\# Save into ./models/ckpt\_model/ckpt
Step:45800 , train loss : 0.6733359098434448
Step:45800 , test loss : 0.6978920102119446
\# Save into ./models/ckpt\_model/ckpt
Step:45850 , train loss : 0.6888972520828247
Step:45850 , test loss : 0.6908320188522339
\# Save into ./models/ckpt\_model/ckpt
Step:45900 , train loss : 0.7287792563438416
Step:45900 , test loss : 0.6909741163253784
\# Save into ./models/ckpt\_model/ckpt
Step:45950 , train loss : 0.6941019892692566
Step:45950 , test loss : 0.6916436553001404
\# Save into ./models/ckpt\_model/ckpt
Step:46000 , train loss : 0.6746377348899841
Step:46000 , test loss : 0.695512056350708
\# Save into ./models/ckpt\_model/ckpt
Step:46050 , train loss : 0.707928478717804
Step:46050 , test loss : 0.6910738945007324
\# Save into ./models/ckpt\_model/ckpt
Step:46100 , train loss : 0.6890506744384766
Step:46100 , test loss : 0.6919093728065491
\# Save into ./models/ckpt\_model/ckpt
Step:46150 , train loss : 0.6900308728218079
Step:46150 , test loss : 0.692489743232727
\# Save into ./models/ckpt\_model/ckpt
Step:46200 , train loss : 0.6105744242668152
Step:46200 , test loss : 0.6958466172218323
\# Save into ./models/ckpt\_model/ckpt
Step:46250 , train loss : 0.6930332183837891
Step:46250 , test loss : 0.690799355506897
\# Save into ./models/ckpt\_model/ckpt
Step:46300 , train loss : 0.6762312054634094
Step:46300 , test loss : 0.6915008425712585
\# Save into ./models/ckpt\_model/ckpt
Step:46350 , train loss : 0.6622456908226013
Step:46350 , test loss : 0.6911656856536865
\# Save into ./models/ckpt\_model/ckpt
Step:46400 , train loss : 0.6857256889343262
Step:46400 , test loss : 0.6917507648468018
\# Save into ./models/ckpt\_model/ckpt
Step:46450 , train loss : 0.6934466361999512
Step:46450 , test loss : 0.6963950991630554
\# Save into ./models/ckpt\_model/ckpt
Step:46500 , train loss : 0.702202558517456
Step:46500 , test loss : 0.6908026337623596
\# Save into ./models/ckpt\_model/ckpt
Step:46550 , train loss : 0.6832739114761353
Step:46550 , test loss : 0.6913628578186035
\# Save into ./models/ckpt\_model/ckpt
Step:46600 , train loss : 0.7002440690994263
Step:46600 , test loss : 0.6927271485328674
\# Save into ./models/ckpt\_model/ckpt
Step:46650 , train loss : 0.69598788022995
Step:46650 , test loss : 0.690750777721405
\# Save into ./models/ckpt\_model/ckpt
Step:46700 , train loss : 0.687224268913269
Step:46700 , test loss : 0.6917985677719116
\# Save into ./models/ckpt\_model/ckpt
Step:46750 , train loss : 0.6928842067718506
Step:46750 , test loss : 0.6926807761192322
\# Save into ./models/ckpt\_model/ckpt
Step:46800 , train loss : 0.6892122626304626
Step:46800 , test loss : 0.6928597092628479
\# Save into ./models/ckpt\_model/ckpt
Step:46850 , train loss : 0.6858910322189331
Step:46850 , test loss : 0.6912140846252441
\# Save into ./models/ckpt\_model/ckpt
Step:46900 , train loss : 0.7025222182273865
Step:46900 , test loss : 0.6906837821006775
\# Save into ./models/ckpt\_model/ckpt
Step:46950 , train loss : 0.6565862894058228
Step:46950 , test loss : 0.6982649564743042
\# Save into ./models/ckpt\_model/ckpt
Step:47000 , train loss : 0.6955651044845581
Step:47000 , test loss : 0.6907795071601868
\# Save into ./models/ckpt\_model/ckpt
Step:47050 , train loss : 0.7157208919525146
Step:47050 , test loss : 0.6968319416046143
\# Save into ./models/ckpt\_model/ckpt
Step:47100 , train loss : 0.6918389201164246
Step:47100 , test loss : 0.6930105090141296
\# Save into ./models/ckpt\_model/ckpt
Step:47150 , train loss : 0.6921364665031433
Step:47150 , test loss : 0.6928897500038147
\# Save into ./models/ckpt\_model/ckpt
Step:47200 , train loss : 0.6880704164505005
Step:47200 , test loss : 0.6918814778327942
\# Save into ./models/ckpt\_model/ckpt
Step:47250 , train loss : 0.6915731430053711
Step:47250 , test loss : 0.6922484040260315
\# Save into ./models/ckpt\_model/ckpt
Step:47300 , train loss : 0.6984429955482483
Step:47300 , test loss : 0.6927480101585388
\# Save into ./models/ckpt\_model/ckpt
Step:47350 , train loss : 0.6739733815193176
Step:47350 , test loss : 0.6926053762435913
\# Save into ./models/ckpt\_model/ckpt
Step:47400 , train loss : 0.714813232421875
Step:47400 , test loss : 0.6911030411720276
\# Save into ./models/ckpt\_model/ckpt
Step:47450 , train loss : 0.7031760215759277
Step:47450 , test loss : 0.6976369023323059
\# Save into ./models/ckpt\_model/ckpt
Step:47500 , train loss : 0.6907358169555664
Step:47500 , test loss : 0.6913200616836548
\# Save into ./models/ckpt\_model/ckpt
Step:47550 , train loss : 0.6815921664237976
Step:47550 , test loss : 0.6928041577339172
\# Save into ./models/ckpt\_model/ckpt
Step:47600 , train loss : 0.7245234251022339
Step:47600 , test loss : 0.7013387084007263
\# Save into ./models/ckpt\_model/ckpt
Step:47650 , train loss : 0.6813234686851501
Step:47650 , test loss : 0.6925223469734192
\# Save into ./models/ckpt\_model/ckpt
Step:47700 , train loss : 0.7131344676017761
Step:47700 , test loss : 0.6911314725875854
\# Save into ./models/ckpt\_model/ckpt
Step:47750 , train loss : 0.6734252572059631
Step:47750 , test loss : 0.6968243718147278
\# Save into ./models/ckpt\_model/ckpt
Step:47800 , train loss : 0.6939775943756104
Step:47800 , test loss : 0.6923187375068665
\# Save into ./models/ckpt\_model/ckpt
Step:47850 , train loss : 0.6332141757011414
Step:47850 , test loss : 0.6920909285545349
\# Save into ./models/ckpt\_model/ckpt
Step:47900 , train loss : 0.6689181327819824
Step:47900 , test loss : 0.7258331775665283
\# Save into ./models/ckpt\_model/ckpt
Step:47950 , train loss : 0.692903995513916
Step:47950 , test loss : 0.6931315064430237
\# Save into ./models/ckpt\_model/ckpt
Step:48000 , train loss : 0.6930015087127686
Step:48000 , test loss : 0.6931294798851013
\# Save into ./models/ckpt\_model/ckpt
Step:48050 , train loss : 0.6933096051216125
Step:48050 , test loss : 0.6931241750717163
\# Save into ./models/ckpt\_model/ckpt
Step:48100 , train loss : 0.6927282214164734
Step:48100 , test loss : 0.6931172013282776
\# Save into ./models/ckpt\_model/ckpt
Step:48150 , train loss : 0.6935114860534668
Step:48150 , test loss : 0.693111002445221
\# Save into ./models/ckpt\_model/ckpt
Step:48200 , train loss : 0.6939473748207092
Step:48200 , test loss : 0.693088710308075
\# Save into ./models/ckpt\_model/ckpt
Step:48250 , train loss : 0.6937662959098816
Step:48250 , test loss : 0.6930733919143677
\# Save into ./models/ckpt\_model/ckpt
Step:48300 , train loss : 0.6941103935241699
Step:48300 , test loss : 0.6929758191108704
\# Save into ./models/ckpt\_model/ckpt
Step:48350 , train loss : 0.6949189901351929
Step:48350 , test loss : 0.692791223526001
\# Save into ./models/ckpt\_model/ckpt
Step:48400 , train loss : 0.6803773641586304
Step:48400 , test loss : 0.6907610893249512
\# Save into ./models/ckpt\_model/ckpt
Step:48450 , train loss : 0.6612774729728699
Step:48450 , test loss : 0.6914591193199158
\# Save into ./models/ckpt\_model/ckpt
Step:48500 , train loss : 0.6839130520820618
Step:48500 , test loss : 0.6922613382339478
\# Save into ./models/ckpt\_model/ckpt
Step:48550 , train loss : 0.6919785141944885
Step:48550 , test loss : 0.6926790475845337
\# Save into ./models/ckpt\_model/ckpt
Step:48600 , train loss : 0.6913191676139832
Step:48600 , test loss : 0.6926640868186951
\# Save into ./models/ckpt\_model/ckpt
Step:48650 , train loss : 0.6768826842308044
Step:48650 , test loss : 0.6913790106773376
\# Save into ./models/ckpt\_model/ckpt
Step:48700 , train loss : 0.6798738241195679
Step:48700 , test loss : 0.6908864378929138
\# Save into ./models/ckpt\_model/ckpt
Step:48750 , train loss : 0.6937469840049744
Step:48750 , test loss : 0.6928887367248535
\# Save into ./models/ckpt\_model/ckpt
Step:48800 , train loss : 0.6918220520019531
Step:48800 , test loss : 0.6920487284660339
\# Save into ./models/ckpt\_model/ckpt
Step:48850 , train loss : 0.6887043714523315
Step:48850 , test loss : 0.690974771976471
\# Save into ./models/ckpt\_model/ckpt
Step:48900 , train loss : 0.646963357925415
Step:48900 , test loss : 0.6916062831878662
\# Save into ./models/ckpt\_model/ckpt
Step:48950 , train loss : 0.6931209564208984
Step:48950 , test loss : 0.6930447816848755
\# Save into ./models/ckpt\_model/ckpt
Step:49000 , train loss : 0.6930969953536987
Step:49000 , test loss : 0.6929550766944885
\# Save into ./models/ckpt\_model/ckpt
Step:49050 , train loss : 0.6981205344200134
Step:49050 , test loss : 0.6924927830696106
\# Save into ./models/ckpt\_model/ckpt
Step:49100 , train loss : 0.6911391615867615
Step:49100 , test loss : 0.6913707256317139
\# Save into ./models/ckpt\_model/ckpt
Step:49150 , train loss : 0.6747117042541504
Step:49150 , test loss : 0.6910393834114075
\# Save into ./models/ckpt\_model/ckpt
Step:49200 , train loss : 0.7038996815681458
Step:49200 , test loss : 0.6948524117469788
\# Save into ./models/ckpt\_model/ckpt
Step:49250 , train loss : 0.7177706360816956
Step:49250 , test loss : 0.6924427151679993
\# Save into ./models/ckpt\_model/ckpt
Step:49300 , train loss : 0.6954778432846069
Step:49300 , test loss : 0.6910090446472168
\# Save into ./models/ckpt\_model/ckpt
Step:49350 , train loss : 0.6794551014900208
Step:49350 , test loss : 0.6921453475952148
\# Save into ./models/ckpt\_model/ckpt
Step:49400 , train loss : 0.6895332336425781
Step:49400 , test loss : 0.6906841993331909
\# Save into ./models/ckpt\_model/ckpt
Step:49450 , train loss : 0.6946808099746704
Step:49450 , test loss : 0.6927211284637451
\# Save into ./models/ckpt\_model/ckpt
Step:49500 , train loss : 0.7064290642738342
Step:49500 , test loss : 0.692713737487793
\# Save into ./models/ckpt\_model/ckpt
Step:49550 , train loss : 0.6714174747467041
Step:49550 , test loss : 0.691922664642334
\# Save into ./models/ckpt\_model/ckpt
Step:49600 , train loss : 0.6915414333343506
Step:49600 , test loss : 0.6921792030334473
\# Save into ./models/ckpt\_model/ckpt
Step:49650 , train loss : 0.7099635601043701
Step:49650 , test loss : 0.6914300918579102
\# Save into ./models/ckpt\_model/ckpt
Step:49700 , train loss : 0.6953142881393433
Step:49700 , test loss : 0.6906937956809998
\# Save into ./models/ckpt\_model/ckpt
Step:49750 , train loss : 0.6654330492019653
Step:49750 , test loss : 0.6920973062515259
\# Save into ./models/ckpt\_model/ckpt
Step:49800 , train loss : 0.6901757121086121
Step:49800 , test loss : 0.6914659738540649
\# Save into ./models/ckpt\_model/ckpt
Step:49850 , train loss : 0.682574987411499
Step:49850 , test loss : 0.6908173561096191
\# Save into ./models/ckpt\_model/ckpt
Step:49900 , train loss : 0.6944482326507568
Step:49900 , test loss : 0.6926982998847961
\# Save into ./models/ckpt\_model/ckpt
Step:49950 , train loss : 0.6958419680595398
Step:49950 , test loss : 0.6918776035308838
\# Save into ./models/ckpt\_model/ckpt
Step:50000 , train loss : 0.6763232946395874
Step:50000 , test loss : 0.6908256411552429
\# Save into ./models/ckpt\_model/ckpt
Step:50050 , train loss : 0.6832736134529114
Step:50050 , test loss : 0.6908301711082458
\# Save into ./models/ckpt\_model/ckpt
Step:50100 , train loss : 0.6966179013252258
Step:50100 , test loss : 0.6909558773040771
\# Save into ./models/ckpt\_model/ckpt
Step:50150 , train loss : 0.6664474010467529
Step:50150 , test loss : 0.6913250684738159
\# Save into ./models/ckpt\_model/ckpt
Step:50200 , train loss : 0.6813187599182129
Step:50200 , test loss : 0.6908932328224182
\# Save into ./models/ckpt\_model/ckpt
Step:50250 , train loss : 0.7591655850410461
Step:50250 , test loss : 0.6906884908676147
\# Save into ./models/ckpt\_model/ckpt
Step:50300 , train loss : 0.6924354434013367
Step:50300 , test loss : 0.6917164325714111
\# Save into ./models/ckpt\_model/ckpt
Step:50350 , train loss : 0.6823577880859375
Step:50350 , test loss : 0.6917704939842224
\# Save into ./models/ckpt\_model/ckpt
Step:50400 , train loss : 0.671846330165863
Step:50400 , test loss : 0.696608304977417
\# Save into ./models/ckpt\_model/ckpt
Step:50450 , train loss : 0.6921896934509277
Step:50450 , test loss : 0.6918947696685791
\# Save into ./models/ckpt\_model/ckpt
Step:50500 , train loss : 0.6822482347488403
Step:50500 , test loss : 0.6910291314125061
\# Save into ./models/ckpt\_model/ckpt
Step:50550 , train loss : 0.710576057434082
Step:50550 , test loss : 0.6910597085952759
\# Save into ./models/ckpt\_model/ckpt
Step:50600 , train loss : 0.6670076847076416
Step:50600 , test loss : 0.6917659044265747
\# Save into ./models/ckpt\_model/ckpt
Step:50650 , train loss : 0.686593770980835
Step:50650 , test loss : 0.6909673810005188
\# Save into ./models/ckpt\_model/ckpt
Step:50700 , train loss : 0.6701464653015137
Step:50700 , test loss : 0.6911052465438843
\# Save into ./models/ckpt\_model/ckpt
Step:50750 , train loss : 0.7255309820175171
Step:50750 , test loss : 0.691303014755249
\# Save into ./models/ckpt\_model/ckpt
Step:50800 , train loss : 0.7015290260314941
Step:50800 , test loss : 0.6930667757987976
\# Save into ./models/ckpt\_model/ckpt
Step:50850 , train loss : 0.7099010944366455
Step:50850 , test loss : 0.691255509853363
\# Save into ./models/ckpt\_model/ckpt
Step:50900 , train loss : 0.6864253282546997
Step:50900 , test loss : 0.6916207671165466
\# Save into ./models/ckpt\_model/ckpt
Step:50950 , train loss : 0.6889961361885071
Step:50950 , test loss : 0.6908974647521973
\# Save into ./models/ckpt\_model/ckpt
Step:51000 , train loss : 0.7054880261421204
Step:51000 , test loss : 0.6909838914871216
\# Save into ./models/ckpt\_model/ckpt
Step:51050 , train loss : 0.6678049564361572
Step:51050 , test loss : 0.6910039782524109
\# Save into ./models/ckpt\_model/ckpt
Step:51100 , train loss : 0.6700398921966553
Step:51100 , test loss : 0.6908097267150879
\# Save into ./models/ckpt\_model/ckpt
Step:51150 , train loss : 0.6782566905021667
Step:51150 , test loss : 0.6914377808570862
\# Save into ./models/ckpt\_model/ckpt
Step:51200 , train loss : 0.6916823983192444
Step:51200 , test loss : 0.6920270323753357
\# Save into ./models/ckpt\_model/ckpt
Step:51250 , train loss : 0.6854085922241211
Step:51250 , test loss : 0.6907293796539307
\# Save into ./models/ckpt\_model/ckpt
Step:51300 , train loss : 0.6619569063186646
Step:51300 , test loss : 0.6923096179962158
\# Save into ./models/ckpt\_model/ckpt
Step:51350 , train loss : 0.7107583284378052
Step:51350 , test loss : 0.6940879821777344
\# Save into ./models/ckpt\_model/ckpt
Step:51400 , train loss : 0.687591552734375
Step:51400 , test loss : 0.6907410621643066
\# Save into ./models/ckpt\_model/ckpt
Step:51450 , train loss : 0.7076702117919922
Step:51450 , test loss : 0.6928856372833252
\# Save into ./models/ckpt\_model/ckpt
Step:51500 , train loss : 0.7319489121437073
Step:51500 , test loss : 0.6916025876998901
\# Save into ./models/ckpt\_model/ckpt
Step:51550 , train loss : 0.6820616722106934
Step:51550 , test loss : 0.6924117803573608
\# Save into ./models/ckpt\_model/ckpt
Step:51600 , train loss : 0.6611688733100891
Step:51600 , test loss : 0.6909862756729126
\# Save into ./models/ckpt\_model/ckpt
Step:51650 , train loss : 0.6967189311981201
Step:51650 , test loss : 0.6920895576477051
\# Save into ./models/ckpt\_model/ckpt
Step:51700 , train loss : 0.6671534776687622
Step:51700 , test loss : 0.6960181593894958
\# Save into ./models/ckpt\_model/ckpt
Step:51750 , train loss : 0.7085096836090088
Step:51750 , test loss : 0.6907296180725098
\# Save into ./models/ckpt\_model/ckpt
Step:51800 , train loss : 0.7105231285095215
Step:51800 , test loss : 0.6926276683807373
\# Save into ./models/ckpt\_model/ckpt
Step:51850 , train loss : 0.6829096078872681
Step:51850 , test loss : 0.6912646293640137
\# Save into ./models/ckpt\_model/ckpt
Step:51900 , train loss : 0.7005756497383118
Step:51900 , test loss : 0.6913049221038818
\# Save into ./models/ckpt\_model/ckpt
Step:51950 , train loss : 0.6623308658599854
Step:51950 , test loss : 0.6909351944923401
\# Save into ./models/ckpt\_model/ckpt
Step:52000 , train loss : 0.6866809129714966
Step:52000 , test loss : 0.6908648014068604
\# Save into ./models/ckpt\_model/ckpt
Step:52050 , train loss : 0.6991921067237854
Step:52050 , test loss : 0.6906885504722595
\# Save into ./models/ckpt\_model/ckpt
Step:52100 , train loss : 0.6943811178207397
Step:52100 , test loss : 0.6909341812133789
\# Save into ./models/ckpt\_model/ckpt
Step:52150 , train loss : 0.6833497285842896
Step:52150 , test loss : 0.690703809261322
\# Save into ./models/ckpt\_model/ckpt
Step:52200 , train loss : 0.6559702754020691
Step:52200 , test loss : 0.6912417411804199
\# Save into ./models/ckpt\_model/ckpt
Step:52250 , train loss : 0.6894766092300415
Step:52250 , test loss : 0.6962130069732666
\# Save into ./models/ckpt\_model/ckpt
Step:52300 , train loss : 0.6913502812385559
Step:52300 , test loss : 0.6906830072402954
\# Save into ./models/ckpt\_model/ckpt
Step:52350 , train loss : 0.7095375061035156
Step:52350 , test loss : 0.691872775554657
\# Save into ./models/ckpt\_model/ckpt
Step:52400 , train loss : 0.6913137435913086
Step:52400 , test loss : 0.690704882144928
\# Save into ./models/ckpt\_model/ckpt
Step:52450 , train loss : 0.6849944591522217
Step:52450 , test loss : 0.691188395023346
\# Save into ./models/ckpt\_model/ckpt
Step:52500 , train loss : 0.6961822509765625
Step:52500 , test loss : 0.692318320274353
\# Save into ./models/ckpt\_model/ckpt
Step:52550 , train loss : 0.6848191618919373
Step:52550 , test loss : 0.6913317441940308
\# Save into ./models/ckpt\_model/ckpt
Step:52600 , train loss : 0.6879246830940247
Step:52600 , test loss : 0.6909157633781433
\# Save into ./models/ckpt\_model/ckpt
Step:52650 , train loss : 0.6847159266471863
Step:52650 , test loss : 0.6916415095329285
\# Save into ./models/ckpt\_model/ckpt
Step:52700 , train loss : 0.6865518093109131
Step:52700 , test loss : 0.6908411979675293
\# Save into ./models/ckpt\_model/ckpt
Step:52750 , train loss : 0.6438646912574768
Step:52750 , test loss : 0.7008733749389648
\# Save into ./models/ckpt\_model/ckpt
Step:52800 , train loss : 0.6922371983528137
Step:52800 , test loss : 0.6931244730949402
\# Save into ./models/ckpt\_model/ckpt
Step:52850 , train loss : 0.6929583549499512
Step:52850 , test loss : 0.6931232810020447
\# Save into ./models/ckpt\_model/ckpt
Step:52900 , train loss : 0.6927145719528198
Step:52900 , test loss : 0.6931197047233582
\# Save into ./models/ckpt\_model/ckpt
Step:52950 , train loss : 0.6936952471733093
Step:52950 , test loss : 0.6931135058403015
\# Save into ./models/ckpt\_model/ckpt
Step:53000 , train loss : 0.6923017501831055
Step:53000 , test loss : 0.6931053996086121
\# Save into ./models/ckpt\_model/ckpt
Step:53050 , train loss : 0.6923624277114868
Step:53050 , test loss : 0.6930899620056152
\# Save into ./models/ckpt\_model/ckpt
Step:53100 , train loss : 0.6905143857002258
Step:53100 , test loss : 0.6930629014968872
\# Save into ./models/ckpt\_model/ckpt
Step:53150 , train loss : 0.6933978796005249
Step:53150 , test loss : 0.6929539442062378
\# Save into ./models/ckpt\_model/ckpt
Step:53200 , train loss : 0.6887321472167969
Step:53200 , test loss : 0.6919358372688293
\# Save into ./models/ckpt\_model/ckpt
Step:53250 , train loss : 0.6509296894073486
Step:53250 , test loss : 0.6906831860542297
\# Save into ./models/ckpt\_model/ckpt
Step:53300 , train loss : 0.69930100440979
Step:53300 , test loss : 0.6928747296333313
\# Save into ./models/ckpt\_model/ckpt
Step:53350 , train loss : 0.6896899938583374
Step:53350 , test loss : 0.6917207837104797
\# Save into ./models/ckpt\_model/ckpt
Step:53400 , train loss : 0.6179232597351074
Step:53400 , test loss : 0.697559118270874
\# Save into ./models/ckpt\_model/ckpt
Step:53450 , train loss : 0.8181629180908203
Step:53450 , test loss : 0.7082768678665161
\# Save into ./models/ckpt\_model/ckpt
Step:53500 , train loss : 0.6949833035469055
Step:53500 , test loss : 0.6929542422294617
\# Save into ./models/ckpt\_model/ckpt
Step:53550 , train loss : 0.6735763549804688
Step:53550 , test loss : 0.692047119140625
\# Save into ./models/ckpt\_model/ckpt
Step:53600 , train loss : 0.6976350545883179
Step:53600 , test loss : 0.6908432841300964
\# Save into ./models/ckpt\_model/ckpt
Step:53650 , train loss : 0.6928467750549316
Step:53650 , test loss : 0.6930885910987854
\# Save into ./models/ckpt\_model/ckpt
Step:53700 , train loss : 0.6927792429924011
Step:53700 , test loss : 0.693069338798523
\# Save into ./models/ckpt\_model/ckpt
Step:53750 , train loss : 0.6917624473571777
Step:53750 , test loss : 0.6930098533630371
\# Save into ./models/ckpt\_model/ckpt
Step:53800 , train loss : 0.6931052207946777
Step:53800 , test loss : 0.6927327513694763
\# Save into ./models/ckpt\_model/ckpt
Step:53850 , train loss : 0.728076696395874
Step:53850 , test loss : 0.6944674253463745
\# Save into ./models/ckpt\_model/ckpt
Step:53900 , train loss : 0.69090336561203
Step:53900 , test loss : 0.6929647922515869
\# Save into ./models/ckpt\_model/ckpt
Step:53950 , train loss : 0.6926141977310181
Step:53950 , test loss : 0.6928252577781677
\# Save into ./models/ckpt\_model/ckpt
Step:54000 , train loss : 0.7070202231407166
Step:54000 , test loss : 0.6906978487968445
\# Save into ./models/ckpt\_model/ckpt
Step:54050 , train loss : 0.6905619502067566
Step:54050 , test loss : 0.6929669380187988
\# Save into ./models/ckpt\_model/ckpt
Step:54100 , train loss : 0.6940200328826904
Step:54100 , test loss : 0.6926611661911011
\# Save into ./models/ckpt\_model/ckpt
Step:54150 , train loss : 0.7049083113670349
Step:54150 , test loss : 0.6912428140640259
\# Save into ./models/ckpt\_model/ckpt
Step:54200 , train loss : 0.6939617395401001
Step:54200 , test loss : 0.69302898645401
\# Save into ./models/ckpt\_model/ckpt
Step:54250 , train loss : 0.6930939555168152
Step:54250 , test loss : 0.6929031610488892
\# Save into ./models/ckpt\_model/ckpt
Step:54300 , train loss : 0.6984444260597229
Step:54300 , test loss : 0.690797746181488
\# Save into ./models/ckpt\_model/ckpt
Step:54350 , train loss : 0.6842393279075623
Step:54350 , test loss : 0.6919105052947998
\# Save into ./models/ckpt\_model/ckpt
Step:54400 , train loss : 0.6940407752990723
Step:54400 , test loss : 0.6915691494941711
\# Save into ./models/ckpt\_model/ckpt
Step:54450 , train loss : 0.6757510304450989
Step:54450 , test loss : 0.6918842792510986
\# Save into ./models/ckpt\_model/ckpt
Step:54500 , train loss : 0.6866854429244995
Step:54500 , test loss : 0.691780686378479
\# Save into ./models/ckpt\_model/ckpt
Step:54550 , train loss : 0.6956527233123779
Step:54550 , test loss : 0.6907117366790771
\# Save into ./models/ckpt\_model/ckpt
Step:54600 , train loss : 0.6311290264129639
Step:54600 , test loss : 0.6965703368186951
\# Save into ./models/ckpt\_model/ckpt
Step:54650 , train loss : 0.698339581489563
Step:54650 , test loss : 0.6908161044120789
\# Save into ./models/ckpt\_model/ckpt
Step:54700 , train loss : 0.6673699617385864
Step:54700 , test loss : 0.6963445544242859
\# Save into ./models/ckpt\_model/ckpt
Step:54750 , train loss : 0.651120126247406
Step:54750 , test loss : 0.6934006810188293
\# Save into ./models/ckpt\_model/ckpt
Step:54800 , train loss : 0.7259270548820496
Step:54800 , test loss : 0.6981436014175415
\# Save into ./models/ckpt\_model/ckpt
Step:54850 , train loss : 0.6962519288063049
Step:54850 , test loss : 0.6909169554710388
\# Save into ./models/ckpt\_model/ckpt
Step:54900 , train loss : 0.6802642345428467
Step:54900 , test loss : 0.6915406584739685
\# Save into ./models/ckpt\_model/ckpt
Step:54950 , train loss : 0.6871321201324463
Step:54950 , test loss : 0.6906910538673401
\# Save into ./models/ckpt\_model/ckpt
Step:55000 , train loss : 0.6791846752166748
Step:55000 , test loss : 0.6915513277053833
\# Save into ./models/ckpt\_model/ckpt
Step:55050 , train loss : 0.6796300411224365
Step:55050 , test loss : 0.6918407082557678
\# Save into ./models/ckpt\_model/ckpt
Step:55100 , train loss : 0.7044727802276611
Step:55100 , test loss : 0.6913665533065796
\# Save into ./models/ckpt\_model/ckpt
Step:55150 , train loss : 0.6704683303833008
Step:55150 , test loss : 0.6934437155723572
\# Save into ./models/ckpt\_model/ckpt
Step:55200 , train loss : 0.7032042145729065
Step:55200 , test loss : 0.690692663192749
\# Save into ./models/ckpt\_model/ckpt
Step:55250 , train loss : 0.7005891799926758
Step:55250 , test loss : 0.6941068768501282
\# Save into ./models/ckpt\_model/ckpt
Step:55300 , train loss : 0.687889039516449
Step:55300 , test loss : 0.6907477974891663
\# Save into ./models/ckpt\_model/ckpt
Step:55350 , train loss : 0.6749691963195801
Step:55350 , test loss : 0.694229006767273
\# Save into ./models/ckpt\_model/ckpt
Step:55400 , train loss : 0.6912263631820679
Step:55400 , test loss : 0.6919391751289368
\# Save into ./models/ckpt\_model/ckpt
Step:55450 , train loss : 0.693999707698822
Step:55450 , test loss : 0.6907793879508972
\# Save into ./models/ckpt\_model/ckpt
Step:55500 , train loss : 0.6800110936164856
Step:55500 , test loss : 0.6907022595405579
\# Save into ./models/ckpt\_model/ckpt
Step:55550 , train loss : 0.6755117177963257
Step:55550 , test loss : 0.6915589570999146
\# Save into ./models/ckpt\_model/ckpt
Step:55600 , train loss : 0.690457820892334
Step:55600 , test loss : 0.6928337216377258
\# Save into ./models/ckpt\_model/ckpt
Step:55650 , train loss : 0.6907691359519958
Step:55650 , test loss : 0.6915587186813354
\# Save into ./models/ckpt\_model/ckpt
Step:55700 , train loss : 0.6889764666557312
Step:55700 , test loss : 0.6910293102264404
\# Save into ./models/ckpt\_model/ckpt
Step:55750 , train loss : 0.6820820569992065
Step:55750 , test loss : 0.6911174654960632
\# Save into ./models/ckpt\_model/ckpt
Step:55800 , train loss : 0.6960849761962891
Step:55800 , test loss : 0.6918187141418457
\# Save into ./models/ckpt\_model/ckpt
Step:55850 , train loss : 0.68009352684021
Step:55850 , test loss : 0.6932885050773621
\# Save into ./models/ckpt\_model/ckpt
Step:55900 , train loss : 0.6839579343795776
Step:55900 , test loss : 0.6909850835800171
\# Save into ./models/ckpt\_model/ckpt
Step:55950 , train loss : 0.6827058792114258
Step:55950 , test loss : 0.6908982396125793
\# Save into ./models/ckpt\_model/ckpt
Step:56000 , train loss : 0.6794532537460327
Step:56000 , test loss : 0.6912438869476318
\# Save into ./models/ckpt\_model/ckpt
Step:56050 , train loss : 0.6783095598220825
Step:56050 , test loss : 0.6928567886352539
\# Save into ./models/ckpt\_model/ckpt
Step:56100 , train loss : 0.6908678412437439
Step:56100 , test loss : 0.6908143758773804
\# Save into ./models/ckpt\_model/ckpt
Step:56150 , train loss : 0.6899265050888062
Step:56150 , test loss : 0.6926459074020386
\# Save into ./models/ckpt\_model/ckpt
Step:56200 , train loss : 0.6454396843910217
Step:56200 , test loss : 0.6960561871528625
\# Save into ./models/ckpt\_model/ckpt
Step:56250 , train loss : 0.7000778317451477
Step:56250 , test loss : 0.6917381882667542
\# Save into ./models/ckpt\_model/ckpt
Step:56300 , train loss : 0.6952581405639648
Step:56300 , test loss : 0.6933013796806335
\# Save into ./models/ckpt\_model/ckpt
Step:56350 , train loss : 0.7290949821472168
Step:56350 , test loss : 0.6919649243354797
\# Save into ./models/ckpt\_model/ckpt
Step:56400 , train loss : 0.6898336410522461
Step:56400 , test loss : 0.6929300427436829
\# Save into ./models/ckpt\_model/ckpt
Step:56450 , train loss : 0.690613865852356
Step:56450 , test loss : 0.6928829550743103
\# Save into ./models/ckpt\_model/ckpt
Step:56500 , train loss : 0.6928735971450806
Step:56500 , test loss : 0.692164957523346
\# Save into ./models/ckpt\_model/ckpt
Step:56550 , train loss : 0.6656133532524109
Step:56550 , test loss : 0.6910688281059265
\# Save into ./models/ckpt\_model/ckpt
Step:56600 , train loss : 0.6921893358230591
Step:56600 , test loss : 0.6913585066795349
\# Save into ./models/ckpt\_model/ckpt
Step:56650 , train loss : 0.6757705211639404
Step:56650 , test loss : 0.6908295750617981
\# Save into ./models/ckpt\_model/ckpt
Step:56700 , train loss : 0.6752926707267761
Step:56700 , test loss : 0.6919554471969604
\# Save into ./models/ckpt\_model/ckpt
Step:56750 , train loss : 0.6765294075012207
Step:56750 , test loss : 0.6907268166542053
\# Save into ./models/ckpt\_model/ckpt
Step:56800 , train loss : 0.6919070482254028
Step:56800 , test loss : 0.691135585308075
\# Save into ./models/ckpt\_model/ckpt
Step:56850 , train loss : 0.6526952385902405
Step:56850 , test loss : 0.6944639682769775
\# Save into ./models/ckpt\_model/ckpt
Step:56900 , train loss : 0.6881561279296875
Step:56900 , test loss : 0.6917653679847717
\# Save into ./models/ckpt\_model/ckpt
Step:56950 , train loss : 0.6913705468177795
Step:56950 , test loss : 0.6921713948249817
\# Save into ./models/ckpt\_model/ckpt
Step:57000 , train loss : 0.6829138398170471
Step:57000 , test loss : 0.6909758448600769
\# Save into ./models/ckpt\_model/ckpt
Step:57050 , train loss : 0.6796483993530273
Step:57050 , test loss : 0.6912024617195129
\# Save into ./models/ckpt\_model/ckpt
Step:57100 , train loss : 0.6857464909553528
Step:57100 , test loss : 0.69166499376297
\# Save into ./models/ckpt\_model/ckpt
Step:57150 , train loss : 0.7054951786994934
Step:57150 , test loss : 0.6907294988632202
\# Save into ./models/ckpt\_model/ckpt
Step:57200 , train loss : 0.6852420568466187
Step:57200 , test loss : 0.6908342242240906
\# Save into ./models/ckpt\_model/ckpt
Step:57250 , train loss : 0.6893314719200134
Step:57250 , test loss : 0.6913393139839172
\# Save into ./models/ckpt\_model/ckpt
Step:57300 , train loss : 0.6772226691246033
Step:57300 , test loss : 0.6913139820098877
\# Save into ./models/ckpt\_model/ckpt
Step:57350 , train loss : 0.6912169456481934
Step:57350 , test loss : 0.7020131945610046
\# Save into ./models/ckpt\_model/ckpt
Step:57400 , train loss : 0.6860198974609375
Step:57400 , test loss : 0.6908514499664307
\# Save into ./models/ckpt\_model/ckpt
Step:57450 , train loss : 0.6868858933448792
Step:57450 , test loss : 0.6925427913665771
\# Save into ./models/ckpt\_model/ckpt
Step:57500 , train loss : 0.7059866189956665
Step:57500 , test loss : 0.6948447227478027
\# Save into ./models/ckpt\_model/ckpt
Step:57550 , train loss : 0.6920256018638611
Step:57550 , test loss : 0.6920334100723267
\# Save into ./models/ckpt\_model/ckpt
Step:57600 , train loss : 0.699392557144165
Step:57600 , test loss : 0.6907155513763428
\# Save into ./models/ckpt\_model/ckpt
Step:57650 , train loss : 0.6869068145751953
Step:57650 , test loss : 0.6909891366958618
\# Save into ./models/ckpt\_model/ckpt
Step:57700 , train loss : 0.6786471009254456
Step:57700 , test loss : 0.693687915802002
\# Save into ./models/ckpt\_model/ckpt
Step:57750 , train loss : 0.6793797016143799
Step:57750 , test loss : 0.6909807324409485
\# Save into ./models/ckpt\_model/ckpt
Step:57800 , train loss : 0.697615921497345
Step:57800 , test loss : 0.6982245445251465
\# Save into ./models/ckpt\_model/ckpt
Step:57850 , train loss : 0.7032166719436646
Step:57850 , test loss : 0.6917240023612976
\# Save into ./models/ckpt\_model/ckpt
Step:57900 , train loss : 0.7139708995819092
Step:57900 , test loss : 0.6907833814620972
\# Save into ./models/ckpt\_model/ckpt
Step:57950 , train loss : 0.6831842660903931
Step:57950 , test loss : 0.690960705280304
\# Save into ./models/ckpt\_model/ckpt
Step:58000 , train loss : 0.6807254552841187
Step:58000 , test loss : 0.6906992197036743
\# Save into ./models/ckpt\_model/ckpt
Step:58050 , train loss : 0.7371160387992859
Step:58050 , test loss : 0.691125750541687
\# Save into ./models/ckpt\_model/ckpt
Step:58100 , train loss : 0.6751214861869812
Step:58100 , test loss : 0.696068525314331
\# Save into ./models/ckpt\_model/ckpt
Step:58150 , train loss : 0.688312292098999
Step:58150 , test loss : 0.6910267472267151
\# Save into ./models/ckpt\_model/ckpt
Step:58200 , train loss : 0.6796092987060547
Step:58200 , test loss : 0.6943252086639404
\# Save into ./models/ckpt\_model/ckpt
Step:58250 , train loss : 0.6876038908958435
Step:58250 , test loss : 0.6907001733779907
\# Save into ./models/ckpt\_model/ckpt
Step:58300 , train loss : 0.6778302788734436
Step:58300 , test loss : 0.690913736820221
\# Save into ./models/ckpt\_model/ckpt
Step:58350 , train loss : 0.7048104405403137
Step:58350 , test loss : 0.6917586922645569
\# Save into ./models/ckpt\_model/ckpt
Step:58400 , train loss : 0.6924479603767395
Step:58400 , test loss : 0.6930458545684814
\# Save into ./models/ckpt\_model/ckpt
Step:58450 , train loss : 0.6914623975753784
Step:58450 , test loss : 0.6928536891937256
\# Save into ./models/ckpt\_model/ckpt
Step:58500 , train loss : 0.6983135342597961
Step:58500 , test loss : 0.6914076805114746
\# Save into ./models/ckpt\_model/ckpt
Step:58550 , train loss : 0.6800497770309448
Step:58550 , test loss : 0.6973224878311157
\# Save into ./models/ckpt\_model/ckpt
Step:58600 , train loss : 0.695281982421875
Step:58600 , test loss : 0.691580057144165
\# Save into ./models/ckpt\_model/ckpt
Step:58650 , train loss : 0.6904732584953308
Step:58650 , test loss : 0.6913698315620422
\# Save into ./models/ckpt\_model/ckpt
Step:58700 , train loss : 0.674035906791687
Step:58700 , test loss : 0.6913076043128967
\# Save into ./models/ckpt\_model/ckpt
Step:58750 , train loss : 0.6827645301818848
Step:58750 , test loss : 0.6911637187004089
\# Save into ./models/ckpt\_model/ckpt
Step:58800 , train loss : 0.682814359664917
Step:58800 , test loss : 0.6917343735694885
\# Save into ./models/ckpt\_model/ckpt
Step:58850 , train loss : 0.6890782117843628
Step:58850 , test loss : 0.6927564740180969
\# Save into ./models/ckpt\_model/ckpt
Step:58900 , train loss : 0.7024132013320923
Step:58900 , test loss : 0.6972137093544006
\# Save into ./models/ckpt\_model/ckpt
Step:58950 , train loss : 0.6907078623771667
Step:58950 , test loss : 0.6907404661178589
\# Save into ./models/ckpt\_model/ckpt
Step:59000 , train loss : 0.6898237466812134
Step:59000 , test loss : 0.691594123840332
\# Save into ./models/ckpt\_model/ckpt
Step:59050 , train loss : 0.686869740486145
Step:59050 , test loss : 0.6912400126457214
\# Save into ./models/ckpt\_model/ckpt
Step:59100 , train loss : 0.6807701587677002
Step:59100 , test loss : 0.6910063624382019
\# Save into ./models/ckpt\_model/ckpt
Step:59150 , train loss : 0.6935740113258362
Step:59150 , test loss : 0.692468523979187
\# Save into ./models/ckpt\_model/ckpt
Step:59200 , train loss : 0.687427282333374
Step:59200 , test loss : 0.6906832456588745
\# Save into ./models/ckpt\_model/ckpt
Step:59250 , train loss : 0.6723259091377258
Step:59250 , test loss : 0.692206084728241
\# Save into ./models/ckpt\_model/ckpt
Step:59300 , train loss : 0.6843291521072388
Step:59300 , test loss : 0.6920894980430603
\# Save into ./models/ckpt\_model/ckpt
Step:59350 , train loss : 0.686115026473999
Step:59350 , test loss : 0.6910949945449829
\# Save into ./models/ckpt\_model/ckpt
Step:59400 , train loss : 0.6715788841247559
Step:59400 , test loss : 0.694238007068634
\# Save into ./models/ckpt\_model/ckpt
Step:59450 , train loss : 0.6988862752914429
Step:59450 , test loss : 0.692747175693512
\# Save into ./models/ckpt\_model/ckpt
Step:59500 , train loss : 0.7020878791809082
Step:59500 , test loss : 0.6930809617042542
\# Save into ./models/ckpt\_model/ckpt
Step:59550 , train loss : 0.6939305663108826
Step:59550 , test loss : 0.6915621757507324
\# Save into ./models/ckpt\_model/ckpt
Step:59600 , train loss : 0.6814237236976624
Step:59600 , test loss : 0.6906901597976685
\# Save into ./models/ckpt\_model/ckpt
Step:59650 , train loss : 0.6911784410476685
Step:59650 , test loss : 0.691983699798584
\# Save into ./models/ckpt\_model/ckpt
Step:59700 , train loss : 0.6812618374824524
Step:59700 , test loss : 0.6909795999526978
\# Save into ./models/ckpt\_model/ckpt
Step:59750 , train loss : 0.6687679290771484
Step:59750 , test loss : 0.6928439736366272
\# Save into ./models/ckpt\_model/ckpt
Step:59800 , train loss : 0.6837282180786133
Step:59800 , test loss : 0.69077467918396
\# Save into ./models/ckpt\_model/ckpt
Step:59850 , train loss : 0.6923067569732666
Step:59850 , test loss : 0.690854012966156
\# Save into ./models/ckpt\_model/ckpt
Step:59900 , train loss : 0.7084415555000305
Step:59900 , test loss : 0.7026193737983704
\# Save into ./models/ckpt\_model/ckpt
Step:59950 , train loss : 0.6672204732894897
Step:59950 , test loss : 0.6909072399139404
\# Save into ./models/ckpt\_model/ckpt
Step:60000 , train loss : 0.6795687079429626
Step:60000 , test loss : 0.6940567493438721
\# Save into ./models/ckpt\_model/ckpt
Step:60050 , train loss : 0.7103512287139893
Step:60050 , test loss : 0.692021906375885
\# Save into ./models/ckpt\_model/ckpt
Step:60100 , train loss : 0.684291422367096
Step:60100 , test loss : 0.6936035752296448
\# Save into ./models/ckpt\_model/ckpt
Step:60150 , train loss : 0.6811216473579407
Step:60150 , test loss : 0.6930471658706665
\# Save into ./models/ckpt\_model/ckpt
Step:60200 , train loss : 0.7334092855453491
Step:60200 , test loss : 0.6956426501274109
\# Save into ./models/ckpt\_model/ckpt
Step:60250 , train loss : 0.6886415481567383
Step:60250 , test loss : 0.6907188892364502
\# Save into ./models/ckpt\_model/ckpt
Step:60300 , train loss : 0.7022303938865662
Step:60300 , test loss : 0.6910447478294373
\# Save into ./models/ckpt\_model/ckpt
Step:60350 , train loss : 0.6819644570350647
Step:60350 , test loss : 0.6909448504447937
\# Save into ./models/ckpt\_model/ckpt
Step:60400 , train loss : 0.6731991171836853
Step:60400 , test loss : 0.6915281414985657
\# Save into ./models/ckpt\_model/ckpt
Step:60450 , train loss : 0.6539098620414734
Step:60450 , test loss : 0.6914288997650146
\# Save into ./models/ckpt\_model/ckpt
Step:60500 , train loss : 0.690006673336029
Step:60500 , test loss : 0.691043496131897
\# Save into ./models/ckpt\_model/ckpt
Step:60550 , train loss : 0.7045265436172485
Step:60550 , test loss : 0.6968774199485779
\# Save into ./models/ckpt\_model/ckpt
Step:60600 , train loss : 0.671323835849762
Step:60600 , test loss : 0.6907590627670288
\# Save into ./models/ckpt\_model/ckpt
Step:60650 , train loss : 0.7197391986846924
Step:60650 , test loss : 0.6921587586402893
\# Save into ./models/ckpt\_model/ckpt
Step:60700 , train loss : 0.7098420858383179
Step:60700 , test loss : 0.6942777633666992
\# Save into ./models/ckpt\_model/ckpt
Step:60750 , train loss : 0.7432475090026855
Step:60750 , test loss : 0.6914551258087158
\# Save into ./models/ckpt\_model/ckpt
Step:60800 , train loss : 0.6967792510986328
Step:60800 , test loss : 0.6908941268920898
\# Save into ./models/ckpt\_model/ckpt
Step:60850 , train loss : 0.693362832069397
Step:60850 , test loss : 0.6968836784362793
\# Save into ./models/ckpt\_model/ckpt
Step:60900 , train loss : 0.7353613972663879
Step:60900 , test loss : 0.6912452578544617
\# Save into ./models/ckpt\_model/ckpt
Step:60950 , train loss : 0.6818974614143372
Step:60950 , test loss : 0.6907669305801392
\# Save into ./models/ckpt\_model/ckpt
Step:61000 , train loss : 0.6662678122520447
Step:61000 , test loss : 0.691718578338623
\# Save into ./models/ckpt\_model/ckpt
Step:61050 , train loss : 0.6566731929779053
Step:61050 , test loss : 0.6938667893409729
\# Save into ./models/ckpt\_model/ckpt
Step:61100 , train loss : 0.6982893943786621
Step:61100 , test loss : 0.6920810341835022
\# Save into ./models/ckpt\_model/ckpt
Step:61150 , train loss : 0.6895190477371216
Step:61150 , test loss : 0.6916977167129517
\# Save into ./models/ckpt\_model/ckpt
Step:61200 , train loss : 0.6862104535102844
Step:61200 , test loss : 0.6907153725624084
\# Save into ./models/ckpt\_model/ckpt
Step:61250 , train loss : 0.6614294648170471
Step:61250 , test loss : 0.6955021023750305
\# Save into ./models/ckpt\_model/ckpt
Step:61300 , train loss : 0.6644827127456665
Step:61300 , test loss : 0.691085696220398
\# Save into ./models/ckpt\_model/ckpt
Step:61350 , train loss : 0.6794050335884094
Step:61350 , test loss : 0.6930345892906189
\# Save into ./models/ckpt\_model/ckpt
Step:61400 , train loss : 0.6912303566932678
Step:61400 , test loss : 0.6927468776702881
\# Save into ./models/ckpt\_model/ckpt
Step:61450 , train loss : 0.6888015270233154
Step:61450 , test loss : 0.6915411949157715
\# Save into ./models/ckpt\_model/ckpt
Step:61500 , train loss : 0.6586516499519348
Step:61500 , test loss : 0.6922170519828796
\# Save into ./models/ckpt\_model/ckpt
Step:61550 , train loss : 0.6880236864089966
Step:61550 , test loss : 0.6907480359077454
\# Save into ./models/ckpt\_model/ckpt
Step:61600 , train loss : 0.6875101923942566
Step:61600 , test loss : 0.6943233609199524
\# Save into ./models/ckpt\_model/ckpt
Step:61650 , train loss : 0.6889578700065613
Step:61650 , test loss : 0.6912975907325745
\# Save into ./models/ckpt\_model/ckpt
Step:61700 , train loss : 0.6874896287918091
Step:61700 , test loss : 0.6967268586158752
\# Save into ./models/ckpt\_model/ckpt
Step:61750 , train loss : 0.6816234588623047
Step:61750 , test loss : 0.6925704479217529
\# Save into ./models/ckpt\_model/ckpt
Step:61800 , train loss : 0.6856414675712585
Step:61800 , test loss : 0.690689206123352
\# Save into ./models/ckpt\_model/ckpt
Step:61850 , train loss : 0.6967992782592773
Step:61850 , test loss : 0.6918833255767822
\# Save into ./models/ckpt\_model/ckpt
Step:61900 , train loss : 0.6537532210350037
Step:61900 , test loss : 0.6957602500915527
\# Save into ./models/ckpt\_model/ckpt
Step:61950 , train loss : 0.6885618567466736
Step:61950 , test loss : 0.6927980780601501
\# Save into ./models/ckpt\_model/ckpt
Step:62000 , train loss : 0.6829879283905029
Step:62000 , test loss : 0.6906927227973938
\# Save into ./models/ckpt\_model/ckpt
Step:62050 , train loss : 0.7031780481338501
Step:62050 , test loss : 0.6951109766960144
\# Save into ./models/ckpt\_model/ckpt
Step:62100 , train loss : 0.6956179738044739
Step:62100 , test loss : 0.6930995583534241
\# Save into ./models/ckpt\_model/ckpt
Step:62150 , train loss : 0.6800649166107178
Step:62150 , test loss : 0.6906890273094177
\# Save into ./models/ckpt\_model/ckpt
Step:62200 , train loss : 0.6815404891967773
Step:62200 , test loss : 0.6906901597976685
\# Save into ./models/ckpt\_model/ckpt
Step:62250 , train loss : 0.7131078839302063
Step:62250 , test loss : 0.6910080313682556
\# Save into ./models/ckpt\_model/ckpt
Step:62300 , train loss : 0.694940447807312
Step:62300 , test loss : 0.6918362975120544
\# Save into ./models/ckpt\_model/ckpt
Step:62350 , train loss : 0.6708427667617798
Step:62350 , test loss : 0.6951677203178406
\# Save into ./models/ckpt\_model/ckpt
Step:62400 , train loss : 0.6507339477539062
Step:62400 , test loss : 0.6928232312202454
\# Save into ./models/ckpt\_model/ckpt
Step:62450 , train loss : 0.6840781569480896
Step:62450 , test loss : 0.6920455694198608
\# Save into ./models/ckpt\_model/ckpt
Step:62500 , train loss : 0.6817368268966675
Step:62500 , test loss : 0.6909877061843872
\# Save into ./models/ckpt\_model/ckpt
Step:62550 , train loss : 0.6729772686958313
Step:62550 , test loss : 0.6925979256629944
\# Save into ./models/ckpt\_model/ckpt
Step:62600 , train loss : 0.6986678838729858
Step:62600 , test loss : 0.6915678977966309
\# Save into ./models/ckpt\_model/ckpt
Step:62650 , train loss : 0.6911951303482056
Step:62650 , test loss : 0.6912100911140442
\# Save into ./models/ckpt\_model/ckpt
Step:62700 , train loss : 0.7173876762390137
Step:62700 , test loss : 0.6908844113349915
\# Save into ./models/ckpt\_model/ckpt
Step:62750 , train loss : 0.7041792869567871
Step:62750 , test loss : 0.6936764717102051
\# Save into ./models/ckpt\_model/ckpt
Step:62800 , train loss : 0.6948267817497253
Step:62800 , test loss : 0.6909616589546204
\# Save into ./models/ckpt\_model/ckpt
Step:62850 , train loss : 0.6830847859382629
Step:62850 , test loss : 0.6907241344451904
\# Save into ./models/ckpt\_model/ckpt
Step:62900 , train loss : 0.6907433271408081
Step:62900 , test loss : 0.6915611028671265
\# Save into ./models/ckpt\_model/ckpt
Step:62950 , train loss : 0.6926590204238892
Step:62950 , test loss : 0.6931077241897583
\# Save into ./models/ckpt\_model/ckpt
Step:63000 , train loss : 0.6933181285858154
Step:63000 , test loss : 0.6931102275848389
\# Save into ./models/ckpt\_model/ckpt
Step:63050 , train loss : 0.693789541721344
Step:63050 , test loss : 0.6931003332138062
\# Save into ./models/ckpt\_model/ckpt
Step:63100 , train loss : 0.6917304992675781
Step:63100 , test loss : 0.6930716037750244
\# Save into ./models/ckpt\_model/ckpt
Step:63150 , train loss : 0.6896578669548035
Step:63150 , test loss : 0.6930330991744995
\# Save into ./models/ckpt\_model/ckpt
Step:63200 , train loss : 0.6958671808242798
Step:63200 , test loss : 0.6927804350852966
\# Save into ./models/ckpt\_model/ckpt
Step:63250 , train loss : 0.7023985385894775
Step:63250 , test loss : 0.6925864815711975
\# Save into ./models/ckpt\_model/ckpt
Step:63300 , train loss : 0.6833413243293762
Step:63300 , test loss : 0.6909310221672058
\# Save into ./models/ckpt\_model/ckpt
Step:63350 , train loss : 0.6930955648422241
Step:63350 , test loss : 0.6927329897880554
\# Save into ./models/ckpt\_model/ckpt
Step:63400 , train loss : 0.68702232837677
Step:63400 , test loss : 0.6913402676582336
\# Save into ./models/ckpt\_model/ckpt
Step:63450 , train loss : 0.6550821661949158
Step:63450 , test loss : 0.6911211609840393
\# Save into ./models/ckpt\_model/ckpt
Step:63500 , train loss : 0.6870027780532837
Step:63500 , test loss : 0.6923975348472595
\# Save into ./models/ckpt\_model/ckpt
Step:63550 , train loss : 0.6824244260787964
Step:63550 , test loss : 0.6913359761238098
\# Save into ./models/ckpt\_model/ckpt
Step:63600 , train loss : 0.6482099890708923
Step:63600 , test loss : 0.6926379203796387
\# Save into ./models/ckpt\_model/ckpt
Step:63650 , train loss : 0.6953474283218384
Step:63650 , test loss : 0.6915462613105774
\# Save into ./models/ckpt\_model/ckpt
Step:63700 , train loss : 0.6780481338500977
Step:63700 , test loss : 0.6906996369361877
\# Save into ./models/ckpt\_model/ckpt
Step:63750 , train loss : 0.6294924020767212
Step:63750 , test loss : 0.6951239109039307
\# Save into ./models/ckpt\_model/ckpt
Step:63800 , train loss : 0.6905134916305542
Step:63800 , test loss : 0.6908778548240662
\# Save into ./models/ckpt\_model/ckpt
Step:63850 , train loss : 0.6937204003334045
Step:63850 , test loss : 0.692731499671936
\# Save into ./models/ckpt\_model/ckpt
Step:63900 , train loss : 0.6895596981048584
Step:63900 , test loss : 0.6923038363456726
\# Save into ./models/ckpt\_model/ckpt
Step:63950 , train loss : 0.6836801767349243
Step:63950 , test loss : 0.6907676458358765
\# Save into ./models/ckpt\_model/ckpt
Step:64000 , train loss : 0.6912039518356323
Step:64000 , test loss : 0.690832793712616
\# Save into ./models/ckpt\_model/ckpt
Step:64050 , train loss : 0.6903329491615295
Step:64050 , test loss : 0.6907102465629578
\# Save into ./models/ckpt\_model/ckpt
Step:64100 , train loss : 0.6825555562973022
Step:64100 , test loss : 0.6911633014678955
\# Save into ./models/ckpt\_model/ckpt
Step:64150 , train loss : 0.6920346021652222
Step:64150 , test loss : 0.692812442779541
\# Save into ./models/ckpt\_model/ckpt
Step:64200 , train loss : 0.6942224502563477
Step:64200 , test loss : 0.6927054524421692
\# Save into ./models/ckpt\_model/ckpt
Step:64250 , train loss : 0.6908730268478394
Step:64250 , test loss : 0.6943985223770142
\# Save into ./models/ckpt\_model/ckpt
Step:64300 , train loss : 0.6905872821807861
Step:64300 , test loss : 0.6924336552619934
\# Save into ./models/ckpt\_model/ckpt
Step:64350 , train loss : 0.6027556657791138
Step:64350 , test loss : 0.6930570602416992
\# Save into ./models/ckpt\_model/ckpt
Step:64400 , train loss : 0.7199783325195312
Step:64400 , test loss : 0.6911712288856506
\# Save into ./models/ckpt\_model/ckpt
Step:64450 , train loss : 0.6846154928207397
Step:64450 , test loss : 0.6909753680229187
\# Save into ./models/ckpt\_model/ckpt
Step:64500 , train loss : 0.687936544418335
Step:64500 , test loss : 0.6909632086753845
\# Save into ./models/ckpt\_model/ckpt
Step:64550 , train loss : 0.6918390393257141
Step:64550 , test loss : 0.6930128931999207
\# Save into ./models/ckpt\_model/ckpt
Step:64600 , train loss : 0.6899099946022034
Step:64600 , test loss : 0.6929187178611755
\# Save into ./models/ckpt\_model/ckpt
Step:64650 , train loss : 0.6821978688240051
Step:64650 , test loss : 0.691957414150238
\# Save into ./models/ckpt\_model/ckpt
Step:64700 , train loss : 0.687883198261261
Step:64700 , test loss : 0.692166268825531
\# Save into ./models/ckpt\_model/ckpt
Step:64750 , train loss : 0.6915820240974426
Step:64750 , test loss : 0.6925662755966187
\# Save into ./models/ckpt\_model/ckpt
Step:64800 , train loss : 0.7032459378242493
Step:64800 , test loss : 0.6916681528091431
\# Save into ./models/ckpt\_model/ckpt
Step:64850 , train loss : 0.6934608221054077
Step:64850 , test loss : 0.6930280923843384
\# Save into ./models/ckpt\_model/ckpt
Step:64900 , train loss : 0.6924093961715698
Step:64900 , test loss : 0.6930111050605774
\# Save into ./models/ckpt\_model/ckpt
Step:64950 , train loss : 0.687816321849823
Step:64950 , test loss : 0.6927610039710999
\# Save into ./models/ckpt\_model/ckpt
Step:65000 , train loss : 0.6836134791374207
Step:65000 , test loss : 0.6907615661621094
\# Save into ./models/ckpt\_model/ckpt
Step:65050 , train loss : 0.692984938621521
Step:65050 , test loss : 0.6931336522102356
\# Save into ./models/ckpt\_model/ckpt
Step:65100 , train loss : 0.6913416981697083
Step:65100 , test loss : 0.6931338310241699
\# Save into ./models/ckpt\_model/ckpt
Step:65150 , train loss : 0.6932830810546875
Step:65150 , test loss : 0.6931312084197998
\# Save into ./models/ckpt\_model/ckpt
Step:65200 , train loss : 0.693825364112854
Step:65200 , test loss : 0.6931262612342834
\# Save into ./models/ckpt\_model/ckpt
Step:65250 , train loss : 0.689384937286377
Step:65250 , test loss : 0.6931212544441223
\# Save into ./models/ckpt\_model/ckpt
Step:65300 , train loss : 0.6921764612197876
Step:65300 , test loss : 0.6931023001670837
\# Save into ./models/ckpt\_model/ckpt
Step:65350 , train loss : 0.6928561329841614
Step:65350 , test loss : 0.6930690407752991
\# Save into ./models/ckpt\_model/ckpt
Step:65400 , train loss : 0.6836127638816833
Step:65400 , test loss : 0.6929642558097839
\# Save into ./models/ckpt\_model/ckpt
Step:65450 , train loss : 0.7057427167892456
Step:65450 , test loss : 0.692396342754364
\# Save into ./models/ckpt\_model/ckpt
Step:65500 , train loss : 0.7024819850921631
Step:65500 , test loss : 0.6915374398231506
\# Save into ./models/ckpt\_model/ckpt
Step:65550 , train loss : 0.6860668063163757
Step:65550 , test loss : 0.6914109587669373
\# Save into ./models/ckpt\_model/ckpt
Step:65600 , train loss : 0.7029225826263428
Step:65600 , test loss : 0.6915478706359863
\# Save into ./models/ckpt\_model/ckpt
Step:65650 , train loss : 0.6913102269172668
Step:65650 , test loss : 0.6927790641784668
\# Save into ./models/ckpt\_model/ckpt
Step:65700 , train loss : 0.6705618500709534
Step:65700 , test loss : 0.6920884251594543
\# Save into ./models/ckpt\_model/ckpt
Step:65750 , train loss : 0.6937742829322815
Step:65750 , test loss : 0.6910302042961121
\# Save into ./models/ckpt\_model/ckpt
Step:65800 , train loss : 0.6842358112335205
Step:65800 , test loss : 0.6915481686592102
\# Save into ./models/ckpt\_model/ckpt
Step:65850 , train loss : 0.6837525367736816
Step:65850 , test loss : 0.6918789148330688
\# Save into ./models/ckpt\_model/ckpt
Step:65900 , train loss : 0.7028802633285522
Step:65900 , test loss : 0.6915827393531799
\# Save into ./models/ckpt\_model/ckpt
Step:65950 , train loss : 0.6904240250587463
Step:65950 , test loss : 0.6911822557449341
\# Save into ./models/ckpt\_model/ckpt
Step:66000 , train loss : 0.6986818313598633
Step:66000 , test loss : 0.6912728548049927
\# Save into ./models/ckpt\_model/ckpt
Step:66050 , train loss : 0.7196453809738159
Step:66050 , test loss : 0.6978579759597778
\# Save into ./models/ckpt\_model/ckpt
Step:66100 , train loss : 0.6899965405464172
Step:66100 , test loss : 0.6907503008842468
\# Save into ./models/ckpt\_model/ckpt
Step:66150 , train loss : 0.6687493920326233
Step:66150 , test loss : 0.6915227770805359
\# Save into ./models/ckpt\_model/ckpt
Step:66200 , train loss : 0.7134157419204712
Step:66200 , test loss : 0.6965212225914001
\# Save into ./models/ckpt\_model/ckpt
Step:66250 , train loss : 0.6922916173934937
Step:66250 , test loss : 0.6925577521324158
\# Save into ./models/ckpt\_model/ckpt
Step:66300 , train loss : 0.663443386554718
Step:66300 , test loss : 0.6935643553733826
\# Save into ./models/ckpt\_model/ckpt
Step:66350 , train loss : 0.6853691339492798
Step:66350 , test loss : 0.6913887858390808
\# Save into ./models/ckpt\_model/ckpt
Step:66400 , train loss : 0.6923267245292664
Step:66400 , test loss : 0.6925316452980042
\# Save into ./models/ckpt\_model/ckpt
Step:66450 , train loss : 0.7124214172363281
Step:66450 , test loss : 0.7014803290367126
\# Save into ./models/ckpt\_model/ckpt
Step:66500 , train loss : 0.6945915222167969
Step:66500 , test loss : 0.6908671855926514
\# Save into ./models/ckpt\_model/ckpt
Step:66550 , train loss : 0.6852661371231079
Step:66550 , test loss : 0.6907852292060852
\# Save into ./models/ckpt\_model/ckpt
Step:66600 , train loss : 0.6586917042732239
Step:66600 , test loss : 0.6908055543899536
\# Save into ./models/ckpt\_model/ckpt
Step:66650 , train loss : 0.679160475730896
Step:66650 , test loss : 0.6913260817527771
\# Save into ./models/ckpt\_model/ckpt
Step:66700 , train loss : 0.7320836782455444
Step:66700 , test loss : 0.6942712664604187
\# Save into ./models/ckpt\_model/ckpt
Step:66750 , train loss : 0.6575262546539307
Step:66750 , test loss : 0.6908089518547058
\# Save into ./models/ckpt\_model/ckpt
Step:66800 , train loss : 0.6601583361625671
Step:66800 , test loss : 0.6914072632789612
\# Save into ./models/ckpt\_model/ckpt
Step:66850 , train loss : 0.6805747151374817
Step:66850 , test loss : 0.691513180732727
\# Save into ./models/ckpt\_model/ckpt
Step:66900 , train loss : 0.7361328601837158
Step:66900 , test loss : 0.6918709874153137
\# Save into ./models/ckpt\_model/ckpt
Step:66950 , train loss : 0.6981319785118103
Step:66950 , test loss : 0.6917381286621094
\# Save into ./models/ckpt\_model/ckpt
Step:67000 , train loss : 0.6916927099227905
Step:67000 , test loss : 0.6916406750679016
\# Save into ./models/ckpt\_model/ckpt
Step:67050 , train loss : 0.6914172768592834
Step:67050 , test loss : 0.6927372217178345
\# Save into ./models/ckpt\_model/ckpt
Step:67100 , train loss : 0.6926867961883545
Step:67100 , test loss : 0.6931211352348328
\# Save into ./models/ckpt\_model/ckpt
Step:67150 , train loss : 0.6932494044303894
Step:67150 , test loss : 0.6931172013282776
\# Save into ./models/ckpt\_model/ckpt
Step:67200 , train loss : 0.6938586235046387
Step:67200 , test loss : 0.6931054592132568
\# Save into ./models/ckpt\_model/ckpt
Step:67250 , train loss : 0.6933012008666992
Step:67250 , test loss : 0.6930846571922302
\# Save into ./models/ckpt\_model/ckpt
Step:67300 , train loss : 0.6946712732315063
Step:67300 , test loss : 0.693048357963562
\# Save into ./models/ckpt\_model/ckpt
Step:67350 , train loss : 0.6932833790779114
Step:67350 , test loss : 0.6928820013999939
\# Save into ./models/ckpt\_model/ckpt
Step:67400 , train loss : 0.6722394227981567
Step:67400 , test loss : 0.6907123327255249
\# Save into ./models/ckpt\_model/ckpt
Step:67450 , train loss : 0.6926871538162231
Step:67450 , test loss : 0.6918343901634216
\# Save into ./models/ckpt\_model/ckpt
Step:67500 , train loss : 0.6649306416511536
Step:67500 , test loss : 0.6908785700798035
\# Save into ./models/ckpt\_model/ckpt
Step:67550 , train loss : 0.6782151460647583
Step:67550 , test loss : 0.691398024559021
\# Save into ./models/ckpt\_model/ckpt
Step:67600 , train loss : 0.6498713493347168
Step:67600 , test loss : 0.6915102601051331
\# Save into ./models/ckpt\_model/ckpt
Step:67650 , train loss : 0.7037184834480286
Step:67650 , test loss : 0.6916655898094177
\# Save into ./models/ckpt\_model/ckpt
Step:67700 , train loss : 0.6954845190048218
Step:67700 , test loss : 0.6916273832321167
\# Save into ./models/ckpt\_model/ckpt
Step:67750 , train loss : 0.6876282095909119
Step:67750 , test loss : 0.6919139623641968
\# Save into ./models/ckpt\_model/ckpt
Step:67800 , train loss : 0.6830432415008545
Step:67800 , test loss : 0.6928033828735352
\# Save into ./models/ckpt\_model/ckpt
Step:67850 , train loss : 0.7003397941589355
Step:67850 , test loss : 0.6933882832527161
\# Save into ./models/ckpt\_model/ckpt
Step:67900 , train loss : 0.6920986175537109
Step:67900 , test loss : 0.691912829875946
\# Save into ./models/ckpt\_model/ckpt
Step:67950 , train loss : 0.6846091151237488
Step:67950 , test loss : 0.6909258365631104
\# Save into ./models/ckpt\_model/ckpt
Step:68000 , train loss : 0.7070183753967285
Step:68000 , test loss : 0.692025363445282
\# Save into ./models/ckpt\_model/ckpt
Step:68050 , train loss : 0.6889067888259888
Step:68050 , test loss : 0.6913650631904602
\# Save into ./models/ckpt\_model/ckpt
Step:68100 , train loss : 0.7092968821525574
Step:68100 , test loss : 0.6907854080200195
\# Save into ./models/ckpt\_model/ckpt
Step:68150 , train loss : 0.6803542375564575
Step:68150 , test loss : 0.6907752156257629
\# Save into ./models/ckpt\_model/ckpt
Step:68200 , train loss : 0.6847454309463501
Step:68200 , test loss : 0.6915221810340881
\# Save into ./models/ckpt\_model/ckpt
Step:68250 , train loss : 0.6629399061203003
Step:68250 , test loss : 0.6907202005386353
\# Save into ./models/ckpt\_model/ckpt
Step:68300 , train loss : 0.686996340751648
Step:68300 , test loss : 0.6907082200050354
\# Save into ./models/ckpt\_model/ckpt
Step:68350 , train loss : 0.6823431849479675
Step:68350 , test loss : 0.6909260749816895
\# Save into ./models/ckpt\_model/ckpt
Step:68400 , train loss : 0.702771008014679
Step:68400 , test loss : 0.6913139820098877
\# Save into ./models/ckpt\_model/ckpt
Step:68450 , train loss : 0.6836137771606445
Step:68450 , test loss : 0.6956117749214172
\# Save into ./models/ckpt\_model/ckpt
Step:68500 , train loss : 0.6897480487823486
Step:68500 , test loss : 0.6927348375320435
\# Save into ./models/ckpt\_model/ckpt
Step:68550 , train loss : 0.6881730556488037
Step:68550 , test loss : 0.6926368474960327
\# Save into ./models/ckpt\_model/ckpt
Step:68600 , train loss : 0.6885494589805603
Step:68600 , test loss : 0.6914513111114502
\# Save into ./models/ckpt\_model/ckpt
Step:68650 , train loss : 0.6896800398826599
Step:68650 , test loss : 0.6913259625434875
\# Save into ./models/ckpt\_model/ckpt
Step:68700 , train loss : 0.6981616020202637
Step:68700 , test loss : 0.692503035068512
\# Save into ./models/ckpt\_model/ckpt
Step:68750 , train loss : 0.6743831634521484
Step:68750 , test loss : 0.6911330223083496
\# Save into ./models/ckpt\_model/ckpt
Step:68800 , train loss : 0.6937683820724487
Step:68800 , test loss : 0.691710889339447
\# Save into ./models/ckpt\_model/ckpt
Step:68850 , train loss : 0.6882330775260925
Step:68850 , test loss : 0.6907075643539429
\# Save into ./models/ckpt\_model/ckpt
Step:68900 , train loss : 0.6764175891876221
Step:68900 , test loss : 0.7017624974250793
\# Save into ./models/ckpt\_model/ckpt
Step:68950 , train loss : 0.6854853630065918
Step:68950 , test loss : 0.6919489502906799
\# Save into ./models/ckpt\_model/ckpt
Step:69000 , train loss : 0.7193571925163269
Step:69000 , test loss : 0.6918760538101196
\# Save into ./models/ckpt\_model/ckpt
Step:69050 , train loss : 0.6898494958877563
Step:69050 , test loss : 0.6925318241119385
\# Save into ./models/ckpt\_model/ckpt
Step:69100 , train loss : 0.6655826568603516
Step:69100 , test loss : 0.6921380758285522
\# Save into ./models/ckpt\_model/ckpt
Step:69150 , train loss : 0.6725051403045654
Step:69150 , test loss : 0.6906829476356506
\# Save into ./models/ckpt\_model/ckpt
Step:69200 , train loss : 0.6920921206474304
Step:69200 , test loss : 0.6930211186408997
\# Save into ./models/ckpt\_model/ckpt
Step:69250 , train loss : 0.6928141117095947
Step:69250 , test loss : 0.692908525466919
\# Save into ./models/ckpt\_model/ckpt
Step:69300 , train loss : 0.6913571357727051
Step:69300 , test loss : 0.6920305490493774
\# Save into ./models/ckpt\_model/ckpt
Step:69350 , train loss : 0.6872645616531372
Step:69350 , test loss : 0.6910938024520874
\# Save into ./models/ckpt\_model/ckpt
Step:69400 , train loss : 0.6883391737937927
Step:69400 , test loss : 0.6927335262298584
\# Save into ./models/ckpt\_model/ckpt
Step:69450 , train loss : 0.7204963564872742
Step:69450 , test loss : 0.6906837821006775
\# Save into ./models/ckpt\_model/ckpt
Step:69500 , train loss : 0.686205267906189
Step:69500 , test loss : 0.6918617486953735
\# Save into ./models/ckpt\_model/ckpt
Step:69550 , train loss : 0.691547155380249
Step:69550 , test loss : 0.6914382576942444
\# Save into ./models/ckpt\_model/ckpt
Step:69600 , train loss : 0.6420148015022278
Step:69600 , test loss : 0.6941430568695068
\# Save into ./models/ckpt\_model/ckpt
Step:69650 , train loss : 0.6933308839797974
Step:69650 , test loss : 0.6928164958953857
\# Save into ./models/ckpt\_model/ckpt
Step:69700 , train loss : 0.688315749168396
Step:69700 , test loss : 0.6920843124389648
\# Save into ./models/ckpt\_model/ckpt
Step:69750 , train loss : 0.7115729451179504
Step:69750 , test loss : 0.6907981634140015
\# Save into ./models/ckpt\_model/ckpt
Step:69800 , train loss : 0.6721380352973938
Step:69800 , test loss : 0.6927053332328796
\# Save into ./models/ckpt\_model/ckpt
Step:69850 , train loss : 0.681216835975647
Step:69850 , test loss : 0.6911109685897827
\# Save into ./models/ckpt\_model/ckpt
Step:69900 , train loss : 0.6511771082878113
Step:69900 , test loss : 0.6911577582359314
\# Save into ./models/ckpt\_model/ckpt
Step:69950 , train loss : 0.686345100402832
Step:69950 , test loss : 0.6907369494438171
\# Save into ./models/ckpt\_model/ckpt
Step:70000 , train loss : 0.6907068490982056
Step:70000 , test loss : 0.6907235383987427
\# Save into ./models/ckpt\_model/ckpt
Step:70050 , train loss : 0.7177076935768127
Step:70050 , test loss : 0.6907410025596619
\# Save into ./models/ckpt\_model/ckpt
Step:70100 , train loss : 0.6930387020111084
Step:70100 , test loss : 0.6908982396125793
\# Save into ./models/ckpt\_model/ckpt
Step:70150 , train loss : 0.6853599548339844
Step:70150 , test loss : 0.6907041072845459
\# Save into ./models/ckpt\_model/ckpt
Step:70200 , train loss : 0.6502118706703186
Step:70200 , test loss : 0.6908012628555298
\# Save into ./models/ckpt\_model/ckpt
Step:70250 , train loss : 0.6576769351959229
Step:70250 , test loss : 0.6938825845718384
\# Save into ./models/ckpt\_model/ckpt
Step:70300 , train loss : 0.6793794631958008
Step:70300 , test loss : 0.6949412822723389
\# Save into ./models/ckpt\_model/ckpt
Step:70350 , train loss : 0.6766924858093262
Step:70350 , test loss : 0.6906852722167969
\# Save into ./models/ckpt\_model/ckpt
Step:70400 , train loss : 0.6694714426994324
Step:70400 , test loss : 0.6938643455505371
\# Save into ./models/ckpt\_model/ckpt
Step:70450 , train loss : 0.6968998908996582
Step:70450 , test loss : 0.6908830404281616
\# Save into ./models/ckpt\_model/ckpt
Step:70500 , train loss : 0.6694632172584534
Step:70500 , test loss : 0.690839409828186
\# Save into ./models/ckpt\_model/ckpt
Step:70550 , train loss : 0.6799580454826355
Step:70550 , test loss : 0.7056673765182495
\# Save into ./models/ckpt\_model/ckpt
Step:70600 , train loss : 0.6743101477622986
Step:70600 , test loss : 0.690726101398468
\# Save into ./models/ckpt\_model/ckpt
Step:70650 , train loss : 0.691694438457489
Step:70650 , test loss : 0.6907141804695129
\# Save into ./models/ckpt\_model/ckpt
Step:70700 , train loss : 0.659489631652832
Step:70700 , test loss : 0.7001520395278931
\# Save into ./models/ckpt\_model/ckpt
Step:70750 , train loss : 0.6895060539245605
Step:70750 , test loss : 0.6906914710998535
\# Save into ./models/ckpt\_model/ckpt
Step:70800 , train loss : 0.660877525806427
Step:70800 , test loss : 0.6908556222915649
\# Save into ./models/ckpt\_model/ckpt
Step:70850 , train loss : 0.6880109906196594
Step:70850 , test loss : 0.6906829476356506
\# Save into ./models/ckpt\_model/ckpt
Step:70900 , train loss : 0.6708523035049438
Step:70900 , test loss : 0.6909782290458679
\# Save into ./models/ckpt\_model/ckpt
Step:70950 , train loss : 0.7214434742927551
Step:70950 , test loss : 0.6939722895622253
\# Save into ./models/ckpt\_model/ckpt
Step:71000 , train loss : 0.7231212258338928
Step:71000 , test loss : 0.6951692700386047
\# Save into ./models/ckpt\_model/ckpt
Step:71050 , train loss : 0.6683039665222168
Step:71050 , test loss : 0.6907472610473633
\# Save into ./models/ckpt\_model/ckpt
Step:71100 , train loss : 0.6863477826118469
Step:71100 , test loss : 0.69244384765625
\# Save into ./models/ckpt\_model/ckpt
Step:71150 , train loss : 0.6930310726165771
Step:71150 , test loss : 0.6995005011558533
\# Save into ./models/ckpt\_model/ckpt
Step:71200 , train loss : 0.6843594312667847
Step:71200 , test loss : 0.6941532492637634
\# Save into ./models/ckpt\_model/ckpt
Step:71250 , train loss : 0.7149431705474854
Step:71250 , test loss : 0.6907187104225159
\# Save into ./models/ckpt\_model/ckpt
Step:71300 , train loss : 0.6818143725395203
Step:71300 , test loss : 0.6910582184791565
\# Save into ./models/ckpt\_model/ckpt
Step:71350 , train loss : 0.7089338302612305
Step:71350 , test loss : 0.6920334100723267
\# Save into ./models/ckpt\_model/ckpt
Step:71400 , train loss : 0.6743084788322449
Step:71400 , test loss : 0.6954498887062073
\# Save into ./models/ckpt\_model/ckpt
Step:71450 , train loss : 0.6995715498924255
Step:71450 , test loss : 0.6907026767730713
\# Save into ./models/ckpt\_model/ckpt
Step:71500 , train loss : 0.6905685663223267
Step:71500 , test loss : 0.6921682357788086
\# Save into ./models/ckpt\_model/ckpt
Step:71550 , train loss : 0.7761936187744141
Step:71550 , test loss : 0.6912136673927307
\# Save into ./models/ckpt\_model/ckpt
Step:71600 , train loss : 0.6746282577514648
Step:71600 , test loss : 0.6916249394416809
\# Save into ./models/ckpt\_model/ckpt
Step:71650 , train loss : 0.6780767440795898
Step:71650 , test loss : 0.6913414001464844
\# Save into ./models/ckpt\_model/ckpt
Step:71700 , train loss : 0.6663253903388977
Step:71700 , test loss : 0.6915659308433533
\# Save into ./models/ckpt\_model/ckpt
Step:71750 , train loss : 0.69542396068573
Step:71750 , test loss : 0.691148579120636
\# Save into ./models/ckpt\_model/ckpt
Step:71800 , train loss : 0.6938945055007935
Step:71800 , test loss : 0.6924338936805725
\# Save into ./models/ckpt\_model/ckpt
Step:71850 , train loss : 0.7345264554023743
Step:71850 , test loss : 0.6922940015792847
\# Save into ./models/ckpt\_model/ckpt
Step:71900 , train loss : 0.6777451634407043
Step:71900 , test loss : 0.6908625960350037
\# Save into ./models/ckpt\_model/ckpt
Step:71950 , train loss : 0.6675101518630981
Step:71950 , test loss : 0.6990267634391785
\# Save into ./models/ckpt\_model/ckpt
Step:72000 , train loss : 0.728272020816803
Step:72000 , test loss : 0.6907491683959961
\# Save into ./models/ckpt\_model/ckpt
Step:72050 , train loss : 0.6865195035934448
Step:72050 , test loss : 0.6915595531463623
\# Save into ./models/ckpt\_model/ckpt
Step:72100 , train loss : 0.6893550753593445
Step:72100 , test loss : 0.6911989450454712
\# Save into ./models/ckpt\_model/ckpt
Step:72150 , train loss : 0.7126226425170898
Step:72150 , test loss : 0.6906889081001282
\# Save into ./models/ckpt\_model/ckpt
Step:72200 , train loss : 0.7105786800384521
Step:72200 , test loss : 0.6928749680519104
\# Save into ./models/ckpt\_model/ckpt
Step:72250 , train loss : 0.6929144859313965
Step:72250 , test loss : 0.6928569674491882
\# Save into ./models/ckpt\_model/ckpt
Step:72300 , train loss : 0.6835980415344238
Step:72300 , test loss : 0.6924148797988892
\# Save into ./models/ckpt\_model/ckpt
Step:72350 , train loss : 0.6655831336975098
Step:72350 , test loss : 0.6931936144828796
\# Save into ./models/ckpt\_model/ckpt
Step:72400 , train loss : 0.6549437642097473
Step:72400 , test loss : 0.6929877996444702
\# Save into ./models/ckpt\_model/ckpt
Step:72450 , train loss : 0.7108944058418274
Step:72450 , test loss : 0.6910489797592163
\# Save into ./models/ckpt\_model/ckpt
Step:72500 , train loss : 0.686516284942627
Step:72500 , test loss : 0.6907923221588135
\# Save into ./models/ckpt\_model/ckpt
Step:72550 , train loss : 0.7008441686630249
Step:72550 , test loss : 0.6908612847328186
\# Save into ./models/ckpt\_model/ckpt
Step:72600 , train loss : 0.7052866816520691
Step:72600 , test loss : 0.6907885074615479
\# Save into ./models/ckpt\_model/ckpt
Step:72650 , train loss : 0.6890880465507507
Step:72650 , test loss : 0.6909987926483154
\# Save into ./models/ckpt\_model/ckpt
Step:72700 , train loss : 0.6949662566184998
Step:72700 , test loss : 0.6921330690383911
\# Save into ./models/ckpt\_model/ckpt
Step:72750 , train loss : 0.6819043755531311
Step:72750 , test loss : 0.6907942295074463
\# Save into ./models/ckpt\_model/ckpt
Step:72800 , train loss : 0.6842508316040039
Step:72800 , test loss : 0.6928783059120178
\# Save into ./models/ckpt\_model/ckpt
Step:72850 , train loss : 0.6839423179626465
Step:72850 , test loss : 0.6910233497619629
\# Save into ./models/ckpt\_model/ckpt
Step:72900 , train loss : 0.6963182091712952
Step:72900 , test loss : 0.69143146276474
\# Save into ./models/ckpt\_model/ckpt
Step:72950 , train loss : 0.6859045028686523
Step:72950 , test loss : 0.6908154487609863
\# Save into ./models/ckpt\_model/ckpt
Step:73000 , train loss : 0.6858671307563782
Step:73000 , test loss : 0.6915077567100525
\# Save into ./models/ckpt\_model/ckpt
Step:73050 , train loss : 0.6919119358062744
Step:73050 , test loss : 0.6929196715354919
\# Save into ./models/ckpt\_model/ckpt
Step:73100 , train loss : 0.6901593208312988
Step:73100 , test loss : 0.6926771402359009
\# Save into ./models/ckpt\_model/ckpt
Step:73150 , train loss : 0.6899400353431702
Step:73150 , test loss : 0.6932225823402405
\# Save into ./models/ckpt\_model/ckpt
Step:73200 , train loss : 0.6734485626220703
Step:73200 , test loss : 0.6914080381393433
\# Save into ./models/ckpt\_model/ckpt
Step:73250 , train loss : 0.6709823608398438
Step:73250 , test loss : 0.6931660175323486
\# Save into ./models/ckpt\_model/ckpt
Step:73300 , train loss : 0.6826510429382324
Step:73300 , test loss : 0.6910682320594788
\# Save into ./models/ckpt\_model/ckpt
Step:73350 , train loss : 0.70452481508255
Step:73350 , test loss : 0.690708577632904
\# Save into ./models/ckpt\_model/ckpt
Step:73400 , train loss : 0.6830942034721375
Step:73400 , test loss : 0.6923533082008362
\# Save into ./models/ckpt\_model/ckpt
Step:73450 , train loss : 0.6825171709060669
Step:73450 , test loss : 0.6917944550514221
\# Save into ./models/ckpt\_model/ckpt
Step:73500 , train loss : 0.7227389216423035
Step:73500 , test loss : 0.6913837194442749
\# Save into ./models/ckpt\_model/ckpt
Step:73550 , train loss : 0.6795616149902344
Step:73550 , test loss : 0.6906901597976685
\# Save into ./models/ckpt\_model/ckpt
Step:73600 , train loss : 0.6799489259719849
Step:73600 , test loss : 0.6906842589378357
\# Save into ./models/ckpt\_model/ckpt
Step:73650 , train loss : 0.7292435765266418
Step:73650 , test loss : 0.6911646127700806
\# Save into ./models/ckpt\_model/ckpt
Step:73700 , train loss : 0.6712867617607117
Step:73700 , test loss : 0.7028447389602661
\# Save into ./models/ckpt\_model/ckpt
Step:73750 , train loss : 0.6931931972503662
Step:73750 , test loss : 0.6917158961296082
\# Save into ./models/ckpt\_model/ckpt
Step:73800 , train loss : 0.6311845183372498
Step:73800 , test loss : 0.6910110116004944
\# Save into ./models/ckpt\_model/ckpt
Step:73850 , train loss : 0.6738012433052063
Step:73850 , test loss : 0.6907134652137756
\# Save into ./models/ckpt\_model/ckpt
Step:73900 , train loss : 0.680375874042511
Step:73900 , test loss : 0.6907537579536438
\# Save into ./models/ckpt\_model/ckpt
Step:73950 , train loss : 0.6957362294197083
Step:73950 , test loss : 0.6906962990760803
\# Save into ./models/ckpt\_model/ckpt
Step:74000 , train loss : 0.6923295259475708
Step:74000 , test loss : 0.6926261782646179
\# Save into ./models/ckpt\_model/ckpt
Step:74050 , train loss : 0.6919958591461182
Step:74050 , test loss : 0.6918339729309082
\# Save into ./models/ckpt\_model/ckpt
Step:74100 , train loss : 0.6654309630393982
Step:74100 , test loss : 0.6925826668739319
\# Save into ./models/ckpt\_model/ckpt
Step:74150 , train loss : 0.6815009713172913
Step:74150 , test loss : 0.6908836364746094
\# Save into ./models/ckpt\_model/ckpt
Step:74200 , train loss : 0.7019891738891602
Step:74200 , test loss : 0.6939611434936523
\# Save into ./models/ckpt\_model/ckpt
Step:74250 , train loss : 0.7407507300376892
Step:74250 , test loss : 0.6907200217247009
\# Save into ./models/ckpt\_model/ckpt
Step:74300 , train loss : 0.6932355165481567
Step:74300 , test loss : 0.6914243698120117
\# Save into ./models/ckpt\_model/ckpt
Step:74350 , train loss : 0.6662287712097168
Step:74350 , test loss : 0.6933431029319763
\# Save into ./models/ckpt\_model/ckpt
Step:74400 , train loss : 0.645799994468689
Step:74400 , test loss : 0.691512942314148
\# Save into ./models/ckpt\_model/ckpt
Step:74450 , train loss : 0.6961783766746521
Step:74450 , test loss : 0.6917849183082581
\# Save into ./models/ckpt\_model/ckpt
Step:74500 , train loss : 0.6388198137283325
Step:74500 , test loss : 0.6947935223579407
\# Save into ./models/ckpt\_model/ckpt
Step:74550 , train loss : 0.7013105750083923
Step:74550 , test loss : 0.6913712024688721
\# Save into ./models/ckpt\_model/ckpt
Step:74600 , train loss : 0.7041121125221252
Step:74600 , test loss : 0.6932428479194641
\# Save into ./models/ckpt\_model/ckpt
Step:74650 , train loss : 0.7066141366958618
Step:74650 , test loss : 0.6908254027366638
\# Save into ./models/ckpt\_model/ckpt
Step:74700 , train loss : 0.6602162718772888
Step:74700 , test loss : 0.691101610660553
\# Save into ./models/ckpt\_model/ckpt
Step:74750 , train loss : 0.6790071129798889
Step:74750 , test loss : 0.6940494775772095
\# Save into ./models/ckpt\_model/ckpt
Step:74800 , train loss : 0.6846822500228882
Step:74800 , test loss : 0.6911530494689941
\# Save into ./models/ckpt\_model/ckpt
Step:74850 , train loss : 0.772759735584259
Step:74850 , test loss : 0.6914679408073425
\# Save into ./models/ckpt\_model/ckpt
Step:74900 , train loss : 0.6915440559387207
Step:74900 , test loss : 0.693047285079956
\# Save into ./models/ckpt\_model/ckpt
Step:74950 , train loss : 0.6938266158103943
Step:74950 , test loss : 0.6931101679801941
\# Save into ./models/ckpt\_model/ckpt
Step:75000 , train loss : 0.6931014060974121
Step:75000 , test loss : 0.6931014060974121
\# Save into ./models/ckpt\_model/ckpt
\# Finish 

    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
